//
// Generated by NVIDIA NVVM Compiler
//
// Compiler Build ID: CL-26855388
// Driver 410.129
// Based on LLVM 3.4svn
//

.version 6.3
.target sm_61, texmode_independent
.address_size 64

	// .globl	gpu_decompress

.entry gpu_decompress(
	.param .u64 .ptr .global .align 4 gpu_decompress_param_0,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_1,
	.param .u64 .ptr .global .align 4 gpu_decompress_param_2,
	.param .u64 gpu_decompress_param_3
)
{
	.local .align 4 .b8 	__local_depot0[260];
	.reg .b64 	%SP;
	.reg .b64 	%SPL;
	.reg .pred 	%p<10>;
	.reg .b32 	%r<56>;
	.reg .b64 	%rd<44>;


	mov.u64 	%SPL, __local_depot0;
	ld.param.u64 	%rd5, [gpu_decompress_param_0];
	ld.param.u64 	%rd6, [gpu_decompress_param_1];
	ld.param.u64 	%rd7, [gpu_decompress_param_2];
	ld.param.u64 	%rd8, [gpu_decompress_param_3];
	add.u64 	%rd1, %SPL, 0;
	mov.u32 	%r23, %ctaid.x;
	mov.u32 	%r24, %ntid.x;
	mov.b32	%r25, %envreg3;
	mad.lo.s32 	%r26, %r23, %r24, %r25;
	mov.u32 	%r27, %tid.x;
	add.s32 	%r1, %r26, %r27;
	cvt.s64.s32	%rd10, %r1;
	setp.ge.u64	%p1, %rd10, %rd8;
	@%p1 bra 	BB0_12;

	mul.wide.s32 	%rd11, %r1, 12;
	add.s64 	%rd12, %rd5, %rd11;
	ld.global.nc.u32 	%r2, [%rd12];
	ld.global.nc.u32 	%r3, [%rd12+4];
	ld.global.nc.u32 	%r4, [%rd12+8];
	mov.u64 	%rd13, 0;
	st.local.u32 	[%rd1+4], %rd13;
	st.local.u32 	[%rd1], %rd13;
	st.local.u32 	[%rd1+12], %rd13;
	st.local.u32 	[%rd1+8], %rd13;
	st.local.u32 	[%rd1+20], %rd13;
	st.local.u32 	[%rd1+16], %rd13;
	st.local.u32 	[%rd1+28], %rd13;
	st.local.u32 	[%rd1+24], %rd13;
	st.local.u32 	[%rd1+36], %rd13;
	st.local.u32 	[%rd1+32], %rd13;
	st.local.u32 	[%rd1+44], %rd13;
	st.local.u32 	[%rd1+40], %rd13;
	st.local.u32 	[%rd1+52], %rd13;
	st.local.u32 	[%rd1+48], %rd13;
	st.local.u32 	[%rd1+60], %rd13;
	st.local.u32 	[%rd1+56], %rd13;
	st.local.u32 	[%rd1+68], %rd13;
	st.local.u32 	[%rd1+64], %rd13;
	st.local.u32 	[%rd1+76], %rd13;
	st.local.u32 	[%rd1+72], %rd13;
	st.local.u32 	[%rd1+84], %rd13;
	st.local.u32 	[%rd1+80], %rd13;
	st.local.u32 	[%rd1+92], %rd13;
	st.local.u32 	[%rd1+88], %rd13;
	st.local.u32 	[%rd1+100], %rd13;
	st.local.u32 	[%rd1+96], %rd13;
	st.local.u32 	[%rd1+108], %rd13;
	st.local.u32 	[%rd1+104], %rd13;
	st.local.u32 	[%rd1+116], %rd13;
	st.local.u32 	[%rd1+112], %rd13;
	st.local.u32 	[%rd1+124], %rd13;
	st.local.u32 	[%rd1+120], %rd13;
	st.local.u32 	[%rd1+132], %rd13;
	st.local.u32 	[%rd1+128], %rd13;
	st.local.u32 	[%rd1+140], %rd13;
	st.local.u32 	[%rd1+136], %rd13;
	st.local.u32 	[%rd1+148], %rd13;
	st.local.u32 	[%rd1+144], %rd13;
	st.local.u32 	[%rd1+156], %rd13;
	st.local.u32 	[%rd1+152], %rd13;
	st.local.u32 	[%rd1+164], %rd13;
	st.local.u32 	[%rd1+160], %rd13;
	st.local.u32 	[%rd1+172], %rd13;
	st.local.u32 	[%rd1+168], %rd13;
	st.local.u32 	[%rd1+180], %rd13;
	st.local.u32 	[%rd1+176], %rd13;
	st.local.u32 	[%rd1+188], %rd13;
	st.local.u32 	[%rd1+184], %rd13;
	st.local.u32 	[%rd1+196], %rd13;
	st.local.u32 	[%rd1+192], %rd13;
	st.local.u32 	[%rd1+204], %rd13;
	st.local.u32 	[%rd1+200], %rd13;
	st.local.u32 	[%rd1+212], %rd13;
	st.local.u32 	[%rd1+208], %rd13;
	st.local.u32 	[%rd1+220], %rd13;
	st.local.u32 	[%rd1+216], %rd13;
	st.local.u32 	[%rd1+228], %rd13;
	st.local.u32 	[%rd1+224], %rd13;
	st.local.u32 	[%rd1+236], %rd13;
	st.local.u32 	[%rd1+232], %rd13;
	st.local.u32 	[%rd1+244], %rd13;
	st.local.u32 	[%rd1+240], %rd13;
	st.local.u32 	[%rd1+252], %rd13;
	st.local.u32 	[%rd1+248], %rd13;
	setp.eq.s32	%p2, %r3, 0;
	@%p2 bra 	BB0_10;

	and.b32  	%r5, %r3, 3;
	setp.eq.s32	%p3, %r5, 0;
	mov.u32 	%r54, 0;
	@%p3 bra 	BB0_8;

	setp.eq.s32	%p4, %r5, 1;
	mov.u32 	%r50, 0;
	@%p4 bra 	BB0_7;

	setp.eq.s32	%p5, %r5, 2;
	mov.u32 	%r48, 0;
	@%p5 bra 	BB0_6;

	mul.wide.u32 	%rd14, %r2, 4;
	add.s64 	%rd15, %rd6, %rd14;
	ld.global.nc.u32 	%r32, [%rd15];
	st.local.u32 	[%rd1], %r32;
	add.s32 	%r2, %r2, 1;
	mov.u32 	%r48, 1;

BB0_6:
	mul.wide.u32 	%rd16, %r2, 4;
	add.s64 	%rd17, %rd6, %rd16;
	ld.global.nc.u32 	%r33, [%rd17];
	mul.wide.u32 	%rd18, %r48, 4;
	add.s64 	%rd19, %rd1, %rd18;
	st.local.u32 	[%rd19], %r33;
	add.s32 	%r50, %r48, 1;
	add.s32 	%r2, %r2, 1;

BB0_7:
	mul.wide.u32 	%rd20, %r2, 4;
	add.s64 	%rd21, %rd6, %rd20;
	ld.global.nc.u32 	%r34, [%rd21];
	mul.wide.u32 	%rd22, %r50, 4;
	add.s64 	%rd23, %rd1, %rd22;
	st.local.u32 	[%rd23], %r34;
	add.s32 	%r54, %r50, 1;
	add.s32 	%r2, %r2, 1;

BB0_8:
	setp.lt.u32	%p6, %r3, 4;
	@%p6 bra 	BB0_10;

BB0_9:
	mul.wide.u32 	%rd24, %r2, 4;
	add.s64 	%rd25, %rd6, %rd24;
	ld.global.nc.u32 	%r35, [%rd25];
	mul.wide.u32 	%rd26, %r54, 4;
	add.s64 	%rd27, %rd1, %rd26;
	st.local.u32 	[%rd27], %r35;
	add.s32 	%r36, %r2, 1;
	mul.wide.u32 	%rd28, %r36, 4;
	add.s64 	%rd29, %rd6, %rd28;
	ld.global.nc.u32 	%r37, [%rd29];
	add.s32 	%r38, %r54, 1;
	mul.wide.u32 	%rd30, %r38, 4;
	add.s64 	%rd31, %rd1, %rd30;
	st.local.u32 	[%rd31], %r37;
	add.s32 	%r39, %r2, 2;
	mul.wide.u32 	%rd32, %r39, 4;
	add.s64 	%rd33, %rd6, %rd32;
	ld.global.nc.u32 	%r40, [%rd33];
	add.s32 	%r41, %r54, 2;
	mul.wide.u32 	%rd34, %r41, 4;
	add.s64 	%rd35, %rd1, %rd34;
	st.local.u32 	[%rd35], %r40;
	add.s32 	%r42, %r2, 3;
	mul.wide.u32 	%rd36, %r42, 4;
	add.s64 	%rd37, %rd6, %rd36;
	ld.global.nc.u32 	%r43, [%rd37];
	add.s32 	%r44, %r54, 3;
	mul.wide.u32 	%rd38, %r44, 4;
	add.s64 	%rd39, %rd1, %rd38;
	st.local.u32 	[%rd39], %r43;
	add.s32 	%r2, %r2, 4;
	add.s32 	%r54, %r54, 4;
	setp.lt.u32	%p7, %r54, %r3;
	@%p7 bra 	BB0_9;

BB0_10:
	st.local.u32 	[%rd1+256], %r4;
	mul.wide.s32 	%rd40, %r1, 260;
	add.s64 	%rd4, %rd7, %rd40;
	mov.u32 	%r55, 0;
	mov.pred 	%p8, 0;
	@%p8 bra 	BB0_12;

BB0_11:
	mul.wide.s32 	%rd41, %r55, 4;
	add.s64 	%rd42, %rd1, %rd41;
	ld.local.u32 	%r46, [%rd42];
	add.s64 	%rd43, %rd4, %rd41;
	st.global.u32 	[%rd43], %r46;
	add.s32 	%r55, %r55, 1;
	setp.lt.u32	%p9, %r55, 65;
	@%p9 bra 	BB0_11;

BB0_12:
	ret;
}

	// .globl	gpu_memset
.entry gpu_memset(
	.param .u64 .ptr .global .align 16 gpu_memset_param_0,
	.param .u32 gpu_memset_param_1,
	.param .u64 gpu_memset_param_2
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<8>;
	.reg .b64 	%rd<6>;


	ld.param.u64 	%rd1, [gpu_memset_param_0];
	ld.param.u32 	%r2, [gpu_memset_param_1];
	ld.param.u64 	%rd2, [gpu_memset_param_2];
	mov.b32	%r3, %envreg3;
	mov.u32 	%r4, %ctaid.x;
	mov.u32 	%r5, %ntid.x;
	mad.lo.s32 	%r6, %r4, %r5, %r3;
	mov.u32 	%r7, %tid.x;
	add.s32 	%r1, %r6, %r7;
	cvt.s64.s32	%rd3, %r1;
	setp.ge.u64	%p1, %rd3, %rd2;
	@%p1 bra 	BB1_2;

	mul.wide.s32 	%rd4, %r1, 16;
	add.s64 	%rd5, %rd1, %rd4;
	st.global.v4.u32 	[%rd5], {%r2, %r2, %r2, %r2};

BB1_2:
	ret;
}

	// .globl	gpu_atinit
.entry gpu_atinit(
	.param .u64 .ptr .global .align 4 gpu_atinit_param_0,
	.param .u64 gpu_atinit_param_1
)
{
	.reg .pred 	%p<2>;
	.reg .b32 	%r<13>;
	.reg .b64 	%rd<7>;


	ld.param.u64 	%rd2, [gpu_atinit_param_0];
	ld.param.u64 	%rd3, [gpu_atinit_param_1];
	mov.b32	%r2, %envreg3;
	mov.u32 	%r3, %ctaid.x;
	mov.u32 	%r4, %ntid.x;
	mad.lo.s32 	%r5, %r3, %r4, %r2;
	mov.u32 	%r6, %tid.x;
	add.s32 	%r1, %r5, %r6;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd3;
	@%p1 bra 	BB2_2;

	cvt.u32.u64	%r7, %rd1;
	shr.u64 	%rd4, %rd1, 32;
	cvt.u32.u64	%r8, %rd4;
	xor.b32  	%r9, %r7, 1549556828;
	xor.b32  	%r10, %r8, 909522486;
	mul.wide.s32 	%rd5, %r1, 260;
	add.s64 	%rd6, %rd2, %rd5;
	st.global.u32 	[%rd6], %r9;
	st.global.u32 	[%rd6+4], %r10;
	mov.u32 	%r11, 0;
	st.global.u32 	[%rd6+8], %r11;
	st.global.u32 	[%rd6+12], %r11;
	st.global.u32 	[%rd6+16], %r11;
	st.global.u32 	[%rd6+20], %r11;
	st.global.u32 	[%rd6+24], %r11;
	st.global.u32 	[%rd6+28], %r11;
	st.global.u32 	[%rd6+32], %r11;
	st.global.u32 	[%rd6+36], %r11;
	st.global.u32 	[%rd6+40], %r11;
	st.global.u32 	[%rd6+44], %r11;
	st.global.u32 	[%rd6+48], %r11;
	st.global.u32 	[%rd6+52], %r11;
	st.global.u32 	[%rd6+56], %r11;
	st.global.u32 	[%rd6+60], %r11;
	st.global.u32 	[%rd6+64], %r11;
	st.global.u32 	[%rd6+68], %r11;
	st.global.u32 	[%rd6+72], %r11;
	st.global.u32 	[%rd6+76], %r11;
	st.global.u32 	[%rd6+80], %r11;
	st.global.u32 	[%rd6+84], %r11;
	st.global.u32 	[%rd6+88], %r11;
	st.global.u32 	[%rd6+92], %r11;
	st.global.u32 	[%rd6+96], %r11;
	st.global.u32 	[%rd6+100], %r11;
	st.global.u32 	[%rd6+104], %r11;
	st.global.u32 	[%rd6+108], %r11;
	st.global.u32 	[%rd6+112], %r11;
	st.global.u32 	[%rd6+116], %r11;
	st.global.u32 	[%rd6+120], %r11;
	st.global.u32 	[%rd6+124], %r11;
	st.global.u32 	[%rd6+128], %r11;
	st.global.u32 	[%rd6+132], %r11;
	st.global.u32 	[%rd6+136], %r11;
	st.global.u32 	[%rd6+140], %r11;
	st.global.u32 	[%rd6+144], %r11;
	st.global.u32 	[%rd6+148], %r11;
	st.global.u32 	[%rd6+152], %r11;
	st.global.u32 	[%rd6+156], %r11;
	st.global.u32 	[%rd6+160], %r11;
	st.global.u32 	[%rd6+164], %r11;
	st.global.u32 	[%rd6+168], %r11;
	st.global.u32 	[%rd6+172], %r11;
	st.global.u32 	[%rd6+176], %r11;
	st.global.u32 	[%rd6+180], %r11;
	st.global.u32 	[%rd6+184], %r11;
	st.global.u32 	[%rd6+188], %r11;
	st.global.u32 	[%rd6+192], %r11;
	st.global.u32 	[%rd6+196], %r11;
	st.global.u32 	[%rd6+200], %r11;
	st.global.u32 	[%rd6+204], %r11;
	st.global.u32 	[%rd6+208], %r11;
	st.global.u32 	[%rd6+212], %r11;
	st.global.u32 	[%rd6+216], %r11;
	st.global.u32 	[%rd6+220], %r11;
	st.global.u32 	[%rd6+224], %r11;
	st.global.u32 	[%rd6+228], %r11;
	st.global.u32 	[%rd6+232], %r11;
	st.global.u32 	[%rd6+236], %r11;
	st.global.u32 	[%rd6+240], %r11;
	st.global.u32 	[%rd6+244], %r11;
	st.global.u32 	[%rd6+248], %r11;
	st.global.u32 	[%rd6+252], %r11;
	mov.u32 	%r12, 7;
	st.global.u32 	[%rd6+256], %r12;

BB2_2:
	ret;
}

	// .globl	m00000_mxx
.entry m00000_mxx(
	.param .u64 .ptr .global .align 4 m00000_mxx_param_0,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_1,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_2,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_3,
	.param .u64 .ptr .global .align 1 m00000_mxx_param_4,
	.param .u64 .ptr .global .align 1 m00000_mxx_param_5,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_6,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_7,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_8,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_9,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_10,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_11,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_12,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_13,
	.param .u64 .ptr .global .align 8 m00000_mxx_param_14,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_15,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_16,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_17,
	.param .u64 .ptr .global .align 1 m00000_mxx_param_18,
	.param .u64 .ptr .global .align 4 m00000_mxx_param_19,
	.param .u64 .ptr .global .align 16 m00000_mxx_param_20,
	.param .u64 .ptr .global .align 16 m00000_mxx_param_21,
	.param .u64 .ptr .global .align 16 m00000_mxx_param_22,
	.param .u64 .ptr .global .align 16 m00000_mxx_param_23,
	.param .u32 m00000_mxx_param_24,
	.param .u32 m00000_mxx_param_25,
	.param .u32 m00000_mxx_param_26,
	.param .u32 m00000_mxx_param_27,
	.param .u32 m00000_mxx_param_28,
	.param .u32 m00000_mxx_param_29,
	.param .u32 m00000_mxx_param_30,
	.param .u32 m00000_mxx_param_31,
	.param .u32 m00000_mxx_param_32,
	.param .u32 m00000_mxx_param_33,
	.param .u64 m00000_mxx_param_34
)
{
	.reg .pred 	%p<141>;
	.reg .b32 	%r<7863>;
	.reg .b64 	%rd<67>;


	ld.param.u64 	%rd5, [m00000_mxx_param_0];
	ld.param.u64 	%rd6, [m00000_mxx_param_2];
	ld.param.u64 	%rd18, [m00000_mxx_param_19];
	ld.param.u32 	%r989, [m00000_mxx_param_24];
	ld.param.u32 	%r994, [m00000_mxx_param_31];
	ld.param.u64 	%rd19, [m00000_mxx_param_34];
	mov.b32	%r996, %envreg3;
	mov.u32 	%r997, %ctaid.x;
	mov.u32 	%r998, %ntid.x;
	mad.lo.s32 	%r999, %r997, %r998, %r996;
	mov.u32 	%r1000, %tid.x;
	add.s32 	%r1, %r999, %r1000;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd19;
	@%p1 bra 	BB3_141;

	mul.wide.s32 	%rd20, %r1, 260;
	add.s64 	%rd21, %rd5, %rd20;
	ld.global.nc.u32 	%r1007, [%rd21+256];
	and.b32  	%r2, %r1007, 255;
	mov.u32 	%r7691, 0;
	mov.u32 	%r7, 1732584193;
	mov.u32 	%r6, -271733879;
	mov.u32 	%r5, -1732584194;
	mov.u32 	%r4, 271733878;
	mov.u32 	%r7696, %r7691;
	bra.uni 	BB3_2;

BB3_189:
	add.s32 	%r7691, %r7691, 64;
	mov.u32 	%r7184, 0;
	// inline asm
	shf.r.wrap.b32 %r7121, %r24, %r7184, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7125, %r23, %r24, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7129, %r22, %r23, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7133, %r21, %r22, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7137, %r20, %r21, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7141, %r19, %r20, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7145, %r18, %r19, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7149, %r17, %r18, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7153, %r16, %r17, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7157, %r15, %r16, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7161, %r14, %r15, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7165, %r13, %r14, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7169, %r12, %r13, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7173, %r11, %r12, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7177, %r10, %r11, %r7184;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7181, %r9, %r10, %r7184;
	// inline asm
	xor.b32  	%r7185, %r5, %r4;
	and.b32  	%r7186, %r6, %r7185;
	xor.b32  	%r7187, %r7186, %r4;
	add.s32 	%r7188, %r7, %r7187;
	add.s32 	%r7189, %r7188, %r7181;
	add.s32 	%r7190, %r7189, -680876936;
	shf.l.wrap.b32 	%r7191, %r7190, %r7190, 7;
	add.s32 	%r7192, %r7191, %r6;
	xor.b32  	%r7193, %r6, %r5;
	and.b32  	%r7194, %r7192, %r7193;
	xor.b32  	%r7195, %r7194, %r5;
	add.s32 	%r7196, %r4, %r7177;
	add.s32 	%r7197, %r7196, %r7195;
	add.s32 	%r7198, %r7197, -389564586;
	shf.l.wrap.b32 	%r7199, %r7198, %r7198, 12;
	add.s32 	%r7200, %r7199, %r7192;
	xor.b32  	%r7201, %r7192, %r6;
	and.b32  	%r7202, %r7200, %r7201;
	xor.b32  	%r7203, %r7202, %r6;
	add.s32 	%r7204, %r5, %r7173;
	add.s32 	%r7205, %r7204, %r7203;
	add.s32 	%r7206, %r7205, 606105819;
	shf.l.wrap.b32 	%r7207, %r7206, %r7206, 17;
	add.s32 	%r7208, %r7207, %r7200;
	xor.b32  	%r7209, %r7200, %r7192;
	and.b32  	%r7210, %r7208, %r7209;
	xor.b32  	%r7211, %r7210, %r7192;
	add.s32 	%r7212, %r6, %r7169;
	add.s32 	%r7213, %r7212, %r7211;
	add.s32 	%r7214, %r7213, -1044525330;
	shf.l.wrap.b32 	%r7215, %r7214, %r7214, 22;
	add.s32 	%r7216, %r7215, %r7208;
	xor.b32  	%r7217, %r7208, %r7200;
	and.b32  	%r7218, %r7216, %r7217;
	xor.b32  	%r7219, %r7218, %r7200;
	add.s32 	%r7220, %r7165, %r7192;
	add.s32 	%r7221, %r7220, %r7219;
	add.s32 	%r7222, %r7221, -176418897;
	shf.l.wrap.b32 	%r7223, %r7222, %r7222, 7;
	add.s32 	%r7224, %r7223, %r7216;
	xor.b32  	%r7225, %r7216, %r7208;
	and.b32  	%r7226, %r7224, %r7225;
	xor.b32  	%r7227, %r7226, %r7208;
	add.s32 	%r7228, %r7161, %r7200;
	add.s32 	%r7229, %r7228, %r7227;
	add.s32 	%r7230, %r7229, 1200080426;
	shf.l.wrap.b32 	%r7231, %r7230, %r7230, 12;
	add.s32 	%r7232, %r7231, %r7224;
	xor.b32  	%r7233, %r7224, %r7216;
	and.b32  	%r7234, %r7232, %r7233;
	xor.b32  	%r7235, %r7234, %r7216;
	add.s32 	%r7236, %r7157, %r7208;
	add.s32 	%r7237, %r7236, %r7235;
	add.s32 	%r7238, %r7237, -1473231341;
	shf.l.wrap.b32 	%r7239, %r7238, %r7238, 17;
	add.s32 	%r7240, %r7239, %r7232;
	xor.b32  	%r7241, %r7232, %r7224;
	and.b32  	%r7242, %r7240, %r7241;
	xor.b32  	%r7243, %r7242, %r7224;
	add.s32 	%r7244, %r7153, %r7216;
	add.s32 	%r7245, %r7244, %r7243;
	add.s32 	%r7246, %r7245, -45705983;
	shf.l.wrap.b32 	%r7247, %r7246, %r7246, 22;
	add.s32 	%r7248, %r7247, %r7240;
	xor.b32  	%r7249, %r7240, %r7232;
	and.b32  	%r7250, %r7248, %r7249;
	xor.b32  	%r7251, %r7250, %r7232;
	add.s32 	%r7252, %r7149, %r7224;
	add.s32 	%r7253, %r7252, %r7251;
	add.s32 	%r7254, %r7253, 1770035416;
	shf.l.wrap.b32 	%r7255, %r7254, %r7254, 7;
	add.s32 	%r7256, %r7255, %r7248;
	xor.b32  	%r7257, %r7248, %r7240;
	and.b32  	%r7258, %r7256, %r7257;
	xor.b32  	%r7259, %r7258, %r7240;
	add.s32 	%r7260, %r7145, %r7232;
	add.s32 	%r7261, %r7260, %r7259;
	add.s32 	%r7262, %r7261, -1958414417;
	shf.l.wrap.b32 	%r7263, %r7262, %r7262, 12;
	add.s32 	%r7264, %r7263, %r7256;
	xor.b32  	%r7265, %r7256, %r7248;
	and.b32  	%r7266, %r7264, %r7265;
	xor.b32  	%r7267, %r7266, %r7248;
	add.s32 	%r7268, %r7141, %r7240;
	add.s32 	%r7269, %r7268, %r7267;
	add.s32 	%r7270, %r7269, -42063;
	shf.l.wrap.b32 	%r7271, %r7270, %r7270, 17;
	add.s32 	%r7272, %r7271, %r7264;
	xor.b32  	%r7273, %r7264, %r7256;
	and.b32  	%r7274, %r7272, %r7273;
	xor.b32  	%r7275, %r7274, %r7256;
	add.s32 	%r7276, %r7137, %r7248;
	add.s32 	%r7277, %r7276, %r7275;
	add.s32 	%r7278, %r7277, -1990404162;
	shf.l.wrap.b32 	%r7279, %r7278, %r7278, 22;
	add.s32 	%r7280, %r7279, %r7272;
	xor.b32  	%r7281, %r7272, %r7264;
	and.b32  	%r7282, %r7280, %r7281;
	xor.b32  	%r7283, %r7282, %r7264;
	add.s32 	%r7284, %r7133, %r7256;
	add.s32 	%r7285, %r7284, %r7283;
	add.s32 	%r7286, %r7285, 1804603682;
	shf.l.wrap.b32 	%r7287, %r7286, %r7286, 7;
	add.s32 	%r7288, %r7287, %r7280;
	xor.b32  	%r7289, %r7280, %r7272;
	and.b32  	%r7290, %r7288, %r7289;
	xor.b32  	%r7291, %r7290, %r7272;
	add.s32 	%r7292, %r7129, %r7264;
	add.s32 	%r7293, %r7292, %r7291;
	add.s32 	%r7294, %r7293, -40341101;
	shf.l.wrap.b32 	%r7295, %r7294, %r7294, 12;
	add.s32 	%r7296, %r7295, %r7288;
	xor.b32  	%r7297, %r7288, %r7280;
	and.b32  	%r7298, %r7296, %r7297;
	xor.b32  	%r7299, %r7298, %r7280;
	add.s32 	%r7300, %r7125, %r7272;
	add.s32 	%r7301, %r7300, %r7299;
	add.s32 	%r7302, %r7301, -1502002290;
	shf.l.wrap.b32 	%r7303, %r7302, %r7302, 17;
	add.s32 	%r7304, %r7303, %r7296;
	xor.b32  	%r7305, %r7296, %r7288;
	and.b32  	%r7306, %r7304, %r7305;
	xor.b32  	%r7307, %r7306, %r7288;
	add.s32 	%r7308, %r7121, %r7280;
	add.s32 	%r7309, %r7308, %r7307;
	add.s32 	%r7310, %r7309, 1236535329;
	shf.l.wrap.b32 	%r7311, %r7310, %r7310, 22;
	add.s32 	%r7312, %r7311, %r7304;
	xor.b32  	%r7313, %r7312, %r7304;
	and.b32  	%r7314, %r7313, %r7296;
	xor.b32  	%r7315, %r7314, %r7304;
	add.s32 	%r7316, %r7177, %r7288;
	add.s32 	%r7317, %r7316, %r7315;
	add.s32 	%r7318, %r7317, -165796510;
	shf.l.wrap.b32 	%r7319, %r7318, %r7318, 5;
	add.s32 	%r7320, %r7319, %r7312;
	xor.b32  	%r7321, %r7320, %r7312;
	and.b32  	%r7322, %r7321, %r7304;
	xor.b32  	%r7323, %r7322, %r7312;
	add.s32 	%r7324, %r7157, %r7296;
	add.s32 	%r7325, %r7324, %r7323;
	add.s32 	%r7326, %r7325, -1069501632;
	shf.l.wrap.b32 	%r7327, %r7326, %r7326, 9;
	add.s32 	%r7328, %r7327, %r7320;
	xor.b32  	%r7329, %r7328, %r7320;
	and.b32  	%r7330, %r7329, %r7312;
	xor.b32  	%r7331, %r7330, %r7320;
	add.s32 	%r7332, %r7137, %r7304;
	add.s32 	%r7333, %r7332, %r7331;
	add.s32 	%r7334, %r7333, 643717713;
	shf.l.wrap.b32 	%r7335, %r7334, %r7334, 14;
	add.s32 	%r7336, %r7335, %r7328;
	xor.b32  	%r7337, %r7336, %r7328;
	and.b32  	%r7338, %r7337, %r7320;
	xor.b32  	%r7339, %r7338, %r7328;
	add.s32 	%r7340, %r7181, %r7312;
	add.s32 	%r7341, %r7340, %r7339;
	add.s32 	%r7342, %r7341, -373897302;
	shf.l.wrap.b32 	%r7343, %r7342, %r7342, 20;
	add.s32 	%r7344, %r7343, %r7336;
	xor.b32  	%r7345, %r7344, %r7336;
	and.b32  	%r7346, %r7345, %r7328;
	xor.b32  	%r7347, %r7346, %r7336;
	add.s32 	%r7348, %r7161, %r7320;
	add.s32 	%r7349, %r7348, %r7347;
	add.s32 	%r7350, %r7349, -701558691;
	shf.l.wrap.b32 	%r7351, %r7350, %r7350, 5;
	add.s32 	%r7352, %r7351, %r7344;
	xor.b32  	%r7353, %r7352, %r7344;
	and.b32  	%r7354, %r7353, %r7336;
	xor.b32  	%r7355, %r7354, %r7344;
	add.s32 	%r7356, %r7141, %r7328;
	add.s32 	%r7357, %r7356, %r7355;
	add.s32 	%r7358, %r7357, 38016083;
	shf.l.wrap.b32 	%r7359, %r7358, %r7358, 9;
	add.s32 	%r7360, %r7359, %r7352;
	xor.b32  	%r7361, %r7360, %r7352;
	and.b32  	%r7362, %r7361, %r7344;
	xor.b32  	%r7363, %r7362, %r7352;
	add.s32 	%r7364, %r7121, %r7336;
	add.s32 	%r7365, %r7364, %r7363;
	add.s32 	%r7366, %r7365, -660478335;
	shf.l.wrap.b32 	%r7367, %r7366, %r7366, 14;
	add.s32 	%r7368, %r7367, %r7360;
	xor.b32  	%r7369, %r7368, %r7360;
	and.b32  	%r7370, %r7369, %r7352;
	xor.b32  	%r7371, %r7370, %r7360;
	add.s32 	%r7372, %r7165, %r7344;
	add.s32 	%r7373, %r7372, %r7371;
	add.s32 	%r7374, %r7373, -405537848;
	shf.l.wrap.b32 	%r7375, %r7374, %r7374, 20;
	add.s32 	%r7376, %r7375, %r7368;
	xor.b32  	%r7377, %r7376, %r7368;
	and.b32  	%r7378, %r7377, %r7360;
	xor.b32  	%r7379, %r7378, %r7368;
	add.s32 	%r7380, %r7145, %r7352;
	add.s32 	%r7381, %r7380, %r7379;
	add.s32 	%r7382, %r7381, 568446438;
	shf.l.wrap.b32 	%r7383, %r7382, %r7382, 5;
	add.s32 	%r7384, %r7383, %r7376;
	xor.b32  	%r7385, %r7384, %r7376;
	and.b32  	%r7386, %r7385, %r7368;
	xor.b32  	%r7387, %r7386, %r7376;
	add.s32 	%r7388, %r7125, %r7360;
	add.s32 	%r7389, %r7388, %r7387;
	add.s32 	%r7390, %r7389, -1019803690;
	shf.l.wrap.b32 	%r7391, %r7390, %r7390, 9;
	add.s32 	%r7392, %r7391, %r7384;
	xor.b32  	%r7393, %r7392, %r7384;
	and.b32  	%r7394, %r7393, %r7376;
	xor.b32  	%r7395, %r7394, %r7384;
	add.s32 	%r7396, %r7169, %r7368;
	add.s32 	%r7397, %r7396, %r7395;
	add.s32 	%r7398, %r7397, -187363961;
	shf.l.wrap.b32 	%r7399, %r7398, %r7398, 14;
	add.s32 	%r7400, %r7399, %r7392;
	xor.b32  	%r7401, %r7400, %r7392;
	and.b32  	%r7402, %r7401, %r7384;
	xor.b32  	%r7403, %r7402, %r7392;
	add.s32 	%r7404, %r7149, %r7376;
	add.s32 	%r7405, %r7404, %r7403;
	add.s32 	%r7406, %r7405, 1163531501;
	shf.l.wrap.b32 	%r7407, %r7406, %r7406, 20;
	add.s32 	%r7408, %r7407, %r7400;
	xor.b32  	%r7409, %r7408, %r7400;
	and.b32  	%r7410, %r7409, %r7392;
	xor.b32  	%r7411, %r7410, %r7400;
	add.s32 	%r7412, %r7129, %r7384;
	add.s32 	%r7413, %r7412, %r7411;
	add.s32 	%r7414, %r7413, -1444681467;
	shf.l.wrap.b32 	%r7415, %r7414, %r7414, 5;
	add.s32 	%r7416, %r7415, %r7408;
	xor.b32  	%r7417, %r7416, %r7408;
	and.b32  	%r7418, %r7417, %r7400;
	xor.b32  	%r7419, %r7418, %r7408;
	add.s32 	%r7420, %r7173, %r7392;
	add.s32 	%r7421, %r7420, %r7419;
	add.s32 	%r7422, %r7421, -51403784;
	shf.l.wrap.b32 	%r7423, %r7422, %r7422, 9;
	add.s32 	%r7424, %r7423, %r7416;
	xor.b32  	%r7425, %r7424, %r7416;
	and.b32  	%r7426, %r7425, %r7408;
	xor.b32  	%r7427, %r7426, %r7416;
	add.s32 	%r7428, %r7153, %r7400;
	add.s32 	%r7429, %r7428, %r7427;
	add.s32 	%r7430, %r7429, 1735328473;
	shf.l.wrap.b32 	%r7431, %r7430, %r7430, 14;
	add.s32 	%r7432, %r7431, %r7424;
	xor.b32  	%r7433, %r7432, %r7424;
	and.b32  	%r7434, %r7433, %r7416;
	xor.b32  	%r7435, %r7434, %r7424;
	add.s32 	%r7436, %r7133, %r7408;
	add.s32 	%r7437, %r7436, %r7435;
	add.s32 	%r7438, %r7437, -1926607734;
	shf.l.wrap.b32 	%r7439, %r7438, %r7438, 20;
	add.s32 	%r7440, %r7439, %r7432;
	xor.b32  	%r7441, %r7440, %r7432;
	xor.b32  	%r7442, %r7441, %r7424;
	add.s32 	%r7443, %r7161, %r7416;
	add.s32 	%r7444, %r7443, %r7442;
	add.s32 	%r7445, %r7444, -378558;
	shf.l.wrap.b32 	%r7446, %r7445, %r7445, 4;
	add.s32 	%r7447, %r7446, %r7440;
	xor.b32  	%r7448, %r7447, %r7441;
	add.s32 	%r7449, %r7149, %r7424;
	add.s32 	%r7450, %r7449, %r7448;
	add.s32 	%r7451, %r7450, -2022574463;
	shf.l.wrap.b32 	%r7452, %r7451, %r7451, 11;
	add.s32 	%r7453, %r7452, %r7447;
	xor.b32  	%r7454, %r7453, %r7447;
	xor.b32  	%r7455, %r7454, %r7440;
	add.s32 	%r7456, %r7137, %r7432;
	add.s32 	%r7457, %r7456, %r7455;
	add.s32 	%r7458, %r7457, 1839030562;
	shf.l.wrap.b32 	%r7459, %r7458, %r7458, 16;
	add.s32 	%r7460, %r7459, %r7453;
	xor.b32  	%r7461, %r7460, %r7454;
	add.s32 	%r7462, %r7125, %r7440;
	add.s32 	%r7463, %r7462, %r7461;
	add.s32 	%r7464, %r7463, -35309556;
	shf.l.wrap.b32 	%r7465, %r7464, %r7464, 23;
	add.s32 	%r7466, %r7465, %r7460;
	xor.b32  	%r7467, %r7466, %r7460;
	xor.b32  	%r7468, %r7467, %r7453;
	add.s32 	%r7469, %r7177, %r7447;
	add.s32 	%r7470, %r7469, %r7468;
	add.s32 	%r7471, %r7470, -1530992060;
	shf.l.wrap.b32 	%r7472, %r7471, %r7471, 4;
	add.s32 	%r7473, %r7472, %r7466;
	xor.b32  	%r7474, %r7473, %r7467;
	add.s32 	%r7475, %r7165, %r7453;
	add.s32 	%r7476, %r7475, %r7474;
	add.s32 	%r7477, %r7476, 1272893353;
	shf.l.wrap.b32 	%r7478, %r7477, %r7477, 11;
	add.s32 	%r7479, %r7478, %r7473;
	xor.b32  	%r7480, %r7479, %r7473;
	xor.b32  	%r7481, %r7480, %r7466;
	add.s32 	%r7482, %r7153, %r7460;
	add.s32 	%r7483, %r7482, %r7481;
	add.s32 	%r7484, %r7483, -155497632;
	shf.l.wrap.b32 	%r7485, %r7484, %r7484, 16;
	add.s32 	%r7486, %r7485, %r7479;
	xor.b32  	%r7487, %r7486, %r7480;
	add.s32 	%r7488, %r7141, %r7466;
	add.s32 	%r7489, %r7488, %r7487;
	add.s32 	%r7490, %r7489, -1094730640;
	shf.l.wrap.b32 	%r7491, %r7490, %r7490, 23;
	add.s32 	%r7492, %r7491, %r7486;
	xor.b32  	%r7493, %r7492, %r7486;
	xor.b32  	%r7494, %r7493, %r7479;
	add.s32 	%r7495, %r7129, %r7473;
	add.s32 	%r7496, %r7495, %r7494;
	add.s32 	%r7497, %r7496, 681279174;
	shf.l.wrap.b32 	%r7498, %r7497, %r7497, 4;
	add.s32 	%r7499, %r7498, %r7492;
	xor.b32  	%r7500, %r7499, %r7493;
	add.s32 	%r7501, %r7181, %r7479;
	add.s32 	%r7502, %r7501, %r7500;
	add.s32 	%r7503, %r7502, -358537222;
	shf.l.wrap.b32 	%r7504, %r7503, %r7503, 11;
	add.s32 	%r7505, %r7504, %r7499;
	xor.b32  	%r7506, %r7505, %r7499;
	xor.b32  	%r7507, %r7506, %r7492;
	add.s32 	%r7508, %r7169, %r7486;
	add.s32 	%r7509, %r7508, %r7507;
	add.s32 	%r7510, %r7509, -722521979;
	shf.l.wrap.b32 	%r7511, %r7510, %r7510, 16;
	add.s32 	%r7512, %r7511, %r7505;
	xor.b32  	%r7513, %r7512, %r7506;
	add.s32 	%r7514, %r7157, %r7492;
	add.s32 	%r7515, %r7514, %r7513;
	add.s32 	%r7516, %r7515, 76029189;
	shf.l.wrap.b32 	%r7517, %r7516, %r7516, 23;
	add.s32 	%r7518, %r7517, %r7512;
	xor.b32  	%r7519, %r7518, %r7512;
	xor.b32  	%r7520, %r7519, %r7505;
	add.s32 	%r7521, %r7145, %r7499;
	add.s32 	%r7522, %r7521, %r7520;
	add.s32 	%r7523, %r7522, -640364487;
	shf.l.wrap.b32 	%r7524, %r7523, %r7523, 4;
	add.s32 	%r7525, %r7524, %r7518;
	xor.b32  	%r7526, %r7525, %r7519;
	add.s32 	%r7527, %r7133, %r7505;
	add.s32 	%r7528, %r7527, %r7526;
	add.s32 	%r7529, %r7528, -421815835;
	shf.l.wrap.b32 	%r7530, %r7529, %r7529, 11;
	add.s32 	%r7531, %r7530, %r7525;
	xor.b32  	%r7532, %r7531, %r7525;
	xor.b32  	%r7533, %r7532, %r7518;
	add.s32 	%r7534, %r7121, %r7512;
	add.s32 	%r7535, %r7534, %r7533;
	add.s32 	%r7536, %r7535, 530742520;
	shf.l.wrap.b32 	%r7537, %r7536, %r7536, 16;
	add.s32 	%r7538, %r7537, %r7531;
	xor.b32  	%r7539, %r7538, %r7532;
	add.s32 	%r7540, %r7173, %r7518;
	add.s32 	%r7541, %r7540, %r7539;
	add.s32 	%r7542, %r7541, -995338651;
	shf.l.wrap.b32 	%r7543, %r7542, %r7542, 23;
	add.s32 	%r7544, %r7543, %r7538;
	not.b32 	%r7545, %r7531;
	or.b32  	%r7546, %r7544, %r7545;
	xor.b32  	%r7547, %r7546, %r7538;
	add.s32 	%r7548, %r7181, %r7525;
	add.s32 	%r7549, %r7548, %r7547;
	add.s32 	%r7550, %r7549, -198630844;
	shf.l.wrap.b32 	%r7551, %r7550, %r7550, 6;
	add.s32 	%r7552, %r7551, %r7544;
	not.b32 	%r7553, %r7538;
	or.b32  	%r7554, %r7552, %r7553;
	xor.b32  	%r7555, %r7554, %r7544;
	add.s32 	%r7556, %r7153, %r7531;
	add.s32 	%r7557, %r7556, %r7555;
	add.s32 	%r7558, %r7557, 1126891415;
	shf.l.wrap.b32 	%r7559, %r7558, %r7558, 10;
	add.s32 	%r7560, %r7559, %r7552;
	not.b32 	%r7561, %r7544;
	or.b32  	%r7562, %r7560, %r7561;
	xor.b32  	%r7563, %r7562, %r7552;
	add.s32 	%r7564, %r7125, %r7538;
	add.s32 	%r7565, %r7564, %r7563;
	add.s32 	%r7566, %r7565, -1416354905;
	shf.l.wrap.b32 	%r7567, %r7566, %r7566, 15;
	add.s32 	%r7568, %r7567, %r7560;
	not.b32 	%r7569, %r7552;
	or.b32  	%r7570, %r7568, %r7569;
	xor.b32  	%r7571, %r7570, %r7560;
	add.s32 	%r7572, %r7161, %r7544;
	add.s32 	%r7573, %r7572, %r7571;
	add.s32 	%r7574, %r7573, -57434055;
	shf.l.wrap.b32 	%r7575, %r7574, %r7574, 21;
	add.s32 	%r7576, %r7575, %r7568;
	not.b32 	%r7577, %r7560;
	or.b32  	%r7578, %r7576, %r7577;
	xor.b32  	%r7579, %r7578, %r7568;
	add.s32 	%r7580, %r7133, %r7552;
	add.s32 	%r7581, %r7580, %r7579;
	add.s32 	%r7582, %r7581, 1700485571;
	shf.l.wrap.b32 	%r7583, %r7582, %r7582, 6;
	add.s32 	%r7584, %r7583, %r7576;
	not.b32 	%r7585, %r7568;
	or.b32  	%r7586, %r7584, %r7585;
	xor.b32  	%r7587, %r7586, %r7576;
	add.s32 	%r7588, %r7169, %r7560;
	add.s32 	%r7589, %r7588, %r7587;
	add.s32 	%r7590, %r7589, -1894986606;
	shf.l.wrap.b32 	%r7591, %r7590, %r7590, 10;
	add.s32 	%r7592, %r7591, %r7584;
	not.b32 	%r7593, %r7576;
	or.b32  	%r7594, %r7592, %r7593;
	xor.b32  	%r7595, %r7594, %r7584;
	add.s32 	%r7596, %r7141, %r7568;
	add.s32 	%r7597, %r7596, %r7595;
	add.s32 	%r7598, %r7597, -1051523;
	shf.l.wrap.b32 	%r7599, %r7598, %r7598, 15;
	add.s32 	%r7600, %r7599, %r7592;
	not.b32 	%r7601, %r7584;
	or.b32  	%r7602, %r7600, %r7601;
	xor.b32  	%r7603, %r7602, %r7592;
	add.s32 	%r7604, %r7177, %r7576;
	add.s32 	%r7605, %r7604, %r7603;
	add.s32 	%r7606, %r7605, -2054922799;
	shf.l.wrap.b32 	%r7607, %r7606, %r7606, 21;
	add.s32 	%r7608, %r7607, %r7600;
	not.b32 	%r7609, %r7592;
	or.b32  	%r7610, %r7608, %r7609;
	xor.b32  	%r7611, %r7610, %r7600;
	add.s32 	%r7612, %r7149, %r7584;
	add.s32 	%r7613, %r7612, %r7611;
	add.s32 	%r7614, %r7613, 1873313359;
	shf.l.wrap.b32 	%r7615, %r7614, %r7614, 6;
	add.s32 	%r7616, %r7615, %r7608;
	not.b32 	%r7617, %r7600;
	or.b32  	%r7618, %r7616, %r7617;
	xor.b32  	%r7619, %r7618, %r7608;
	add.s32 	%r7620, %r7121, %r7592;
	add.s32 	%r7621, %r7620, %r7619;
	add.s32 	%r7622, %r7621, -30611744;
	shf.l.wrap.b32 	%r7623, %r7622, %r7622, 10;
	add.s32 	%r7624, %r7623, %r7616;
	not.b32 	%r7625, %r7608;
	or.b32  	%r7626, %r7624, %r7625;
	xor.b32  	%r7627, %r7626, %r7616;
	add.s32 	%r7628, %r7157, %r7600;
	add.s32 	%r7629, %r7628, %r7627;
	add.s32 	%r7630, %r7629, -1560198380;
	shf.l.wrap.b32 	%r7631, %r7630, %r7630, 15;
	add.s32 	%r7632, %r7631, %r7624;
	not.b32 	%r7633, %r7616;
	or.b32  	%r7634, %r7632, %r7633;
	xor.b32  	%r7635, %r7634, %r7624;
	add.s32 	%r7636, %r7129, %r7608;
	add.s32 	%r7637, %r7636, %r7635;
	add.s32 	%r7638, %r7637, 1309151649;
	shf.l.wrap.b32 	%r7639, %r7638, %r7638, 21;
	add.s32 	%r7640, %r7639, %r7632;
	not.b32 	%r7641, %r7624;
	or.b32  	%r7642, %r7640, %r7641;
	xor.b32  	%r7643, %r7642, %r7632;
	add.s32 	%r7644, %r7165, %r7616;
	add.s32 	%r7645, %r7644, %r7643;
	add.s32 	%r7646, %r7645, -145523070;
	shf.l.wrap.b32 	%r7647, %r7646, %r7646, 6;
	add.s32 	%r7648, %r7647, %r7640;
	not.b32 	%r7649, %r7632;
	or.b32  	%r7650, %r7648, %r7649;
	xor.b32  	%r7651, %r7650, %r7640;
	add.s32 	%r7652, %r7137, %r7624;
	add.s32 	%r7653, %r7652, %r7651;
	add.s32 	%r7654, %r7653, -1120210379;
	shf.l.wrap.b32 	%r7655, %r7654, %r7654, 10;
	add.s32 	%r7656, %r7655, %r7648;
	not.b32 	%r7657, %r7640;
	or.b32  	%r7658, %r7656, %r7657;
	xor.b32  	%r7659, %r7658, %r7648;
	add.s32 	%r7660, %r7173, %r7632;
	add.s32 	%r7661, %r7660, %r7659;
	add.s32 	%r7662, %r7661, 718787259;
	shf.l.wrap.b32 	%r7663, %r7662, %r7662, 15;
	add.s32 	%r7664, %r7663, %r7656;
	not.b32 	%r7665, %r7648;
	or.b32  	%r7666, %r7664, %r7665;
	xor.b32  	%r7667, %r7666, %r7656;
	add.s32 	%r7668, %r7145, %r7640;
	add.s32 	%r7669, %r7668, %r7667;
	add.s32 	%r7670, %r7669, -343485551;
	shf.l.wrap.b32 	%r7671, %r7670, %r7670, 21;
	add.s32 	%r7, %r7648, %r7;
	add.s32 	%r7672, %r7664, %r6;
	add.s32 	%r6, %r7672, %r7671;
	add.s32 	%r5, %r7664, %r5;
	add.s32 	%r4, %r7656, %r4;
	add.s32 	%r7696, %r7696, 16;

BB3_2:
	add.s32 	%r1008, %r2, -64;
	setp.lt.s32	%p2, %r7691, %r1008;
	mul.wide.s32 	%rd24, %r7696, 4;
	add.s64 	%rd25, %rd21, %rd24;
	ld.global.nc.u32 	%r9, [%rd25];
	ld.global.nc.u32 	%r10, [%rd25+4];
	ld.global.nc.u32 	%r11, [%rd25+8];
	ld.global.nc.u32 	%r12, [%rd25+12];
	ld.global.nc.u32 	%r13, [%rd25+16];
	ld.global.nc.u32 	%r14, [%rd25+20];
	ld.global.nc.u32 	%r15, [%rd25+24];
	ld.global.nc.u32 	%r16, [%rd25+28];
	ld.global.nc.u32 	%r17, [%rd25+32];
	ld.global.nc.u32 	%r18, [%rd25+36];
	ld.global.nc.u32 	%r19, [%rd25+40];
	ld.global.nc.u32 	%r20, [%rd25+44];
	ld.global.nc.u32 	%r21, [%rd25+48];
	ld.global.nc.u32 	%r22, [%rd25+52];
	ld.global.nc.u32 	%r23, [%rd25+56];
	ld.global.nc.u32 	%r24, [%rd25+60];
	@%p2 bra 	BB3_189;

	sub.s32 	%r1009, %r2, %r7691;
	setp.lt.s32	%p3, %r1009, 64;
	@%p3 bra 	BB3_5;
	bra.uni 	BB3_4;

BB3_5:
	mov.u32 	%r1641, 30292;
	// inline asm
	prmt.b32 %r7697, %r23, %r24, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7698, %r22, %r23, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7699, %r21, %r22, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7700, %r20, %r21, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7701, %r19, %r20, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7702, %r18, %r19, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7703, %r17, %r18, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7704, %r16, %r17, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7705, %r15, %r16, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7706, %r14, %r15, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7707, %r13, %r14, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7708, %r12, %r13, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7709, %r11, %r12, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7710, %r10, %r11, %r1641;
	// inline asm
	// inline asm
	prmt.b32 %r7711, %r9, %r10, %r1641;
	// inline asm
	mov.u32 	%r1639, 0;
	// inline asm
	prmt.b32 %r7712, %r1639, %r9, %r1641;
	// inline asm
	bra.uni 	BB3_6;

BB3_4:
	mov.u32 	%r7697, 0;
	// inline asm
	shf.r.wrap.b32 %r1010, %r24, %r7697, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1014, %r23, %r24, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1018, %r22, %r23, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1022, %r21, %r22, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1026, %r20, %r21, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1030, %r19, %r20, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1034, %r18, %r19, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1038, %r17, %r18, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1042, %r16, %r17, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1046, %r15, %r16, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1050, %r14, %r15, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1054, %r13, %r14, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1058, %r12, %r13, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1062, %r11, %r12, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1066, %r10, %r11, %r7697;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1070, %r9, %r10, %r7697;
	// inline asm
	xor.b32  	%r1090, %r5, %r4;
	and.b32  	%r1091, %r6, %r1090;
	xor.b32  	%r1092, %r1091, %r4;
	add.s32 	%r1093, %r7, %r1092;
	add.s32 	%r1094, %r1093, %r1070;
	add.s32 	%r1095, %r1094, -680876936;
	shf.l.wrap.b32 	%r1096, %r1095, %r1095, 7;
	add.s32 	%r1097, %r1096, %r6;
	xor.b32  	%r1098, %r6, %r5;
	and.b32  	%r1099, %r1097, %r1098;
	xor.b32  	%r1100, %r1099, %r5;
	add.s32 	%r1101, %r4, %r1066;
	add.s32 	%r1102, %r1101, %r1100;
	add.s32 	%r1103, %r1102, -389564586;
	shf.l.wrap.b32 	%r1104, %r1103, %r1103, 12;
	add.s32 	%r1105, %r1104, %r1097;
	xor.b32  	%r1106, %r1097, %r6;
	and.b32  	%r1107, %r1105, %r1106;
	xor.b32  	%r1108, %r1107, %r6;
	add.s32 	%r1109, %r5, %r1062;
	add.s32 	%r1110, %r1109, %r1108;
	add.s32 	%r1111, %r1110, 606105819;
	shf.l.wrap.b32 	%r1112, %r1111, %r1111, 17;
	add.s32 	%r1113, %r1112, %r1105;
	xor.b32  	%r1114, %r1105, %r1097;
	and.b32  	%r1115, %r1113, %r1114;
	xor.b32  	%r1116, %r1115, %r1097;
	add.s32 	%r1117, %r6, %r1058;
	add.s32 	%r1118, %r1117, %r1116;
	add.s32 	%r1119, %r1118, -1044525330;
	shf.l.wrap.b32 	%r1120, %r1119, %r1119, 22;
	add.s32 	%r1121, %r1120, %r1113;
	xor.b32  	%r1122, %r1113, %r1105;
	and.b32  	%r1123, %r1121, %r1122;
	xor.b32  	%r1124, %r1123, %r1105;
	add.s32 	%r1125, %r1054, %r1097;
	add.s32 	%r1126, %r1125, %r1124;
	add.s32 	%r1127, %r1126, -176418897;
	shf.l.wrap.b32 	%r1128, %r1127, %r1127, 7;
	add.s32 	%r1129, %r1128, %r1121;
	xor.b32  	%r1130, %r1121, %r1113;
	and.b32  	%r1131, %r1129, %r1130;
	xor.b32  	%r1132, %r1131, %r1113;
	add.s32 	%r1133, %r1050, %r1105;
	add.s32 	%r1134, %r1133, %r1132;
	add.s32 	%r1135, %r1134, 1200080426;
	shf.l.wrap.b32 	%r1136, %r1135, %r1135, 12;
	add.s32 	%r1137, %r1136, %r1129;
	xor.b32  	%r1138, %r1129, %r1121;
	and.b32  	%r1139, %r1137, %r1138;
	xor.b32  	%r1140, %r1139, %r1121;
	add.s32 	%r1141, %r1046, %r1113;
	add.s32 	%r1142, %r1141, %r1140;
	add.s32 	%r1143, %r1142, -1473231341;
	shf.l.wrap.b32 	%r1144, %r1143, %r1143, 17;
	add.s32 	%r1145, %r1144, %r1137;
	xor.b32  	%r1146, %r1137, %r1129;
	and.b32  	%r1147, %r1145, %r1146;
	xor.b32  	%r1148, %r1147, %r1129;
	add.s32 	%r1149, %r1042, %r1121;
	add.s32 	%r1150, %r1149, %r1148;
	add.s32 	%r1151, %r1150, -45705983;
	shf.l.wrap.b32 	%r1152, %r1151, %r1151, 22;
	add.s32 	%r1153, %r1152, %r1145;
	xor.b32  	%r1154, %r1145, %r1137;
	and.b32  	%r1155, %r1153, %r1154;
	xor.b32  	%r1156, %r1155, %r1137;
	add.s32 	%r1157, %r1038, %r1129;
	add.s32 	%r1158, %r1157, %r1156;
	add.s32 	%r1159, %r1158, 1770035416;
	shf.l.wrap.b32 	%r1160, %r1159, %r1159, 7;
	add.s32 	%r1161, %r1160, %r1153;
	xor.b32  	%r1162, %r1153, %r1145;
	and.b32  	%r1163, %r1161, %r1162;
	xor.b32  	%r1164, %r1163, %r1145;
	add.s32 	%r1165, %r1034, %r1137;
	add.s32 	%r1166, %r1165, %r1164;
	add.s32 	%r1167, %r1166, -1958414417;
	shf.l.wrap.b32 	%r1168, %r1167, %r1167, 12;
	add.s32 	%r1169, %r1168, %r1161;
	xor.b32  	%r1170, %r1161, %r1153;
	and.b32  	%r1171, %r1169, %r1170;
	xor.b32  	%r1172, %r1171, %r1153;
	add.s32 	%r1173, %r1030, %r1145;
	add.s32 	%r1174, %r1173, %r1172;
	add.s32 	%r1175, %r1174, -42063;
	shf.l.wrap.b32 	%r1176, %r1175, %r1175, 17;
	add.s32 	%r1177, %r1176, %r1169;
	xor.b32  	%r1178, %r1169, %r1161;
	and.b32  	%r1179, %r1177, %r1178;
	xor.b32  	%r1180, %r1179, %r1161;
	add.s32 	%r1181, %r1026, %r1153;
	add.s32 	%r1182, %r1181, %r1180;
	add.s32 	%r1183, %r1182, -1990404162;
	shf.l.wrap.b32 	%r1184, %r1183, %r1183, 22;
	add.s32 	%r1185, %r1184, %r1177;
	xor.b32  	%r1186, %r1177, %r1169;
	and.b32  	%r1187, %r1185, %r1186;
	xor.b32  	%r1188, %r1187, %r1169;
	add.s32 	%r1189, %r1022, %r1161;
	add.s32 	%r1190, %r1189, %r1188;
	add.s32 	%r1191, %r1190, 1804603682;
	shf.l.wrap.b32 	%r1192, %r1191, %r1191, 7;
	add.s32 	%r1193, %r1192, %r1185;
	xor.b32  	%r1194, %r1185, %r1177;
	and.b32  	%r1195, %r1193, %r1194;
	xor.b32  	%r1196, %r1195, %r1177;
	add.s32 	%r1197, %r1018, %r1169;
	add.s32 	%r1198, %r1197, %r1196;
	add.s32 	%r1199, %r1198, -40341101;
	shf.l.wrap.b32 	%r1200, %r1199, %r1199, 12;
	add.s32 	%r1201, %r1200, %r1193;
	xor.b32  	%r1202, %r1193, %r1185;
	and.b32  	%r1203, %r1201, %r1202;
	xor.b32  	%r1204, %r1203, %r1185;
	add.s32 	%r1205, %r1014, %r1177;
	add.s32 	%r1206, %r1205, %r1204;
	add.s32 	%r1207, %r1206, -1502002290;
	shf.l.wrap.b32 	%r1208, %r1207, %r1207, 17;
	add.s32 	%r1209, %r1208, %r1201;
	xor.b32  	%r1210, %r1201, %r1193;
	and.b32  	%r1211, %r1209, %r1210;
	xor.b32  	%r1212, %r1211, %r1193;
	add.s32 	%r1213, %r1010, %r1185;
	add.s32 	%r1214, %r1213, %r1212;
	add.s32 	%r1215, %r1214, 1236535329;
	shf.l.wrap.b32 	%r1216, %r1215, %r1215, 22;
	add.s32 	%r1217, %r1216, %r1209;
	xor.b32  	%r1218, %r1217, %r1209;
	and.b32  	%r1219, %r1218, %r1201;
	xor.b32  	%r1220, %r1219, %r1209;
	add.s32 	%r1221, %r1066, %r1193;
	add.s32 	%r1222, %r1221, %r1220;
	add.s32 	%r1223, %r1222, -165796510;
	shf.l.wrap.b32 	%r1224, %r1223, %r1223, 5;
	add.s32 	%r1225, %r1224, %r1217;
	xor.b32  	%r1226, %r1225, %r1217;
	and.b32  	%r1227, %r1226, %r1209;
	xor.b32  	%r1228, %r1227, %r1217;
	add.s32 	%r1229, %r1046, %r1201;
	add.s32 	%r1230, %r1229, %r1228;
	add.s32 	%r1231, %r1230, -1069501632;
	shf.l.wrap.b32 	%r1232, %r1231, %r1231, 9;
	add.s32 	%r1233, %r1232, %r1225;
	xor.b32  	%r1234, %r1233, %r1225;
	and.b32  	%r1235, %r1234, %r1217;
	xor.b32  	%r1236, %r1235, %r1225;
	add.s32 	%r1237, %r1026, %r1209;
	add.s32 	%r1238, %r1237, %r1236;
	add.s32 	%r1239, %r1238, 643717713;
	shf.l.wrap.b32 	%r1240, %r1239, %r1239, 14;
	add.s32 	%r1241, %r1240, %r1233;
	xor.b32  	%r1242, %r1241, %r1233;
	and.b32  	%r1243, %r1242, %r1225;
	xor.b32  	%r1244, %r1243, %r1233;
	add.s32 	%r1245, %r1070, %r1217;
	add.s32 	%r1246, %r1245, %r1244;
	add.s32 	%r1247, %r1246, -373897302;
	shf.l.wrap.b32 	%r1248, %r1247, %r1247, 20;
	add.s32 	%r1249, %r1248, %r1241;
	xor.b32  	%r1250, %r1249, %r1241;
	and.b32  	%r1251, %r1250, %r1233;
	xor.b32  	%r1252, %r1251, %r1241;
	add.s32 	%r1253, %r1050, %r1225;
	add.s32 	%r1254, %r1253, %r1252;
	add.s32 	%r1255, %r1254, -701558691;
	shf.l.wrap.b32 	%r1256, %r1255, %r1255, 5;
	add.s32 	%r1257, %r1256, %r1249;
	xor.b32  	%r1258, %r1257, %r1249;
	and.b32  	%r1259, %r1258, %r1241;
	xor.b32  	%r1260, %r1259, %r1249;
	add.s32 	%r1261, %r1030, %r1233;
	add.s32 	%r1262, %r1261, %r1260;
	add.s32 	%r1263, %r1262, 38016083;
	shf.l.wrap.b32 	%r1264, %r1263, %r1263, 9;
	add.s32 	%r1265, %r1264, %r1257;
	xor.b32  	%r1266, %r1265, %r1257;
	and.b32  	%r1267, %r1266, %r1249;
	xor.b32  	%r1268, %r1267, %r1257;
	add.s32 	%r1269, %r1010, %r1241;
	add.s32 	%r1270, %r1269, %r1268;
	add.s32 	%r1271, %r1270, -660478335;
	shf.l.wrap.b32 	%r1272, %r1271, %r1271, 14;
	add.s32 	%r1273, %r1272, %r1265;
	xor.b32  	%r1274, %r1273, %r1265;
	and.b32  	%r1275, %r1274, %r1257;
	xor.b32  	%r1276, %r1275, %r1265;
	add.s32 	%r1277, %r1054, %r1249;
	add.s32 	%r1278, %r1277, %r1276;
	add.s32 	%r1279, %r1278, -405537848;
	shf.l.wrap.b32 	%r1280, %r1279, %r1279, 20;
	add.s32 	%r1281, %r1280, %r1273;
	xor.b32  	%r1282, %r1281, %r1273;
	and.b32  	%r1283, %r1282, %r1265;
	xor.b32  	%r1284, %r1283, %r1273;
	add.s32 	%r1285, %r1034, %r1257;
	add.s32 	%r1286, %r1285, %r1284;
	add.s32 	%r1287, %r1286, 568446438;
	shf.l.wrap.b32 	%r1288, %r1287, %r1287, 5;
	add.s32 	%r1289, %r1288, %r1281;
	xor.b32  	%r1290, %r1289, %r1281;
	and.b32  	%r1291, %r1290, %r1273;
	xor.b32  	%r1292, %r1291, %r1281;
	add.s32 	%r1293, %r1014, %r1265;
	add.s32 	%r1294, %r1293, %r1292;
	add.s32 	%r1295, %r1294, -1019803690;
	shf.l.wrap.b32 	%r1296, %r1295, %r1295, 9;
	add.s32 	%r1297, %r1296, %r1289;
	xor.b32  	%r1298, %r1297, %r1289;
	and.b32  	%r1299, %r1298, %r1281;
	xor.b32  	%r1300, %r1299, %r1289;
	add.s32 	%r1301, %r1058, %r1273;
	add.s32 	%r1302, %r1301, %r1300;
	add.s32 	%r1303, %r1302, -187363961;
	shf.l.wrap.b32 	%r1304, %r1303, %r1303, 14;
	add.s32 	%r1305, %r1304, %r1297;
	xor.b32  	%r1306, %r1305, %r1297;
	and.b32  	%r1307, %r1306, %r1289;
	xor.b32  	%r1308, %r1307, %r1297;
	add.s32 	%r1309, %r1038, %r1281;
	add.s32 	%r1310, %r1309, %r1308;
	add.s32 	%r1311, %r1310, 1163531501;
	shf.l.wrap.b32 	%r1312, %r1311, %r1311, 20;
	add.s32 	%r1313, %r1312, %r1305;
	xor.b32  	%r1314, %r1313, %r1305;
	and.b32  	%r1315, %r1314, %r1297;
	xor.b32  	%r1316, %r1315, %r1305;
	add.s32 	%r1317, %r1018, %r1289;
	add.s32 	%r1318, %r1317, %r1316;
	add.s32 	%r1319, %r1318, -1444681467;
	shf.l.wrap.b32 	%r1320, %r1319, %r1319, 5;
	add.s32 	%r1321, %r1320, %r1313;
	xor.b32  	%r1322, %r1321, %r1313;
	and.b32  	%r1323, %r1322, %r1305;
	xor.b32  	%r1324, %r1323, %r1313;
	add.s32 	%r1325, %r1062, %r1297;
	add.s32 	%r1326, %r1325, %r1324;
	add.s32 	%r1327, %r1326, -51403784;
	shf.l.wrap.b32 	%r1328, %r1327, %r1327, 9;
	add.s32 	%r1329, %r1328, %r1321;
	xor.b32  	%r1330, %r1329, %r1321;
	and.b32  	%r1331, %r1330, %r1313;
	xor.b32  	%r1332, %r1331, %r1321;
	add.s32 	%r1333, %r1042, %r1305;
	add.s32 	%r1334, %r1333, %r1332;
	add.s32 	%r1335, %r1334, 1735328473;
	shf.l.wrap.b32 	%r1336, %r1335, %r1335, 14;
	add.s32 	%r1337, %r1336, %r1329;
	xor.b32  	%r1338, %r1337, %r1329;
	and.b32  	%r1339, %r1338, %r1321;
	xor.b32  	%r1340, %r1339, %r1329;
	add.s32 	%r1341, %r1022, %r1313;
	add.s32 	%r1342, %r1341, %r1340;
	add.s32 	%r1343, %r1342, -1926607734;
	shf.l.wrap.b32 	%r1344, %r1343, %r1343, 20;
	add.s32 	%r1345, %r1344, %r1337;
	xor.b32  	%r1346, %r1345, %r1337;
	xor.b32  	%r1347, %r1346, %r1329;
	add.s32 	%r1348, %r1050, %r1321;
	add.s32 	%r1349, %r1348, %r1347;
	add.s32 	%r1350, %r1349, -378558;
	shf.l.wrap.b32 	%r1351, %r1350, %r1350, 4;
	add.s32 	%r1352, %r1351, %r1345;
	xor.b32  	%r1353, %r1352, %r1346;
	add.s32 	%r1354, %r1038, %r1329;
	add.s32 	%r1355, %r1354, %r1353;
	add.s32 	%r1356, %r1355, -2022574463;
	shf.l.wrap.b32 	%r1357, %r1356, %r1356, 11;
	add.s32 	%r1358, %r1357, %r1352;
	xor.b32  	%r1359, %r1358, %r1352;
	xor.b32  	%r1360, %r1359, %r1345;
	add.s32 	%r1361, %r1026, %r1337;
	add.s32 	%r1362, %r1361, %r1360;
	add.s32 	%r1363, %r1362, 1839030562;
	shf.l.wrap.b32 	%r1364, %r1363, %r1363, 16;
	add.s32 	%r1365, %r1364, %r1358;
	xor.b32  	%r1366, %r1365, %r1359;
	add.s32 	%r1367, %r1014, %r1345;
	add.s32 	%r1368, %r1367, %r1366;
	add.s32 	%r1369, %r1368, -35309556;
	shf.l.wrap.b32 	%r1370, %r1369, %r1369, 23;
	add.s32 	%r1371, %r1370, %r1365;
	xor.b32  	%r1372, %r1371, %r1365;
	xor.b32  	%r1373, %r1372, %r1358;
	add.s32 	%r1374, %r1066, %r1352;
	add.s32 	%r1375, %r1374, %r1373;
	add.s32 	%r1376, %r1375, -1530992060;
	shf.l.wrap.b32 	%r1377, %r1376, %r1376, 4;
	add.s32 	%r1378, %r1377, %r1371;
	xor.b32  	%r1379, %r1378, %r1372;
	add.s32 	%r1380, %r1054, %r1358;
	add.s32 	%r1381, %r1380, %r1379;
	add.s32 	%r1382, %r1381, 1272893353;
	shf.l.wrap.b32 	%r1383, %r1382, %r1382, 11;
	add.s32 	%r1384, %r1383, %r1378;
	xor.b32  	%r1385, %r1384, %r1378;
	xor.b32  	%r1386, %r1385, %r1371;
	add.s32 	%r1387, %r1042, %r1365;
	add.s32 	%r1388, %r1387, %r1386;
	add.s32 	%r1389, %r1388, -155497632;
	shf.l.wrap.b32 	%r1390, %r1389, %r1389, 16;
	add.s32 	%r1391, %r1390, %r1384;
	xor.b32  	%r1392, %r1391, %r1385;
	add.s32 	%r1393, %r1030, %r1371;
	add.s32 	%r1394, %r1393, %r1392;
	add.s32 	%r1395, %r1394, -1094730640;
	shf.l.wrap.b32 	%r1396, %r1395, %r1395, 23;
	add.s32 	%r1397, %r1396, %r1391;
	xor.b32  	%r1398, %r1397, %r1391;
	xor.b32  	%r1399, %r1398, %r1384;
	add.s32 	%r1400, %r1018, %r1378;
	add.s32 	%r1401, %r1400, %r1399;
	add.s32 	%r1402, %r1401, 681279174;
	shf.l.wrap.b32 	%r1403, %r1402, %r1402, 4;
	add.s32 	%r1404, %r1403, %r1397;
	xor.b32  	%r1405, %r1404, %r1398;
	add.s32 	%r1406, %r1070, %r1384;
	add.s32 	%r1407, %r1406, %r1405;
	add.s32 	%r1408, %r1407, -358537222;
	shf.l.wrap.b32 	%r1409, %r1408, %r1408, 11;
	add.s32 	%r1410, %r1409, %r1404;
	xor.b32  	%r1411, %r1410, %r1404;
	xor.b32  	%r1412, %r1411, %r1397;
	add.s32 	%r1413, %r1058, %r1391;
	add.s32 	%r1414, %r1413, %r1412;
	add.s32 	%r1415, %r1414, -722521979;
	shf.l.wrap.b32 	%r1416, %r1415, %r1415, 16;
	add.s32 	%r1417, %r1416, %r1410;
	xor.b32  	%r1418, %r1417, %r1411;
	add.s32 	%r1419, %r1046, %r1397;
	add.s32 	%r1420, %r1419, %r1418;
	add.s32 	%r1421, %r1420, 76029189;
	shf.l.wrap.b32 	%r1422, %r1421, %r1421, 23;
	add.s32 	%r1423, %r1422, %r1417;
	xor.b32  	%r1424, %r1423, %r1417;
	xor.b32  	%r1425, %r1424, %r1410;
	add.s32 	%r1426, %r1034, %r1404;
	add.s32 	%r1427, %r1426, %r1425;
	add.s32 	%r1428, %r1427, -640364487;
	shf.l.wrap.b32 	%r1429, %r1428, %r1428, 4;
	add.s32 	%r1430, %r1429, %r1423;
	xor.b32  	%r1431, %r1430, %r1424;
	add.s32 	%r1432, %r1022, %r1410;
	add.s32 	%r1433, %r1432, %r1431;
	add.s32 	%r1434, %r1433, -421815835;
	shf.l.wrap.b32 	%r1435, %r1434, %r1434, 11;
	add.s32 	%r1436, %r1435, %r1430;
	xor.b32  	%r1437, %r1436, %r1430;
	xor.b32  	%r1438, %r1437, %r1423;
	add.s32 	%r1439, %r1010, %r1417;
	add.s32 	%r1440, %r1439, %r1438;
	add.s32 	%r1441, %r1440, 530742520;
	shf.l.wrap.b32 	%r1442, %r1441, %r1441, 16;
	add.s32 	%r1443, %r1442, %r1436;
	xor.b32  	%r1444, %r1443, %r1437;
	add.s32 	%r1445, %r1062, %r1423;
	add.s32 	%r1446, %r1445, %r1444;
	add.s32 	%r1447, %r1446, -995338651;
	shf.l.wrap.b32 	%r1448, %r1447, %r1447, 23;
	add.s32 	%r1449, %r1448, %r1443;
	not.b32 	%r1450, %r1436;
	or.b32  	%r1451, %r1449, %r1450;
	xor.b32  	%r1452, %r1451, %r1443;
	add.s32 	%r1453, %r1070, %r1430;
	add.s32 	%r1454, %r1453, %r1452;
	add.s32 	%r1455, %r1454, -198630844;
	shf.l.wrap.b32 	%r1456, %r1455, %r1455, 6;
	add.s32 	%r1457, %r1456, %r1449;
	not.b32 	%r1458, %r1443;
	or.b32  	%r1459, %r1457, %r1458;
	xor.b32  	%r1460, %r1459, %r1449;
	add.s32 	%r1461, %r1042, %r1436;
	add.s32 	%r1462, %r1461, %r1460;
	add.s32 	%r1463, %r1462, 1126891415;
	shf.l.wrap.b32 	%r1464, %r1463, %r1463, 10;
	add.s32 	%r1465, %r1464, %r1457;
	not.b32 	%r1466, %r1449;
	or.b32  	%r1467, %r1465, %r1466;
	xor.b32  	%r1468, %r1467, %r1457;
	add.s32 	%r1469, %r1014, %r1443;
	add.s32 	%r1470, %r1469, %r1468;
	add.s32 	%r1471, %r1470, -1416354905;
	shf.l.wrap.b32 	%r1472, %r1471, %r1471, 15;
	add.s32 	%r1473, %r1472, %r1465;
	not.b32 	%r1474, %r1457;
	or.b32  	%r1475, %r1473, %r1474;
	xor.b32  	%r1476, %r1475, %r1465;
	add.s32 	%r1477, %r1050, %r1449;
	add.s32 	%r1478, %r1477, %r1476;
	add.s32 	%r1479, %r1478, -57434055;
	shf.l.wrap.b32 	%r1480, %r1479, %r1479, 21;
	add.s32 	%r1481, %r1480, %r1473;
	not.b32 	%r1482, %r1465;
	or.b32  	%r1483, %r1481, %r1482;
	xor.b32  	%r1484, %r1483, %r1473;
	add.s32 	%r1485, %r1022, %r1457;
	add.s32 	%r1486, %r1485, %r1484;
	add.s32 	%r1487, %r1486, 1700485571;
	shf.l.wrap.b32 	%r1488, %r1487, %r1487, 6;
	add.s32 	%r1489, %r1488, %r1481;
	not.b32 	%r1490, %r1473;
	or.b32  	%r1491, %r1489, %r1490;
	xor.b32  	%r1492, %r1491, %r1481;
	add.s32 	%r1493, %r1058, %r1465;
	add.s32 	%r1494, %r1493, %r1492;
	add.s32 	%r1495, %r1494, -1894986606;
	shf.l.wrap.b32 	%r1496, %r1495, %r1495, 10;
	add.s32 	%r1497, %r1496, %r1489;
	not.b32 	%r1498, %r1481;
	or.b32  	%r1499, %r1497, %r1498;
	xor.b32  	%r1500, %r1499, %r1489;
	add.s32 	%r1501, %r1030, %r1473;
	add.s32 	%r1502, %r1501, %r1500;
	add.s32 	%r1503, %r1502, -1051523;
	shf.l.wrap.b32 	%r1504, %r1503, %r1503, 15;
	add.s32 	%r1505, %r1504, %r1497;
	not.b32 	%r1506, %r1489;
	or.b32  	%r1507, %r1505, %r1506;
	xor.b32  	%r1508, %r1507, %r1497;
	add.s32 	%r1509, %r1066, %r1481;
	add.s32 	%r1510, %r1509, %r1508;
	add.s32 	%r1511, %r1510, -2054922799;
	shf.l.wrap.b32 	%r1512, %r1511, %r1511, 21;
	add.s32 	%r1513, %r1512, %r1505;
	not.b32 	%r1514, %r1497;
	or.b32  	%r1515, %r1513, %r1514;
	xor.b32  	%r1516, %r1515, %r1505;
	add.s32 	%r1517, %r1038, %r1489;
	add.s32 	%r1518, %r1517, %r1516;
	add.s32 	%r1519, %r1518, 1873313359;
	shf.l.wrap.b32 	%r1520, %r1519, %r1519, 6;
	add.s32 	%r1521, %r1520, %r1513;
	not.b32 	%r1522, %r1505;
	or.b32  	%r1523, %r1521, %r1522;
	xor.b32  	%r1524, %r1523, %r1513;
	add.s32 	%r1525, %r1010, %r1497;
	add.s32 	%r1526, %r1525, %r1524;
	add.s32 	%r1527, %r1526, -30611744;
	shf.l.wrap.b32 	%r1528, %r1527, %r1527, 10;
	add.s32 	%r1529, %r1528, %r1521;
	not.b32 	%r1530, %r1513;
	or.b32  	%r1531, %r1529, %r1530;
	xor.b32  	%r1532, %r1531, %r1521;
	add.s32 	%r1533, %r1046, %r1505;
	add.s32 	%r1534, %r1533, %r1532;
	add.s32 	%r1535, %r1534, -1560198380;
	shf.l.wrap.b32 	%r1536, %r1535, %r1535, 15;
	add.s32 	%r1537, %r1536, %r1529;
	not.b32 	%r1538, %r1521;
	or.b32  	%r1539, %r1537, %r1538;
	xor.b32  	%r1540, %r1539, %r1529;
	add.s32 	%r1541, %r1018, %r1513;
	add.s32 	%r1542, %r1541, %r1540;
	add.s32 	%r1543, %r1542, 1309151649;
	shf.l.wrap.b32 	%r1544, %r1543, %r1543, 21;
	add.s32 	%r1545, %r1544, %r1537;
	not.b32 	%r1546, %r1529;
	or.b32  	%r1547, %r1545, %r1546;
	xor.b32  	%r1548, %r1547, %r1537;
	add.s32 	%r1549, %r1054, %r1521;
	add.s32 	%r1550, %r1549, %r1548;
	add.s32 	%r1551, %r1550, -145523070;
	shf.l.wrap.b32 	%r1552, %r1551, %r1551, 6;
	add.s32 	%r1553, %r1552, %r1545;
	not.b32 	%r1554, %r1537;
	or.b32  	%r1555, %r1553, %r1554;
	xor.b32  	%r1556, %r1555, %r1545;
	add.s32 	%r1557, %r1026, %r1529;
	add.s32 	%r1558, %r1557, %r1556;
	add.s32 	%r1559, %r1558, -1120210379;
	shf.l.wrap.b32 	%r1560, %r1559, %r1559, 10;
	add.s32 	%r1561, %r1560, %r1553;
	not.b32 	%r1562, %r1545;
	or.b32  	%r1563, %r1561, %r1562;
	xor.b32  	%r1564, %r1563, %r1553;
	add.s32 	%r1565, %r1062, %r1537;
	add.s32 	%r1566, %r1565, %r1564;
	add.s32 	%r1567, %r1566, 718787259;
	shf.l.wrap.b32 	%r1568, %r1567, %r1567, 15;
	add.s32 	%r1569, %r1568, %r1561;
	not.b32 	%r1570, %r1553;
	or.b32  	%r1571, %r1569, %r1570;
	xor.b32  	%r1572, %r1571, %r1561;
	add.s32 	%r1573, %r1034, %r1545;
	add.s32 	%r1574, %r1573, %r1572;
	add.s32 	%r1575, %r1574, -343485551;
	shf.l.wrap.b32 	%r1576, %r1575, %r1575, 21;
	add.s32 	%r7, %r1553, %r7;
	add.s32 	%r1577, %r1569, %r6;
	add.s32 	%r6, %r1577, %r1576;
	add.s32 	%r5, %r1569, %r5;
	add.s32 	%r4, %r1561, %r4;
	mov.u32 	%r7698, %r7697;
	mov.u32 	%r7699, %r7697;
	mov.u32 	%r7700, %r7697;
	mov.u32 	%r7701, %r7697;
	mov.u32 	%r7702, %r7697;
	mov.u32 	%r7703, %r7697;
	mov.u32 	%r7704, %r7697;
	mov.u32 	%r7705, %r7697;
	mov.u32 	%r7706, %r7697;
	mov.u32 	%r7707, %r7697;
	mov.u32 	%r7708, %r7697;
	mov.u32 	%r7709, %r7697;
	mov.u32 	%r7710, %r7697;
	mov.u32 	%r7711, %r7697;
	mov.u32 	%r7712, %r7697;

BB3_6:
	ld.param.u32 	%r7687, [m00000_mxx_param_30];
	setp.eq.s32	%p4, %r7687, 0;
	@%p4 bra 	BB3_141;

	ld.param.u32 	%r7690, [m00000_mxx_param_32];
	ld.param.u32 	%r7689, [m00000_mxx_param_26];
	ld.param.u32 	%r7688, [m00000_mxx_param_25];
	and.b32  	%r66, %r7688, 31;
	and.b32  	%r67, %r7689, 31;
	cvt.u64.u32	%rd2, %r7690;
	mov.u32 	%r7717, 0;

BB3_8:
	mov.u32 	%r7739, 0;
	mul.wide.u32 	%rd26, %r7717, 260;
	add.s64 	%rd27, %rd6, %rd26;
	ld.global.nc.u32 	%r1645, [%rd27+256];
	and.b32  	%r69, %r1645, 255;
	mov.u32 	%r7718, %r2;
	mov.u32 	%r7835, %r7697;
	mov.u32 	%r7836, %r7698;
	mov.u32 	%r7837, %r7699;
	mov.u32 	%r7838, %r7700;
	mov.u32 	%r7831, %r7701;
	mov.u32 	%r7832, %r7702;
	mov.u32 	%r7833, %r7703;
	mov.u32 	%r7834, %r7704;
	mov.u32 	%r7862, %r7705;
	mov.u32 	%r7861, %r7706;
	mov.u32 	%r7860, %r7707;
	mov.u32 	%r7859, %r7708;
	mov.u32 	%r7855, %r7709;
	mov.u32 	%r7856, %r7710;
	mov.u32 	%r7857, %r7711;
	mov.u32 	%r7858, %r7712;
	mov.u32 	%r87, %r4;
	mov.u32 	%r88, %r5;
	mov.u32 	%r89, %r6;
	mov.u32 	%r90, %r7;
	mov.u32 	%r7740, %r7739;
	bra.uni 	BB3_9;

BB3_188:
	xor.b32  	%r6617, %r88, %r87;
	and.b32  	%r6618, %r89, %r6617;
	xor.b32  	%r6619, %r6618, %r87;
	add.s32 	%r6620, %r90, %r6619;
	or.b32  	%r6621, %r93, %r86;
	add.s32 	%r6622, %r6620, %r6621;
	add.s32 	%r6623, %r6622, -680876936;
	shf.l.wrap.b32 	%r6624, %r6623, %r6623, 7;
	add.s32 	%r6625, %r6624, %r89;
	xor.b32  	%r6626, %r89, %r88;
	and.b32  	%r6627, %r6625, %r6626;
	xor.b32  	%r6628, %r6627, %r88;
	or.b32  	%r6629, %r94, %r85;
	add.s32 	%r6630, %r87, %r6629;
	add.s32 	%r6631, %r6630, %r6628;
	add.s32 	%r6632, %r6631, -389564586;
	shf.l.wrap.b32 	%r6633, %r6632, %r6632, 12;
	add.s32 	%r6634, %r6633, %r6625;
	xor.b32  	%r6635, %r6625, %r89;
	and.b32  	%r6636, %r6634, %r6635;
	xor.b32  	%r6637, %r6636, %r89;
	or.b32  	%r6638, %r95, %r84;
	add.s32 	%r6639, %r88, %r6638;
	add.s32 	%r6640, %r6639, %r6637;
	add.s32 	%r6641, %r6640, 606105819;
	shf.l.wrap.b32 	%r6642, %r6641, %r6641, 17;
	add.s32 	%r6643, %r6642, %r6634;
	xor.b32  	%r6644, %r6634, %r6625;
	and.b32  	%r6645, %r6643, %r6644;
	xor.b32  	%r6646, %r6645, %r6625;
	or.b32  	%r6647, %r7839, %r83;
	add.s32 	%r6648, %r89, %r6647;
	add.s32 	%r6649, %r6648, %r6646;
	add.s32 	%r6650, %r6649, -1044525330;
	shf.l.wrap.b32 	%r6651, %r6650, %r6650, 22;
	add.s32 	%r6652, %r6651, %r6643;
	xor.b32  	%r6653, %r6643, %r6634;
	and.b32  	%r6654, %r6652, %r6653;
	xor.b32  	%r6655, %r6654, %r6634;
	or.b32  	%r6656, %r97, %r82;
	add.s32 	%r6657, %r6656, %r6625;
	add.s32 	%r6658, %r6657, %r6655;
	add.s32 	%r6659, %r6658, -176418897;
	shf.l.wrap.b32 	%r6660, %r6659, %r6659, 7;
	add.s32 	%r6661, %r6660, %r6652;
	xor.b32  	%r6662, %r6652, %r6643;
	and.b32  	%r6663, %r6661, %r6662;
	xor.b32  	%r6664, %r6663, %r6643;
	or.b32  	%r6665, %r98, %r81;
	add.s32 	%r6666, %r6665, %r6634;
	add.s32 	%r6667, %r6666, %r6664;
	add.s32 	%r6668, %r6667, 1200080426;
	shf.l.wrap.b32 	%r6669, %r6668, %r6668, 12;
	add.s32 	%r6670, %r6669, %r6661;
	xor.b32  	%r6671, %r6661, %r6652;
	and.b32  	%r6672, %r6670, %r6671;
	xor.b32  	%r6673, %r6672, %r6652;
	or.b32  	%r6674, %r99, %r80;
	add.s32 	%r6675, %r6674, %r6643;
	add.s32 	%r6676, %r6675, %r6673;
	add.s32 	%r6677, %r6676, -1473231341;
	shf.l.wrap.b32 	%r6678, %r6677, %r6677, 17;
	add.s32 	%r6679, %r6678, %r6670;
	xor.b32  	%r6680, %r6670, %r6661;
	and.b32  	%r6681, %r6679, %r6680;
	xor.b32  	%r6682, %r6681, %r6661;
	or.b32  	%r6683, %r100, %r79;
	add.s32 	%r6684, %r6683, %r6652;
	add.s32 	%r6685, %r6684, %r6682;
	add.s32 	%r6686, %r6685, -45705983;
	shf.l.wrap.b32 	%r6687, %r6686, %r6686, 22;
	add.s32 	%r6688, %r6687, %r6679;
	xor.b32  	%r6689, %r6679, %r6670;
	and.b32  	%r6690, %r6688, %r6689;
	xor.b32  	%r6691, %r6690, %r6670;
	or.b32  	%r6692, %r101, %r78;
	add.s32 	%r6693, %r6692, %r6661;
	add.s32 	%r6694, %r6693, %r6691;
	add.s32 	%r6695, %r6694, 1770035416;
	shf.l.wrap.b32 	%r6696, %r6695, %r6695, 7;
	add.s32 	%r6697, %r6696, %r6688;
	xor.b32  	%r6698, %r6688, %r6679;
	and.b32  	%r6699, %r6697, %r6698;
	xor.b32  	%r6700, %r6699, %r6679;
	or.b32  	%r6701, %r102, %r77;
	add.s32 	%r6702, %r6701, %r6670;
	add.s32 	%r6703, %r6702, %r6700;
	add.s32 	%r6704, %r6703, -1958414417;
	shf.l.wrap.b32 	%r6705, %r6704, %r6704, 12;
	add.s32 	%r6706, %r6705, %r6697;
	xor.b32  	%r6707, %r6697, %r6688;
	and.b32  	%r6708, %r6706, %r6707;
	xor.b32  	%r6709, %r6708, %r6688;
	or.b32  	%r6710, %r103, %r76;
	add.s32 	%r6711, %r6710, %r6679;
	add.s32 	%r6712, %r6711, %r6709;
	add.s32 	%r6713, %r6712, -42063;
	shf.l.wrap.b32 	%r6714, %r6713, %r6713, 17;
	add.s32 	%r6715, %r6714, %r6706;
	xor.b32  	%r6716, %r6706, %r6697;
	and.b32  	%r6717, %r6715, %r6716;
	xor.b32  	%r6718, %r6717, %r6697;
	or.b32  	%r6719, %r104, %r75;
	add.s32 	%r6720, %r6719, %r6688;
	add.s32 	%r6721, %r6720, %r6718;
	add.s32 	%r6722, %r6721, -1990404162;
	shf.l.wrap.b32 	%r6723, %r6722, %r6722, 22;
	add.s32 	%r6724, %r6723, %r6715;
	xor.b32  	%r6725, %r6715, %r6706;
	and.b32  	%r6726, %r6724, %r6725;
	xor.b32  	%r6727, %r6726, %r6706;
	or.b32  	%r6728, %r105, %r74;
	add.s32 	%r6729, %r6728, %r6697;
	add.s32 	%r6730, %r6729, %r6727;
	add.s32 	%r6731, %r6730, 1804603682;
	shf.l.wrap.b32 	%r6732, %r6731, %r6731, 7;
	add.s32 	%r6733, %r6732, %r6724;
	xor.b32  	%r6734, %r6724, %r6715;
	and.b32  	%r6735, %r6733, %r6734;
	xor.b32  	%r6736, %r6735, %r6715;
	or.b32  	%r6737, %r106, %r73;
	add.s32 	%r6738, %r6737, %r6706;
	add.s32 	%r6739, %r6738, %r6736;
	add.s32 	%r6740, %r6739, -40341101;
	shf.l.wrap.b32 	%r6741, %r6740, %r6740, 12;
	add.s32 	%r6742, %r6741, %r6733;
	xor.b32  	%r6743, %r6733, %r6724;
	and.b32  	%r6744, %r6742, %r6743;
	xor.b32  	%r6745, %r6744, %r6724;
	or.b32  	%r6746, %r107, %r72;
	add.s32 	%r6747, %r6746, %r6715;
	add.s32 	%r6748, %r6747, %r6745;
	add.s32 	%r6749, %r6748, -1502002290;
	shf.l.wrap.b32 	%r6750, %r6749, %r6749, 17;
	add.s32 	%r6751, %r6750, %r6742;
	xor.b32  	%r6752, %r6742, %r6733;
	and.b32  	%r6753, %r6751, %r6752;
	xor.b32  	%r6754, %r6753, %r6733;
	or.b32  	%r6755, %r108, %r71;
	add.s32 	%r6756, %r6755, %r6724;
	add.s32 	%r6757, %r6756, %r6754;
	add.s32 	%r6758, %r6757, 1236535329;
	shf.l.wrap.b32 	%r6759, %r6758, %r6758, 22;
	add.s32 	%r6760, %r6759, %r6751;
	xor.b32  	%r6761, %r6760, %r6751;
	and.b32  	%r6762, %r6761, %r6742;
	xor.b32  	%r6763, %r6762, %r6751;
	add.s32 	%r6764, %r6629, %r6733;
	add.s32 	%r6765, %r6764, %r6763;
	add.s32 	%r6766, %r6765, -165796510;
	shf.l.wrap.b32 	%r6767, %r6766, %r6766, 5;
	add.s32 	%r6768, %r6767, %r6760;
	xor.b32  	%r6769, %r6768, %r6760;
	and.b32  	%r6770, %r6769, %r6751;
	xor.b32  	%r6771, %r6770, %r6760;
	add.s32 	%r6772, %r6674, %r6742;
	add.s32 	%r6773, %r6772, %r6771;
	add.s32 	%r6774, %r6773, -1069501632;
	shf.l.wrap.b32 	%r6775, %r6774, %r6774, 9;
	add.s32 	%r6776, %r6775, %r6768;
	xor.b32  	%r6777, %r6776, %r6768;
	and.b32  	%r6778, %r6777, %r6760;
	xor.b32  	%r6779, %r6778, %r6768;
	add.s32 	%r6780, %r6719, %r6751;
	add.s32 	%r6781, %r6780, %r6779;
	add.s32 	%r6782, %r6781, 643717713;
	shf.l.wrap.b32 	%r6783, %r6782, %r6782, 14;
	add.s32 	%r6784, %r6783, %r6776;
	xor.b32  	%r6785, %r6784, %r6776;
	and.b32  	%r6786, %r6785, %r6768;
	xor.b32  	%r6787, %r6786, %r6776;
	add.s32 	%r6788, %r6621, %r6760;
	add.s32 	%r6789, %r6788, %r6787;
	add.s32 	%r6790, %r6789, -373897302;
	shf.l.wrap.b32 	%r6791, %r6790, %r6790, 20;
	add.s32 	%r6792, %r6791, %r6784;
	xor.b32  	%r6793, %r6792, %r6784;
	and.b32  	%r6794, %r6793, %r6776;
	xor.b32  	%r6795, %r6794, %r6784;
	add.s32 	%r6796, %r6665, %r6768;
	add.s32 	%r6797, %r6796, %r6795;
	add.s32 	%r6798, %r6797, -701558691;
	shf.l.wrap.b32 	%r6799, %r6798, %r6798, 5;
	add.s32 	%r6800, %r6799, %r6792;
	xor.b32  	%r6801, %r6800, %r6792;
	and.b32  	%r6802, %r6801, %r6784;
	xor.b32  	%r6803, %r6802, %r6792;
	add.s32 	%r6804, %r6710, %r6776;
	add.s32 	%r6805, %r6804, %r6803;
	add.s32 	%r6806, %r6805, 38016083;
	shf.l.wrap.b32 	%r6807, %r6806, %r6806, 9;
	add.s32 	%r6808, %r6807, %r6800;
	xor.b32  	%r6809, %r6808, %r6800;
	and.b32  	%r6810, %r6809, %r6792;
	xor.b32  	%r6811, %r6810, %r6800;
	add.s32 	%r6812, %r6755, %r6784;
	add.s32 	%r6813, %r6812, %r6811;
	add.s32 	%r6814, %r6813, -660478335;
	shf.l.wrap.b32 	%r6815, %r6814, %r6814, 14;
	add.s32 	%r6816, %r6815, %r6808;
	xor.b32  	%r6817, %r6816, %r6808;
	and.b32  	%r6818, %r6817, %r6800;
	xor.b32  	%r6819, %r6818, %r6808;
	add.s32 	%r6820, %r6656, %r6792;
	add.s32 	%r6821, %r6820, %r6819;
	add.s32 	%r6822, %r6821, -405537848;
	shf.l.wrap.b32 	%r6823, %r6822, %r6822, 20;
	add.s32 	%r6824, %r6823, %r6816;
	xor.b32  	%r6825, %r6824, %r6816;
	and.b32  	%r6826, %r6825, %r6808;
	xor.b32  	%r6827, %r6826, %r6816;
	add.s32 	%r6828, %r6701, %r6800;
	add.s32 	%r6829, %r6828, %r6827;
	add.s32 	%r6830, %r6829, 568446438;
	shf.l.wrap.b32 	%r6831, %r6830, %r6830, 5;
	add.s32 	%r6832, %r6831, %r6824;
	xor.b32  	%r6833, %r6832, %r6824;
	and.b32  	%r6834, %r6833, %r6816;
	xor.b32  	%r6835, %r6834, %r6824;
	add.s32 	%r6836, %r6746, %r6808;
	add.s32 	%r6837, %r6836, %r6835;
	add.s32 	%r6838, %r6837, -1019803690;
	shf.l.wrap.b32 	%r6839, %r6838, %r6838, 9;
	add.s32 	%r6840, %r6839, %r6832;
	xor.b32  	%r6841, %r6840, %r6832;
	and.b32  	%r6842, %r6841, %r6824;
	xor.b32  	%r6843, %r6842, %r6832;
	add.s32 	%r6844, %r6647, %r6816;
	add.s32 	%r6845, %r6844, %r6843;
	add.s32 	%r6846, %r6845, -187363961;
	shf.l.wrap.b32 	%r6847, %r6846, %r6846, 14;
	add.s32 	%r6848, %r6847, %r6840;
	xor.b32  	%r6849, %r6848, %r6840;
	and.b32  	%r6850, %r6849, %r6832;
	xor.b32  	%r6851, %r6850, %r6840;
	add.s32 	%r6852, %r6692, %r6824;
	add.s32 	%r6853, %r6852, %r6851;
	add.s32 	%r6854, %r6853, 1163531501;
	shf.l.wrap.b32 	%r6855, %r6854, %r6854, 20;
	add.s32 	%r6856, %r6855, %r6848;
	xor.b32  	%r6857, %r6856, %r6848;
	and.b32  	%r6858, %r6857, %r6840;
	xor.b32  	%r6859, %r6858, %r6848;
	add.s32 	%r6860, %r6737, %r6832;
	add.s32 	%r6861, %r6860, %r6859;
	add.s32 	%r6862, %r6861, -1444681467;
	shf.l.wrap.b32 	%r6863, %r6862, %r6862, 5;
	add.s32 	%r6864, %r6863, %r6856;
	xor.b32  	%r6865, %r6864, %r6856;
	and.b32  	%r6866, %r6865, %r6848;
	xor.b32  	%r6867, %r6866, %r6856;
	add.s32 	%r6868, %r6638, %r6840;
	add.s32 	%r6869, %r6868, %r6867;
	add.s32 	%r6870, %r6869, -51403784;
	shf.l.wrap.b32 	%r6871, %r6870, %r6870, 9;
	add.s32 	%r6872, %r6871, %r6864;
	xor.b32  	%r6873, %r6872, %r6864;
	and.b32  	%r6874, %r6873, %r6856;
	xor.b32  	%r6875, %r6874, %r6864;
	add.s32 	%r6876, %r6683, %r6848;
	add.s32 	%r6877, %r6876, %r6875;
	add.s32 	%r6878, %r6877, 1735328473;
	shf.l.wrap.b32 	%r6879, %r6878, %r6878, 14;
	add.s32 	%r6880, %r6879, %r6872;
	xor.b32  	%r6881, %r6880, %r6872;
	and.b32  	%r6882, %r6881, %r6864;
	xor.b32  	%r6883, %r6882, %r6872;
	add.s32 	%r6884, %r6728, %r6856;
	add.s32 	%r6885, %r6884, %r6883;
	add.s32 	%r6886, %r6885, -1926607734;
	shf.l.wrap.b32 	%r6887, %r6886, %r6886, 20;
	add.s32 	%r6888, %r6887, %r6880;
	xor.b32  	%r6889, %r6888, %r6880;
	xor.b32  	%r6890, %r6889, %r6872;
	add.s32 	%r6891, %r6665, %r6864;
	add.s32 	%r6892, %r6891, %r6890;
	add.s32 	%r6893, %r6892, -378558;
	shf.l.wrap.b32 	%r6894, %r6893, %r6893, 4;
	add.s32 	%r6895, %r6894, %r6888;
	xor.b32  	%r6896, %r6895, %r6889;
	add.s32 	%r6897, %r6692, %r6872;
	add.s32 	%r6898, %r6897, %r6896;
	add.s32 	%r6899, %r6898, -2022574463;
	shf.l.wrap.b32 	%r6900, %r6899, %r6899, 11;
	add.s32 	%r6901, %r6900, %r6895;
	xor.b32  	%r6902, %r6901, %r6895;
	xor.b32  	%r6903, %r6902, %r6888;
	add.s32 	%r6904, %r6719, %r6880;
	add.s32 	%r6905, %r6904, %r6903;
	add.s32 	%r6906, %r6905, 1839030562;
	shf.l.wrap.b32 	%r6907, %r6906, %r6906, 16;
	add.s32 	%r6908, %r6907, %r6901;
	xor.b32  	%r6909, %r6908, %r6902;
	add.s32 	%r6910, %r6746, %r6888;
	add.s32 	%r6911, %r6910, %r6909;
	add.s32 	%r6912, %r6911, -35309556;
	shf.l.wrap.b32 	%r6913, %r6912, %r6912, 23;
	add.s32 	%r6914, %r6913, %r6908;
	xor.b32  	%r6915, %r6914, %r6908;
	xor.b32  	%r6916, %r6915, %r6901;
	add.s32 	%r6917, %r6629, %r6895;
	add.s32 	%r6918, %r6917, %r6916;
	add.s32 	%r6919, %r6918, -1530992060;
	shf.l.wrap.b32 	%r6920, %r6919, %r6919, 4;
	add.s32 	%r6921, %r6920, %r6914;
	xor.b32  	%r6922, %r6921, %r6915;
	add.s32 	%r6923, %r6656, %r6901;
	add.s32 	%r6924, %r6923, %r6922;
	add.s32 	%r6925, %r6924, 1272893353;
	shf.l.wrap.b32 	%r6926, %r6925, %r6925, 11;
	add.s32 	%r6927, %r6926, %r6921;
	xor.b32  	%r6928, %r6927, %r6921;
	xor.b32  	%r6929, %r6928, %r6914;
	add.s32 	%r6930, %r6683, %r6908;
	add.s32 	%r6931, %r6930, %r6929;
	add.s32 	%r6932, %r6931, -155497632;
	shf.l.wrap.b32 	%r6933, %r6932, %r6932, 16;
	add.s32 	%r6934, %r6933, %r6927;
	xor.b32  	%r6935, %r6934, %r6928;
	add.s32 	%r6936, %r6710, %r6914;
	add.s32 	%r6937, %r6936, %r6935;
	add.s32 	%r6938, %r6937, -1094730640;
	shf.l.wrap.b32 	%r6939, %r6938, %r6938, 23;
	add.s32 	%r6940, %r6939, %r6934;
	xor.b32  	%r6941, %r6940, %r6934;
	xor.b32  	%r6942, %r6941, %r6927;
	add.s32 	%r6943, %r6737, %r6921;
	add.s32 	%r6944, %r6943, %r6942;
	add.s32 	%r6945, %r6944, 681279174;
	shf.l.wrap.b32 	%r6946, %r6945, %r6945, 4;
	add.s32 	%r6947, %r6946, %r6940;
	xor.b32  	%r6948, %r6947, %r6941;
	add.s32 	%r6949, %r6621, %r6927;
	add.s32 	%r6950, %r6949, %r6948;
	add.s32 	%r6951, %r6950, -358537222;
	shf.l.wrap.b32 	%r6952, %r6951, %r6951, 11;
	add.s32 	%r6953, %r6952, %r6947;
	xor.b32  	%r6954, %r6953, %r6947;
	xor.b32  	%r6955, %r6954, %r6940;
	add.s32 	%r6956, %r6647, %r6934;
	add.s32 	%r6957, %r6956, %r6955;
	add.s32 	%r6958, %r6957, -722521979;
	shf.l.wrap.b32 	%r6959, %r6958, %r6958, 16;
	add.s32 	%r6960, %r6959, %r6953;
	xor.b32  	%r6961, %r6960, %r6954;
	add.s32 	%r6962, %r6674, %r6940;
	add.s32 	%r6963, %r6962, %r6961;
	add.s32 	%r6964, %r6963, 76029189;
	shf.l.wrap.b32 	%r6965, %r6964, %r6964, 23;
	add.s32 	%r6966, %r6965, %r6960;
	xor.b32  	%r6967, %r6966, %r6960;
	xor.b32  	%r6968, %r6967, %r6953;
	add.s32 	%r6969, %r6701, %r6947;
	add.s32 	%r6970, %r6969, %r6968;
	add.s32 	%r6971, %r6970, -640364487;
	shf.l.wrap.b32 	%r6972, %r6971, %r6971, 4;
	add.s32 	%r6973, %r6972, %r6966;
	xor.b32  	%r6974, %r6973, %r6967;
	add.s32 	%r6975, %r6728, %r6953;
	add.s32 	%r6976, %r6975, %r6974;
	add.s32 	%r6977, %r6976, -421815835;
	shf.l.wrap.b32 	%r6978, %r6977, %r6977, 11;
	add.s32 	%r6979, %r6978, %r6973;
	xor.b32  	%r6980, %r6979, %r6973;
	xor.b32  	%r6981, %r6980, %r6966;
	add.s32 	%r6982, %r6755, %r6960;
	add.s32 	%r6983, %r6982, %r6981;
	add.s32 	%r6984, %r6983, 530742520;
	shf.l.wrap.b32 	%r6985, %r6984, %r6984, 16;
	add.s32 	%r6986, %r6985, %r6979;
	xor.b32  	%r6987, %r6986, %r6980;
	add.s32 	%r6988, %r6638, %r6966;
	add.s32 	%r6989, %r6988, %r6987;
	add.s32 	%r6990, %r6989, -995338651;
	shf.l.wrap.b32 	%r6991, %r6990, %r6990, 23;
	add.s32 	%r6992, %r6991, %r6986;
	not.b32 	%r6993, %r6979;
	or.b32  	%r6994, %r6992, %r6993;
	xor.b32  	%r6995, %r6994, %r6986;
	add.s32 	%r6996, %r6621, %r6973;
	add.s32 	%r6997, %r6996, %r6995;
	add.s32 	%r6998, %r6997, -198630844;
	shf.l.wrap.b32 	%r6999, %r6998, %r6998, 6;
	add.s32 	%r7000, %r6999, %r6992;
	not.b32 	%r7001, %r6986;
	or.b32  	%r7002, %r7000, %r7001;
	xor.b32  	%r7003, %r7002, %r6992;
	add.s32 	%r7004, %r6683, %r6979;
	add.s32 	%r7005, %r7004, %r7003;
	add.s32 	%r7006, %r7005, 1126891415;
	shf.l.wrap.b32 	%r7007, %r7006, %r7006, 10;
	add.s32 	%r7008, %r7007, %r7000;
	not.b32 	%r7009, %r6992;
	or.b32  	%r7010, %r7008, %r7009;
	xor.b32  	%r7011, %r7010, %r7000;
	add.s32 	%r7012, %r6746, %r6986;
	add.s32 	%r7013, %r7012, %r7011;
	add.s32 	%r7014, %r7013, -1416354905;
	shf.l.wrap.b32 	%r7015, %r7014, %r7014, 15;
	add.s32 	%r7016, %r7015, %r7008;
	not.b32 	%r7017, %r7000;
	or.b32  	%r7018, %r7016, %r7017;
	xor.b32  	%r7019, %r7018, %r7008;
	add.s32 	%r7020, %r6665, %r6992;
	add.s32 	%r7021, %r7020, %r7019;
	add.s32 	%r7022, %r7021, -57434055;
	shf.l.wrap.b32 	%r7023, %r7022, %r7022, 21;
	add.s32 	%r7024, %r7023, %r7016;
	not.b32 	%r7025, %r7008;
	or.b32  	%r7026, %r7024, %r7025;
	xor.b32  	%r7027, %r7026, %r7016;
	add.s32 	%r7028, %r6728, %r7000;
	add.s32 	%r7029, %r7028, %r7027;
	add.s32 	%r7030, %r7029, 1700485571;
	shf.l.wrap.b32 	%r7031, %r7030, %r7030, 6;
	add.s32 	%r7032, %r7031, %r7024;
	not.b32 	%r7033, %r7016;
	or.b32  	%r7034, %r7032, %r7033;
	xor.b32  	%r7035, %r7034, %r7024;
	add.s32 	%r7036, %r6647, %r7008;
	add.s32 	%r7037, %r7036, %r7035;
	add.s32 	%r7038, %r7037, -1894986606;
	shf.l.wrap.b32 	%r7039, %r7038, %r7038, 10;
	add.s32 	%r7040, %r7039, %r7032;
	not.b32 	%r7041, %r7024;
	or.b32  	%r7042, %r7040, %r7041;
	xor.b32  	%r7043, %r7042, %r7032;
	add.s32 	%r7044, %r6710, %r7016;
	add.s32 	%r7045, %r7044, %r7043;
	add.s32 	%r7046, %r7045, -1051523;
	shf.l.wrap.b32 	%r7047, %r7046, %r7046, 15;
	add.s32 	%r7048, %r7047, %r7040;
	not.b32 	%r7049, %r7032;
	or.b32  	%r7050, %r7048, %r7049;
	xor.b32  	%r7051, %r7050, %r7040;
	add.s32 	%r7052, %r6629, %r7024;
	add.s32 	%r7053, %r7052, %r7051;
	add.s32 	%r7054, %r7053, -2054922799;
	shf.l.wrap.b32 	%r7055, %r7054, %r7054, 21;
	add.s32 	%r7056, %r7055, %r7048;
	not.b32 	%r7057, %r7040;
	or.b32  	%r7058, %r7056, %r7057;
	xor.b32  	%r7059, %r7058, %r7048;
	add.s32 	%r7060, %r6692, %r7032;
	add.s32 	%r7061, %r7060, %r7059;
	add.s32 	%r7062, %r7061, 1873313359;
	shf.l.wrap.b32 	%r7063, %r7062, %r7062, 6;
	add.s32 	%r7064, %r7063, %r7056;
	not.b32 	%r7065, %r7048;
	or.b32  	%r7066, %r7064, %r7065;
	xor.b32  	%r7067, %r7066, %r7056;
	add.s32 	%r7068, %r6755, %r7040;
	add.s32 	%r7069, %r7068, %r7067;
	add.s32 	%r7070, %r7069, -30611744;
	shf.l.wrap.b32 	%r7071, %r7070, %r7070, 10;
	add.s32 	%r7072, %r7071, %r7064;
	not.b32 	%r7073, %r7056;
	or.b32  	%r7074, %r7072, %r7073;
	xor.b32  	%r7075, %r7074, %r7064;
	add.s32 	%r7076, %r6674, %r7048;
	add.s32 	%r7077, %r7076, %r7075;
	add.s32 	%r7078, %r7077, -1560198380;
	shf.l.wrap.b32 	%r7079, %r7078, %r7078, 15;
	add.s32 	%r7080, %r7079, %r7072;
	not.b32 	%r7081, %r7064;
	or.b32  	%r7082, %r7080, %r7081;
	xor.b32  	%r7083, %r7082, %r7072;
	add.s32 	%r7084, %r6737, %r7056;
	add.s32 	%r7085, %r7084, %r7083;
	add.s32 	%r7086, %r7085, 1309151649;
	shf.l.wrap.b32 	%r7087, %r7086, %r7086, 21;
	add.s32 	%r7088, %r7087, %r7080;
	not.b32 	%r7089, %r7072;
	or.b32  	%r7090, %r7088, %r7089;
	xor.b32  	%r7091, %r7090, %r7080;
	add.s32 	%r7092, %r6656, %r7064;
	add.s32 	%r7093, %r7092, %r7091;
	add.s32 	%r7094, %r7093, -145523070;
	shf.l.wrap.b32 	%r7095, %r7094, %r7094, 6;
	add.s32 	%r7096, %r7095, %r7088;
	not.b32 	%r7097, %r7080;
	or.b32  	%r7098, %r7096, %r7097;
	xor.b32  	%r7099, %r7098, %r7088;
	add.s32 	%r7100, %r6719, %r7072;
	add.s32 	%r7101, %r7100, %r7099;
	add.s32 	%r7102, %r7101, -1120210379;
	shf.l.wrap.b32 	%r7103, %r7102, %r7102, 10;
	add.s32 	%r7104, %r7103, %r7096;
	not.b32 	%r7105, %r7088;
	or.b32  	%r7106, %r7104, %r7105;
	xor.b32  	%r7107, %r7106, %r7096;
	add.s32 	%r7108, %r6638, %r7080;
	add.s32 	%r7109, %r7108, %r7107;
	add.s32 	%r7110, %r7109, 718787259;
	shf.l.wrap.b32 	%r7111, %r7110, %r7110, 15;
	add.s32 	%r7112, %r7111, %r7104;
	not.b32 	%r7113, %r7096;
	or.b32  	%r7114, %r7112, %r7113;
	xor.b32  	%r7115, %r7114, %r7104;
	add.s32 	%r7116, %r6701, %r7088;
	add.s32 	%r7117, %r7116, %r7115;
	add.s32 	%r7118, %r7117, -343485551;
	shf.l.wrap.b32 	%r7119, %r7118, %r7118, 21;
	add.s32 	%r90, %r7096, %r90;
	add.s32 	%r7120, %r7112, %r89;
	add.s32 	%r89, %r7120, %r7119;
	add.s32 	%r88, %r7112, %r88;
	add.s32 	%r87, %r7104, %r87;
	add.s32 	%r7739, %r7739, 64;
	add.s32 	%r7740, %r7740, 16;
	add.s32 	%r7718, %r7718, 64;

BB3_9:
	mov.u32 	%r86, %r7858;
	mov.u32 	%r85, %r7857;
	mov.u32 	%r84, %r7856;
	mov.u32 	%r83, %r7855;
	mov.u32 	%r82, %r7859;
	mov.u32 	%r81, %r7860;
	mov.u32 	%r80, %r7861;
	mov.u32 	%r79, %r7862;
	mov.u32 	%r78, %r7834;
	mov.u32 	%r77, %r7833;
	mov.u32 	%r76, %r7832;
	mov.u32 	%r75, %r7831;
	mov.u32 	%r74, %r7838;
	mov.u32 	%r73, %r7837;
	mov.u32 	%r72, %r7836;
	mov.u32 	%r71, %r7835;
	cvt.u64.u32	%rd66, %r7717;
	add.s32 	%r1646, %r69, -64;
	setp.lt.s32	%p5, %r7739, %r1646;
	mul.lo.s64 	%rd28, %rd66, 260;
	add.s64 	%rd29, %rd6, %rd28;
	mul.wide.s32 	%rd30, %r7740, 4;
	add.s64 	%rd31, %rd29, %rd30;
	ld.global.nc.u32 	%r93, [%rd31];
	mov.u32 	%r1647, 4;
	ld.global.nc.u32 	%r94, [%rd31+4];
	ld.global.nc.u32 	%r95, [%rd31+8];
	ld.global.nc.u32 	%r96, [%rd31+12];
	ld.global.nc.u32 	%r97, [%rd31+16];
	ld.global.nc.u32 	%r98, [%rd31+20];
	ld.global.nc.u32 	%r99, [%rd31+24];
	ld.global.nc.u32 	%r100, [%rd31+28];
	ld.global.nc.u32 	%r101, [%rd31+32];
	ld.global.nc.u32 	%r102, [%rd31+36];
	ld.global.nc.u32 	%r103, [%rd31+40];
	ld.global.nc.u32 	%r104, [%rd31+44];
	ld.global.nc.u32 	%r105, [%rd31+48];
	ld.global.nc.u32 	%r106, [%rd31+52];
	ld.global.nc.u32 	%r107, [%rd31+56];
	ld.global.nc.u32 	%r108, [%rd31+60];
	and.b32  	%r109, %r7718, 3;
	sub.s32 	%r110, %r1647, %r109;
	@%p5 bra 	BB3_142;
	bra.uni 	BB3_10;

BB3_142:
	bfe.u32 	%r5272, %r7718, 2, 4;
	mov.u32 	%r7831, 0;
	setp.gt.s32	%p102, %r5272, 7;
	@%p102 bra 	BB3_158;

	setp.gt.s32	%p114, %r5272, 3;
	@%p114 bra 	BB3_151;

	setp.gt.s32	%p120, %r5272, 1;
	@%p120 bra 	BB3_148;

	setp.eq.s32	%p123, %r5272, 0;
	@%p123 bra 	BB3_183;
	bra.uni 	BB3_146;

BB3_183:
	and.b32  	%r6616, %r110, 3;
	shl.b32 	%r6600, %r6616, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6533, %r108, %r7831, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6537, %r107, %r108, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6541, %r106, %r107, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6545, %r105, %r106, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6549, %r104, %r105, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6553, %r103, %r104, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6557, %r102, %r103, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6561, %r101, %r102, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6565, %r100, %r101, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6569, %r99, %r100, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6573, %r98, %r99, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6577, %r97, %r98, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6581, %r96, %r97, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6585, %r95, %r96, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6589, %r94, %r95, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6593, %r93, %r94, %r6600;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6597, %r7831, %r93, %r6600;
	// inline asm
	setp.eq.s32	%p140, %r109, 0;
	selp.b32	%r7839, %r6581, %r6585, %p140;
	selp.b32	%r95, %r6585, %r6589, %p140;
	selp.b32	%r94, %r6589, %r6593, %p140;
	selp.b32	%r93, %r6593, %r6597, %p140;
	selp.b32	%r100, %r6565, %r6569, %p140;
	selp.b32	%r99, %r6569, %r6573, %p140;
	selp.b32	%r98, %r6573, %r6577, %p140;
	selp.b32	%r97, %r6577, %r6581, %p140;
	selp.b32	%r104, %r6549, %r6553, %p140;
	selp.b32	%r103, %r6553, %r6557, %p140;
	selp.b32	%r102, %r6557, %r6561, %p140;
	selp.b32	%r101, %r6561, %r6565, %p140;
	selp.b32	%r108, %r6533, %r6537, %p140;
	selp.b32	%r107, %r6537, %r6541, %p140;
	selp.b32	%r106, %r6541, %r6545, %p140;
	selp.b32	%r105, %r6545, %r6549, %p140;
	selp.b32	%r7858, 0, %r6533, %p140;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7855, %r7831;
	mov.u32 	%r7856, %r7831;
	mov.u32 	%r7857, %r7831;
	bra.uni 	BB3_184;

BB3_158:
	setp.gt.s32	%p103, %r5272, 11;
	@%p103 bra 	BB3_166;

	setp.gt.s32	%p109, %r5272, 9;
	@%p109 bra 	BB3_163;

	setp.eq.s32	%p112, %r5272, 8;
	@%p112 bra 	BB3_178;
	bra.uni 	BB3_161;

BB3_178:
	and.b32  	%r5944, %r110, 3;
	shl.b32 	%r5928, %r5944, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r5861, %r108, %r7831, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5865, %r107, %r108, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5869, %r106, %r107, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5873, %r105, %r106, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5877, %r104, %r105, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5881, %r103, %r104, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5885, %r102, %r103, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5889, %r101, %r102, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5893, %r100, %r101, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5897, %r99, %r100, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5901, %r98, %r99, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5905, %r97, %r98, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5909, %r96, %r97, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5913, %r95, %r96, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5917, %r94, %r95, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5921, %r93, %r94, %r5928;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5925, %r7831, %r93, %r5928;
	// inline asm
	setp.eq.s32	%p132, %r109, 0;
	selp.b32	%r7834, 0, %r5861, %p132;
	selp.b32	%r104, %r5909, %r5913, %p132;
	selp.b32	%r103, %r5913, %r5917, %p132;
	selp.b32	%r102, %r5917, %r5921, %p132;
	selp.b32	%r101, %r5921, %r5925, %p132;
	selp.b32	%r108, %r5893, %r5897, %p132;
	selp.b32	%r107, %r5897, %r5901, %p132;
	selp.b32	%r106, %r5901, %r5905, %p132;
	selp.b32	%r105, %r5905, %r5909, %p132;
	selp.b32	%r7855, %r5877, %r5881, %p132;
	selp.b32	%r7856, %r5881, %r5885, %p132;
	selp.b32	%r7857, %r5885, %r5889, %p132;
	selp.b32	%r7858, %r5889, %r5893, %p132;
	selp.b32	%r7859, %r5873, %r5877, %p132;
	selp.b32	%r7860, %r5869, %r5873, %p132;
	selp.b32	%r7861, %r5865, %r5869, %p132;
	selp.b32	%r7862, %r5861, %r5865, %p132;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r100, %r7831;
	bra.uni 	BB3_179;

BB3_151:
	setp.gt.s32	%p115, %r5272, 5;
	@%p115 bra 	BB3_155;

	setp.eq.s32	%p118, %r5272, 4;
	@%p118 bra 	BB3_181;
	bra.uni 	BB3_153;

BB3_181:
	and.b32  	%r6280, %r110, 3;
	shl.b32 	%r6264, %r6280, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6197, %r108, %r7831, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6201, %r107, %r108, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6205, %r106, %r107, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6209, %r105, %r106, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6213, %r104, %r105, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6217, %r103, %r104, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6221, %r102, %r103, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6225, %r101, %r102, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6229, %r100, %r101, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6233, %r99, %r100, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6237, %r98, %r99, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6241, %r97, %r98, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6245, %r96, %r97, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6249, %r95, %r96, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6253, %r94, %r95, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6257, %r93, %r94, %r6264;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6261, %r7831, %r93, %r6264;
	// inline asm
	setp.eq.s32	%p136, %r109, 0;
	selp.b32	%r100, %r6245, %r6249, %p136;
	selp.b32	%r99, %r6249, %r6253, %p136;
	selp.b32	%r98, %r6253, %r6257, %p136;
	selp.b32	%r97, %r6257, %r6261, %p136;
	selp.b32	%r104, %r6229, %r6233, %p136;
	selp.b32	%r103, %r6233, %r6237, %p136;
	selp.b32	%r102, %r6237, %r6241, %p136;
	selp.b32	%r101, %r6241, %r6245, %p136;
	selp.b32	%r108, %r6213, %r6217, %p136;
	selp.b32	%r107, %r6217, %r6221, %p136;
	selp.b32	%r106, %r6221, %r6225, %p136;
	selp.b32	%r105, %r6225, %r6229, %p136;
	selp.b32	%r7855, %r6197, %r6201, %p136;
	selp.b32	%r7856, %r6201, %r6205, %p136;
	selp.b32	%r7857, %r6205, %r6209, %p136;
	selp.b32	%r7858, %r6209, %r6213, %p136;
	selp.b32	%r7859, 0, %r6197, %p136;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	bra.uni 	BB3_185;

BB3_166:
	setp.gt.s32	%p104, %r5272, 13;
	@%p104 bra 	BB3_170;

	setp.eq.s32	%p107, %r5272, 12;
	@%p107 bra 	BB3_175;
	bra.uni 	BB3_168;

BB3_175:
	and.b32  	%r5608, %r110, 3;
	shl.b32 	%r5592, %r5608, 3;
	mov.u32 	%r7835, 0;
	// inline asm
	shf.r.wrap.b32 %r5525, %r108, %r7835, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5529, %r107, %r108, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5533, %r106, %r107, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5537, %r105, %r106, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5541, %r104, %r105, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5545, %r103, %r104, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5549, %r102, %r103, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5553, %r101, %r102, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5557, %r100, %r101, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5561, %r99, %r100, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5565, %r98, %r99, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5569, %r97, %r98, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5573, %r96, %r97, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5577, %r95, %r96, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5581, %r94, %r95, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5585, %r93, %r94, %r5592;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5589, %r7835, %r93, %r5592;
	// inline asm
	setp.eq.s32	%p128, %r109, 0;
	selp.b32	%r7831, %r5525, %r5529, %p128;
	selp.b32	%r7832, %r5529, %r5533, %p128;
	selp.b32	%r7833, %r5533, %r5537, %p128;
	selp.b32	%r7834, %r5537, %r5541, %p128;
	selp.b32	%r7838, 0, %r5525, %p128;
	selp.b32	%r108, %r5573, %r5577, %p128;
	selp.b32	%r107, %r5577, %r5581, %p128;
	selp.b32	%r106, %r5581, %r5585, %p128;
	selp.b32	%r105, %r5585, %r5589, %p128;
	selp.b32	%r7855, %r5557, %r5561, %p128;
	selp.b32	%r7856, %r5561, %r5565, %p128;
	selp.b32	%r7857, %r5565, %r5569, %p128;
	selp.b32	%r7858, %r5569, %r5573, %p128;
	selp.b32	%r7859, %r5553, %r5557, %p128;
	selp.b32	%r7860, %r5549, %r5553, %p128;
	selp.b32	%r7861, %r5545, %r5549, %p128;
	selp.b32	%r7862, %r5541, %r5545, %p128;
	mov.u32 	%r7836, %r7835;
	mov.u32 	%r7837, %r7835;
	mov.u32 	%r7839, %r7835;
	mov.u32 	%r95, %r7835;
	mov.u32 	%r94, %r7835;
	mov.u32 	%r93, %r7835;
	mov.u32 	%r100, %r7835;
	mov.u32 	%r99, %r7835;
	mov.u32 	%r98, %r7835;
	mov.u32 	%r97, %r7835;
	mov.u32 	%r104, %r7835;
	bra.uni 	BB3_176;

BB3_148:
	setp.eq.s32	%p121, %r5272, 2;
	@%p121 bra 	BB3_182;
	bra.uni 	BB3_149;

BB3_182:
	and.b32  	%r6448, %r110, 3;
	shl.b32 	%r6432, %r6448, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6365, %r108, %r7831, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6369, %r107, %r108, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6373, %r106, %r107, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6377, %r105, %r106, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6381, %r104, %r105, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6385, %r103, %r104, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6389, %r102, %r103, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6393, %r101, %r102, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6397, %r100, %r101, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6401, %r99, %r100, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6405, %r98, %r99, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6409, %r97, %r98, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6413, %r96, %r97, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6417, %r95, %r96, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6421, %r94, %r95, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6425, %r93, %r94, %r6432;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6429, %r7831, %r93, %r6432;
	// inline asm
	setp.eq.s32	%p138, %r109, 0;
	selp.b32	%r7839, %r6421, %r6425, %p138;
	selp.b32	%r95, %r6425, %r6429, %p138;
	selp.b32	%r100, %r6405, %r6409, %p138;
	selp.b32	%r99, %r6409, %r6413, %p138;
	selp.b32	%r98, %r6413, %r6417, %p138;
	selp.b32	%r97, %r6417, %r6421, %p138;
	selp.b32	%r104, %r6389, %r6393, %p138;
	selp.b32	%r103, %r6393, %r6397, %p138;
	selp.b32	%r102, %r6397, %r6401, %p138;
	selp.b32	%r101, %r6401, %r6405, %p138;
	selp.b32	%r108, %r6373, %r6377, %p138;
	selp.b32	%r107, %r6377, %r6381, %p138;
	selp.b32	%r106, %r6381, %r6385, %p138;
	selp.b32	%r105, %r6385, %r6389, %p138;
	selp.b32	%r7856, 0, %r6365, %p138;
	selp.b32	%r7857, %r6365, %r6369, %p138;
	selp.b32	%r7858, %r6369, %r6373, %p138;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r7855, %r7831;
	bra.uni 	BB3_184;

BB3_163:
	setp.eq.s32	%p110, %r5272, 10;
	@%p110 bra 	BB3_177;
	bra.uni 	BB3_164;

BB3_177:
	and.b32  	%r5776, %r110, 3;
	shl.b32 	%r5760, %r5776, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r5693, %r108, %r7831, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5697, %r107, %r108, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5701, %r106, %r107, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5705, %r105, %r106, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5709, %r104, %r105, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5713, %r103, %r104, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5717, %r102, %r103, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5721, %r101, %r102, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5725, %r100, %r101, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5729, %r99, %r100, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5733, %r98, %r99, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5737, %r97, %r98, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5741, %r96, %r97, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5745, %r95, %r96, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5749, %r94, %r95, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5753, %r93, %r94, %r5760;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5757, %r7831, %r93, %r5760;
	// inline asm
	setp.eq.s32	%p130, %r109, 0;
	selp.b32	%r7832, 0, %r5693, %p130;
	selp.b32	%r7833, %r5693, %r5697, %p130;
	selp.b32	%r7834, %r5697, %r5701, %p130;
	selp.b32	%r104, %r5749, %r5753, %p130;
	selp.b32	%r103, %r5753, %r5757, %p130;
	selp.b32	%r108, %r5733, %r5737, %p130;
	selp.b32	%r107, %r5737, %r5741, %p130;
	selp.b32	%r106, %r5741, %r5745, %p130;
	selp.b32	%r105, %r5745, %r5749, %p130;
	selp.b32	%r7855, %r5717, %r5721, %p130;
	selp.b32	%r7856, %r5721, %r5725, %p130;
	selp.b32	%r7857, %r5725, %r5729, %p130;
	selp.b32	%r7858, %r5729, %r5733, %p130;
	selp.b32	%r7859, %r5713, %r5717, %p130;
	selp.b32	%r7860, %r5709, %r5713, %p130;
	selp.b32	%r7861, %r5705, %r5709, %p130;
	selp.b32	%r7862, %r5701, %r5705, %p130;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r100, %r7831;
	mov.u32 	%r99, %r7831;
	mov.u32 	%r98, %r7831;
	mov.u32 	%r97, %r7831;
	mov.u32 	%r102, %r7831;
	mov.u32 	%r101, %r7831;
	bra.uni 	BB3_188;

BB3_155:
	setp.eq.s32	%p116, %r5272, 6;
	@%p116 bra 	BB3_180;
	bra.uni 	BB3_156;

BB3_180:
	and.b32  	%r6112, %r110, 3;
	shl.b32 	%r6096, %r6112, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6029, %r108, %r7831, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6033, %r107, %r108, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6037, %r106, %r107, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6041, %r105, %r106, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6045, %r104, %r105, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6049, %r103, %r104, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6053, %r102, %r103, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6057, %r101, %r102, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6061, %r100, %r101, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6065, %r99, %r100, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6069, %r98, %r99, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6073, %r97, %r98, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6077, %r96, %r97, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6081, %r95, %r96, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6085, %r94, %r95, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6089, %r93, %r94, %r6096;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6093, %r7831, %r93, %r6096;
	// inline asm
	setp.eq.s32	%p134, %r109, 0;
	selp.b32	%r100, %r6085, %r6089, %p134;
	selp.b32	%r99, %r6089, %r6093, %p134;
	selp.b32	%r104, %r6069, %r6073, %p134;
	selp.b32	%r103, %r6073, %r6077, %p134;
	selp.b32	%r102, %r6077, %r6081, %p134;
	selp.b32	%r101, %r6081, %r6085, %p134;
	selp.b32	%r108, %r6053, %r6057, %p134;
	selp.b32	%r107, %r6057, %r6061, %p134;
	selp.b32	%r106, %r6061, %r6065, %p134;
	selp.b32	%r105, %r6065, %r6069, %p134;
	selp.b32	%r7855, %r6037, %r6041, %p134;
	selp.b32	%r7856, %r6041, %r6045, %p134;
	selp.b32	%r7857, %r6045, %r6049, %p134;
	selp.b32	%r7858, %r6049, %r6053, %p134;
	selp.b32	%r7859, %r6033, %r6037, %p134;
	selp.b32	%r7860, %r6029, %r6033, %p134;
	selp.b32	%r7861, 0, %r6029, %p134;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r98, %r7831;
	mov.u32 	%r97, %r7831;
	bra.uni 	BB3_187;

BB3_170:
	setp.eq.s32	%p105, %r5272, 14;
	@%p105 bra 	BB3_174;
	bra.uni 	BB3_171;

BB3_174:
	and.b32  	%r5440, %r110, 3;
	shl.b32 	%r5424, %r5440, 3;
	mov.u32 	%r7835, 0;
	// inline asm
	shf.r.wrap.b32 %r5357, %r108, %r7835, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5361, %r107, %r108, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5365, %r106, %r107, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5369, %r105, %r106, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5373, %r104, %r105, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5377, %r103, %r104, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5381, %r102, %r103, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5385, %r101, %r102, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5389, %r100, %r101, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5393, %r99, %r100, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5397, %r98, %r99, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5401, %r97, %r98, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5405, %r96, %r97, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5409, %r95, %r96, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5413, %r94, %r95, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5417, %r93, %r94, %r5424;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5421, %r7835, %r93, %r5424;
	// inline asm
	setp.eq.s32	%p126, %r109, 0;
	selp.b32	%r7831, %r5365, %r5369, %p126;
	selp.b32	%r7832, %r5369, %r5373, %p126;
	selp.b32	%r7833, %r5373, %r5377, %p126;
	selp.b32	%r7834, %r5377, %r5381, %p126;
	selp.b32	%r7836, 0, %r5357, %p126;
	selp.b32	%r7837, %r5357, %r5361, %p126;
	selp.b32	%r7838, %r5361, %r5365, %p126;
	selp.b32	%r108, %r5413, %r5417, %p126;
	selp.b32	%r107, %r5417, %r5421, %p126;
	selp.b32	%r7855, %r5397, %r5401, %p126;
	selp.b32	%r7856, %r5401, %r5405, %p126;
	selp.b32	%r7857, %r5405, %r5409, %p126;
	selp.b32	%r7858, %r5409, %r5413, %p126;
	selp.b32	%r7859, %r5393, %r5397, %p126;
	selp.b32	%r7860, %r5389, %r5393, %p126;
	selp.b32	%r7861, %r5385, %r5389, %p126;
	selp.b32	%r7862, %r5381, %r5385, %p126;
	mov.u32 	%r7839, %r7835;
	mov.u32 	%r95, %r7835;
	mov.u32 	%r94, %r7835;
	mov.u32 	%r93, %r7835;
	mov.u32 	%r100, %r7835;
	mov.u32 	%r99, %r7835;
	mov.u32 	%r98, %r7835;
	mov.u32 	%r97, %r7835;
	mov.u32 	%r104, %r7835;
	mov.u32 	%r103, %r7835;
	mov.u32 	%r102, %r7835;
	mov.u32 	%r101, %r7835;
	mov.u32 	%r106, %r7835;
	mov.u32 	%r105, %r7835;
	bra.uni 	BB3_188;

BB3_146:
	setp.eq.s32	%p124, %r5272, 1;
	@%p124 bra 	BB3_147;
	bra.uni 	BB3_172;

BB3_147:
	and.b32  	%r6532, %r110, 3;
	shl.b32 	%r6516, %r6532, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6449, %r108, %r7831, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6453, %r107, %r108, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6457, %r106, %r107, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6461, %r105, %r106, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6465, %r104, %r105, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6469, %r103, %r104, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6473, %r102, %r103, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6477, %r101, %r102, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6481, %r100, %r101, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6485, %r99, %r100, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6489, %r98, %r99, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6493, %r97, %r98, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6497, %r96, %r97, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6501, %r95, %r96, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6505, %r94, %r95, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6509, %r93, %r94, %r6516;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6513, %r7831, %r93, %r6516;
	// inline asm
	setp.eq.s32	%p139, %r109, 0;
	selp.b32	%r7839, %r6501, %r6505, %p139;
	selp.b32	%r95, %r6505, %r6509, %p139;
	selp.b32	%r94, %r6509, %r6513, %p139;
	selp.b32	%r100, %r6485, %r6489, %p139;
	selp.b32	%r99, %r6489, %r6493, %p139;
	selp.b32	%r98, %r6493, %r6497, %p139;
	selp.b32	%r97, %r6497, %r6501, %p139;
	selp.b32	%r104, %r6469, %r6473, %p139;
	selp.b32	%r103, %r6473, %r6477, %p139;
	selp.b32	%r102, %r6477, %r6481, %p139;
	selp.b32	%r101, %r6481, %r6485, %p139;
	selp.b32	%r108, %r6453, %r6457, %p139;
	selp.b32	%r107, %r6457, %r6461, %p139;
	selp.b32	%r106, %r6461, %r6465, %p139;
	selp.b32	%r105, %r6465, %r6469, %p139;
	selp.b32	%r7857, 0, %r6449, %p139;
	selp.b32	%r7858, %r6449, %r6453, %p139;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r7855, %r7831;
	mov.u32 	%r7856, %r7831;
	bra.uni 	BB3_184;

BB3_161:
	setp.eq.s32	%p113, %r5272, 9;
	@%p113 bra 	BB3_162;
	bra.uni 	BB3_172;

BB3_162:
	and.b32  	%r5860, %r110, 3;
	shl.b32 	%r5844, %r5860, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r5777, %r108, %r7831, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5781, %r107, %r108, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5785, %r106, %r107, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5789, %r105, %r106, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5793, %r104, %r105, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5797, %r103, %r104, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5801, %r102, %r103, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5805, %r101, %r102, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5809, %r100, %r101, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5813, %r99, %r100, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5817, %r98, %r99, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5821, %r97, %r98, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5825, %r96, %r97, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5829, %r95, %r96, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5833, %r94, %r95, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5837, %r93, %r94, %r5844;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5841, %r7831, %r93, %r5844;
	// inline asm
	setp.eq.s32	%p131, %r109, 0;
	selp.b32	%r7833, 0, %r5777, %p131;
	selp.b32	%r7834, %r5777, %r5781, %p131;
	selp.b32	%r104, %r5829, %r5833, %p131;
	selp.b32	%r103, %r5833, %r5837, %p131;
	selp.b32	%r102, %r5837, %r5841, %p131;
	selp.b32	%r108, %r5813, %r5817, %p131;
	selp.b32	%r107, %r5817, %r5821, %p131;
	selp.b32	%r106, %r5821, %r5825, %p131;
	selp.b32	%r105, %r5825, %r5829, %p131;
	selp.b32	%r7855, %r5797, %r5801, %p131;
	selp.b32	%r7856, %r5801, %r5805, %p131;
	selp.b32	%r7857, %r5805, %r5809, %p131;
	selp.b32	%r7858, %r5809, %r5813, %p131;
	selp.b32	%r7859, %r5793, %r5797, %p131;
	selp.b32	%r7860, %r5789, %r5793, %p131;
	selp.b32	%r7861, %r5785, %r5789, %p131;
	selp.b32	%r7862, %r5781, %r5785, %p131;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r100, %r7831;
	mov.u32 	%r99, %r7831;
	mov.u32 	%r98, %r7831;
	mov.u32 	%r97, %r7831;
	mov.u32 	%r101, %r7831;
	bra.uni 	BB3_188;

BB3_153:
	setp.eq.s32	%p119, %r5272, 5;
	@%p119 bra 	BB3_154;
	bra.uni 	BB3_172;

BB3_154:
	and.b32  	%r6196, %r110, 3;
	shl.b32 	%r6180, %r6196, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6113, %r108, %r7831, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6117, %r107, %r108, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6121, %r106, %r107, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6125, %r105, %r106, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6129, %r104, %r105, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6133, %r103, %r104, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6137, %r102, %r103, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6141, %r101, %r102, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6145, %r100, %r101, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6149, %r99, %r100, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6153, %r98, %r99, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6157, %r97, %r98, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6161, %r96, %r97, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6165, %r95, %r96, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6169, %r94, %r95, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6173, %r93, %r94, %r6180;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6177, %r7831, %r93, %r6180;
	// inline asm
	setp.eq.s32	%p135, %r109, 0;
	selp.b32	%r100, %r6165, %r6169, %p135;
	selp.b32	%r99, %r6169, %r6173, %p135;
	selp.b32	%r98, %r6173, %r6177, %p135;
	selp.b32	%r104, %r6149, %r6153, %p135;
	selp.b32	%r103, %r6153, %r6157, %p135;
	selp.b32	%r102, %r6157, %r6161, %p135;
	selp.b32	%r101, %r6161, %r6165, %p135;
	selp.b32	%r108, %r6133, %r6137, %p135;
	selp.b32	%r107, %r6137, %r6141, %p135;
	selp.b32	%r106, %r6141, %r6145, %p135;
	selp.b32	%r105, %r6145, %r6149, %p135;
	selp.b32	%r7855, %r6117, %r6121, %p135;
	selp.b32	%r7856, %r6121, %r6125, %p135;
	selp.b32	%r7857, %r6125, %r6129, %p135;
	selp.b32	%r7858, %r6129, %r6133, %p135;
	selp.b32	%r7859, %r6113, %r6117, %p135;
	selp.b32	%r7860, 0, %r6113, %p135;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	mov.u32 	%r97, %r7831;
	bra.uni 	BB3_186;

BB3_168:
	setp.eq.s32	%p108, %r5272, 13;
	@%p108 bra 	BB3_169;
	bra.uni 	BB3_172;

BB3_169:
	and.b32  	%r5524, %r110, 3;
	shl.b32 	%r5508, %r5524, 3;
	mov.u32 	%r7835, 0;
	// inline asm
	shf.r.wrap.b32 %r5441, %r108, %r7835, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5445, %r107, %r108, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5449, %r106, %r107, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5453, %r105, %r106, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5457, %r104, %r105, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5461, %r103, %r104, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5465, %r102, %r103, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5469, %r101, %r102, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5473, %r100, %r101, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5477, %r99, %r100, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5481, %r98, %r99, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5485, %r97, %r98, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5489, %r96, %r97, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5493, %r95, %r96, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5497, %r94, %r95, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5501, %r93, %r94, %r5508;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5505, %r7835, %r93, %r5508;
	// inline asm
	setp.eq.s32	%p127, %r109, 0;
	selp.b32	%r7831, %r5445, %r5449, %p127;
	selp.b32	%r7832, %r5449, %r5453, %p127;
	selp.b32	%r7833, %r5453, %r5457, %p127;
	selp.b32	%r7834, %r5457, %r5461, %p127;
	selp.b32	%r7837, 0, %r5441, %p127;
	selp.b32	%r7838, %r5441, %r5445, %p127;
	selp.b32	%r108, %r5493, %r5497, %p127;
	selp.b32	%r107, %r5497, %r5501, %p127;
	selp.b32	%r106, %r5501, %r5505, %p127;
	selp.b32	%r7855, %r5477, %r5481, %p127;
	selp.b32	%r7856, %r5481, %r5485, %p127;
	selp.b32	%r7857, %r5485, %r5489, %p127;
	selp.b32	%r7858, %r5489, %r5493, %p127;
	selp.b32	%r7859, %r5473, %r5477, %p127;
	selp.b32	%r7860, %r5469, %r5473, %p127;
	selp.b32	%r7861, %r5465, %r5469, %p127;
	selp.b32	%r7862, %r5461, %r5465, %p127;
	mov.u32 	%r7836, %r7835;
	mov.u32 	%r7839, %r7835;
	mov.u32 	%r95, %r7835;
	mov.u32 	%r94, %r7835;
	mov.u32 	%r93, %r7835;
	mov.u32 	%r100, %r7835;
	mov.u32 	%r99, %r7835;
	mov.u32 	%r98, %r7835;
	mov.u32 	%r97, %r7835;
	mov.u32 	%r104, %r7835;
	mov.u32 	%r103, %r7835;
	mov.u32 	%r102, %r7835;
	mov.u32 	%r101, %r7835;
	mov.u32 	%r105, %r7835;
	bra.uni 	BB3_188;

BB3_149:
	setp.eq.s32	%p122, %r5272, 3;
	@%p122 bra 	BB3_150;
	bra.uni 	BB3_172;

BB3_150:
	and.b32  	%r6364, %r110, 3;
	shl.b32 	%r6348, %r6364, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r6281, %r108, %r7831, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6285, %r107, %r108, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6289, %r106, %r107, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6293, %r105, %r106, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6297, %r104, %r105, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6301, %r103, %r104, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6305, %r102, %r103, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6309, %r101, %r102, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6313, %r100, %r101, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6317, %r99, %r100, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6321, %r98, %r99, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6325, %r97, %r98, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6329, %r96, %r97, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6333, %r95, %r96, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6337, %r94, %r95, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6341, %r93, %r94, %r6348;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6345, %r7831, %r93, %r6348;
	// inline asm
	setp.eq.s32	%p137, %r109, 0;
	selp.b32	%r7839, %r6341, %r6345, %p137;
	selp.b32	%r100, %r6325, %r6329, %p137;
	selp.b32	%r99, %r6329, %r6333, %p137;
	selp.b32	%r98, %r6333, %r6337, %p137;
	selp.b32	%r97, %r6337, %r6341, %p137;
	selp.b32	%r104, %r6309, %r6313, %p137;
	selp.b32	%r103, %r6313, %r6317, %p137;
	selp.b32	%r102, %r6317, %r6321, %p137;
	selp.b32	%r101, %r6321, %r6325, %p137;
	selp.b32	%r108, %r6293, %r6297, %p137;
	selp.b32	%r107, %r6297, %r6301, %p137;
	selp.b32	%r106, %r6301, %r6305, %p137;
	selp.b32	%r105, %r6305, %r6309, %p137;
	selp.b32	%r7855, 0, %r6281, %p137;
	selp.b32	%r7856, %r6281, %r6285, %p137;
	selp.b32	%r7857, %r6285, %r6289, %p137;
	selp.b32	%r7858, %r6289, %r6293, %p137;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;
	bra.uni 	BB3_184;

BB3_164:
	setp.eq.s32	%p111, %r5272, 11;
	@%p111 bra 	BB3_165;
	bra.uni 	BB3_172;

BB3_165:
	and.b32  	%r5692, %r110, 3;
	shl.b32 	%r5676, %r5692, 3;
	mov.u32 	%r7835, 0;
	// inline asm
	shf.r.wrap.b32 %r5609, %r108, %r7835, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5613, %r107, %r108, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5617, %r106, %r107, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5621, %r105, %r106, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5625, %r104, %r105, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5629, %r103, %r104, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5633, %r102, %r103, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5637, %r101, %r102, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5641, %r100, %r101, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5645, %r99, %r100, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5649, %r98, %r99, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5653, %r97, %r98, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5657, %r96, %r97, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5661, %r95, %r96, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5665, %r94, %r95, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5669, %r93, %r94, %r5676;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5673, %r7835, %r93, %r5676;
	// inline asm
	setp.eq.s32	%p129, %r109, 0;
	selp.b32	%r7831, 0, %r5609, %p129;
	selp.b32	%r7832, %r5609, %r5613, %p129;
	selp.b32	%r7833, %r5613, %r5617, %p129;
	selp.b32	%r7834, %r5617, %r5621, %p129;
	selp.b32	%r104, %r5669, %r5673, %p129;
	selp.b32	%r108, %r5653, %r5657, %p129;
	selp.b32	%r107, %r5657, %r5661, %p129;
	selp.b32	%r106, %r5661, %r5665, %p129;
	selp.b32	%r105, %r5665, %r5669, %p129;
	selp.b32	%r7855, %r5637, %r5641, %p129;
	selp.b32	%r7856, %r5641, %r5645, %p129;
	selp.b32	%r7857, %r5645, %r5649, %p129;
	selp.b32	%r7858, %r5649, %r5653, %p129;
	selp.b32	%r7859, %r5633, %r5637, %p129;
	selp.b32	%r7860, %r5629, %r5633, %p129;
	selp.b32	%r7861, %r5625, %r5629, %p129;
	selp.b32	%r7862, %r5621, %r5625, %p129;
	mov.u32 	%r7836, %r7835;
	mov.u32 	%r7837, %r7835;
	mov.u32 	%r7838, %r7835;
	mov.u32 	%r7839, %r7835;
	mov.u32 	%r95, %r7835;
	mov.u32 	%r94, %r7835;
	mov.u32 	%r93, %r7835;
	mov.u32 	%r100, %r7835;
	mov.u32 	%r99, %r7835;
	mov.u32 	%r98, %r7835;
	mov.u32 	%r97, %r7835;

BB3_176:
	mov.u32 	%r103, %r7835;
	mov.u32 	%r102, %r7835;
	mov.u32 	%r101, %r7835;
	bra.uni 	BB3_188;

BB3_156:
	setp.eq.s32	%p117, %r5272, 7;
	@%p117 bra 	BB3_157;
	bra.uni 	BB3_172;

BB3_157:
	and.b32  	%r6028, %r110, 3;
	shl.b32 	%r6012, %r6028, 3;
	mov.u32 	%r7831, 0;
	// inline asm
	shf.r.wrap.b32 %r5945, %r108, %r7831, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5949, %r107, %r108, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5953, %r106, %r107, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5957, %r105, %r106, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5961, %r104, %r105, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5965, %r103, %r104, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5969, %r102, %r103, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5973, %r101, %r102, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5977, %r100, %r101, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5981, %r99, %r100, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5985, %r98, %r99, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5989, %r97, %r98, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5993, %r96, %r97, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5997, %r95, %r96, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6001, %r94, %r95, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6005, %r93, %r94, %r6012;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6009, %r7831, %r93, %r6012;
	// inline asm
	setp.eq.s32	%p133, %r109, 0;
	selp.b32	%r100, %r6005, %r6009, %p133;
	selp.b32	%r104, %r5989, %r5993, %p133;
	selp.b32	%r103, %r5993, %r5997, %p133;
	selp.b32	%r102, %r5997, %r6001, %p133;
	selp.b32	%r101, %r6001, %r6005, %p133;
	selp.b32	%r108, %r5973, %r5977, %p133;
	selp.b32	%r107, %r5977, %r5981, %p133;
	selp.b32	%r106, %r5981, %r5985, %p133;
	selp.b32	%r105, %r5985, %r5989, %p133;
	selp.b32	%r7855, %r5957, %r5961, %p133;
	selp.b32	%r7856, %r5961, %r5965, %p133;
	selp.b32	%r7857, %r5965, %r5969, %p133;
	selp.b32	%r7858, %r5969, %r5973, %p133;
	selp.b32	%r7859, %r5953, %r5957, %p133;
	selp.b32	%r7860, %r5949, %r5953, %p133;
	selp.b32	%r7861, %r5945, %r5949, %p133;
	selp.b32	%r7862, 0, %r5945, %p133;
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r7831;
	mov.u32 	%r95, %r7831;
	mov.u32 	%r94, %r7831;
	mov.u32 	%r93, %r7831;

BB3_179:
	mov.u32 	%r99, %r7831;
	mov.u32 	%r98, %r7831;
	mov.u32 	%r97, %r7831;
	bra.uni 	BB3_188;

BB3_171:
	setp.ne.s32	%p106, %r5272, 15;
	@%p106 bra 	BB3_172;

	and.b32  	%r5356, %r110, 3;
	shl.b32 	%r5340, %r5356, 3;
	mov.u32 	%r7839, 0;
	// inline asm
	shf.r.wrap.b32 %r5273, %r108, %r7839, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5277, %r107, %r108, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5281, %r106, %r107, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5285, %r105, %r106, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5289, %r104, %r105, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5293, %r103, %r104, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5297, %r102, %r103, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5301, %r101, %r102, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5305, %r100, %r101, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5309, %r99, %r100, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5313, %r98, %r99, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5317, %r97, %r98, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5321, %r96, %r97, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5325, %r95, %r96, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5329, %r94, %r95, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5333, %r93, %r94, %r5340;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5337, %r7839, %r93, %r5340;
	// inline asm
	setp.eq.s32	%p125, %r109, 0;
	selp.b32	%r7831, %r5285, %r5289, %p125;
	selp.b32	%r7832, %r5289, %r5293, %p125;
	selp.b32	%r7833, %r5293, %r5297, %p125;
	selp.b32	%r7834, %r5297, %r5301, %p125;
	selp.b32	%r7835, 0, %r5273, %p125;
	selp.b32	%r7836, %r5273, %r5277, %p125;
	selp.b32	%r7837, %r5277, %r5281, %p125;
	selp.b32	%r7838, %r5281, %r5285, %p125;
	selp.b32	%r108, %r5333, %r5337, %p125;
	selp.b32	%r7855, %r5317, %r5321, %p125;
	selp.b32	%r7856, %r5321, %r5325, %p125;
	selp.b32	%r7857, %r5325, %r5329, %p125;
	selp.b32	%r7858, %r5329, %r5333, %p125;
	selp.b32	%r7859, %r5313, %r5317, %p125;
	selp.b32	%r7860, %r5309, %r5313, %p125;
	selp.b32	%r7861, %r5305, %r5309, %p125;
	selp.b32	%r7862, %r5301, %r5305, %p125;
	mov.u32 	%r95, %r7839;
	mov.u32 	%r94, %r7839;
	mov.u32 	%r93, %r7839;
	mov.u32 	%r100, %r7839;
	mov.u32 	%r99, %r7839;
	mov.u32 	%r98, %r7839;
	mov.u32 	%r97, %r7839;
	mov.u32 	%r104, %r7839;
	mov.u32 	%r103, %r7839;
	mov.u32 	%r102, %r7839;
	mov.u32 	%r101, %r7839;
	mov.u32 	%r107, %r7839;
	mov.u32 	%r106, %r7839;
	mov.u32 	%r105, %r7839;
	bra.uni 	BB3_188;

BB3_172:
	mov.u32 	%r7832, %r7831;
	mov.u32 	%r7833, %r7831;
	mov.u32 	%r7834, %r7831;
	mov.u32 	%r7835, %r7831;
	mov.u32 	%r7836, %r7831;
	mov.u32 	%r7837, %r7831;
	mov.u32 	%r7838, %r7831;
	mov.u32 	%r7839, %r96;
	mov.u32 	%r7855, %r7831;
	mov.u32 	%r7856, %r7831;
	mov.u32 	%r7857, %r7831;
	mov.u32 	%r7858, %r7831;

BB3_184:
	mov.u32 	%r7859, %r7831;

BB3_185:
	mov.u32 	%r7860, %r7831;

BB3_186:
	mov.u32 	%r7861, %r7831;

BB3_187:
	mov.u32 	%r7862, %r7831;
	bra.uni 	BB3_188;

BB3_10:
	sub.s32 	%r1648, %r69, %r7739;
	add.s32 	%r111, %r1648, %r7718;
	and.b32  	%r1649, %r7718, 63;
	add.s32 	%r1650, %r1648, %r1649;
	setp.lt.s32	%p6, %r1650, 64;
	bfe.u32 	%r112, %r7718, 2, 4;
	@%p6 bra 	BB3_58;
	bra.uni 	BB3_11;

BB3_58:
	shl.b32 	%r3515, %r110, 2;
	mov.u32 	%r3516, 1985229328;
	shr.u32 	%r3517, %r3516, %r3515;
	and.b32  	%r421, %r3517, 65535;
	setp.gt.s32	%p46, %r112, 7;
	@%p46 bra 	BB3_74;

	setp.gt.s32	%p58, %r112, 3;
	@%p58 bra 	BB3_67;

	setp.gt.s32	%p64, %r112, 1;
	@%p64 bra 	BB3_64;

	setp.eq.s32	%p67, %r112, 0;
	@%p67 bra 	BB3_109;
	bra.uni 	BB3_62;

BB3_109:
	// inline asm
	prmt.b32 %r108, %r107, %r108, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r106, %r107, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r105, %r106, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r104, %r105, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r103, %r104, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r96, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r95, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r94, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r4179, 0;
	// inline asm
	prmt.b32 %r7776, %r4179, %r93, %r421;
	// inline asm
	bra.uni 	BB3_110;

BB3_11:
	mov.u32 	%r7741, 0;
	setp.gt.s32	%p7, %r112, 7;
	@%p7 bra 	BB3_27;

	setp.gt.s32	%p19, %r112, 3;
	@%p19 bra 	BB3_20;

	setp.gt.s32	%p25, %r112, 1;
	@%p25 bra 	BB3_17;

	setp.eq.s32	%p28, %r112, 0;
	@%p28 bra 	BB3_52;
	bra.uni 	BB3_15;

BB3_52:
	and.b32  	%r3010, %r110, 3;
	shl.b32 	%r2994, %r3010, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2927, %r108, %r7741, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2931, %r107, %r108, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2935, %r106, %r107, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2939, %r105, %r106, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2943, %r104, %r105, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2947, %r103, %r104, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2951, %r102, %r103, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2955, %r101, %r102, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2959, %r100, %r101, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2963, %r99, %r100, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2967, %r98, %r99, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2971, %r97, %r98, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2975, %r96, %r97, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2979, %r95, %r96, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2983, %r94, %r95, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2987, %r93, %r94, %r2994;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2991, %r7741, %r93, %r2994;
	// inline asm
	setp.eq.s32	%p45, %r109, 0;
	selp.b32	%r7749, %r2975, %r2979, %p45;
	selp.b32	%r95, %r2979, %r2983, %p45;
	selp.b32	%r94, %r2983, %r2987, %p45;
	selp.b32	%r93, %r2987, %r2991, %p45;
	selp.b32	%r100, %r2959, %r2963, %p45;
	selp.b32	%r99, %r2963, %r2967, %p45;
	selp.b32	%r98, %r2967, %r2971, %p45;
	selp.b32	%r97, %r2971, %r2975, %p45;
	selp.b32	%r104, %r2943, %r2947, %p45;
	selp.b32	%r103, %r2947, %r2951, %p45;
	selp.b32	%r102, %r2951, %r2955, %p45;
	selp.b32	%r101, %r2955, %r2959, %p45;
	selp.b32	%r108, %r2927, %r2931, %p45;
	selp.b32	%r107, %r2931, %r2935, %p45;
	selp.b32	%r106, %r2935, %r2939, %p45;
	selp.b32	%r105, %r2939, %r2943, %p45;
	selp.b32	%r7768, 0, %r2927, %p45;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7765, %r7741;
	mov.u32 	%r7766, %r7741;
	mov.u32 	%r7767, %r7741;
	bra.uni 	BB3_53;

BB3_74:
	setp.gt.s32	%p47, %r112, 11;
	@%p47 bra 	BB3_82;

	setp.gt.s32	%p53, %r112, 9;
	@%p53 bra 	BB3_79;

	setp.eq.s32	%p56, %r112, 8;
	@%p56 bra 	BB3_99;
	bra.uni 	BB3_77;

BB3_99:
	// inline asm
	prmt.b32 %r108, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r101, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	bra.uni 	BB3_100;

BB3_27:
	setp.gt.s32	%p8, %r112, 11;
	@%p8 bra 	BB3_35;

	setp.gt.s32	%p14, %r112, 9;
	@%p14 bra 	BB3_32;

	setp.eq.s32	%p17, %r112, 8;
	@%p17 bra 	BB3_47;
	bra.uni 	BB3_30;

BB3_47:
	and.b32  	%r2338, %r110, 3;
	shl.b32 	%r2322, %r2338, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2255, %r108, %r7741, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2259, %r107, %r108, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2263, %r106, %r107, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2267, %r105, %r106, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2271, %r104, %r105, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2275, %r103, %r104, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2279, %r102, %r103, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2283, %r101, %r102, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2287, %r100, %r101, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2291, %r99, %r100, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2295, %r98, %r99, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2299, %r97, %r98, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2303, %r96, %r97, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2307, %r95, %r96, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2311, %r94, %r95, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2315, %r93, %r94, %r2322;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2319, %r7741, %r93, %r2322;
	// inline asm
	setp.eq.s32	%p37, %r109, 0;
	selp.b32	%r7744, 0, %r2255, %p37;
	selp.b32	%r104, %r2303, %r2307, %p37;
	selp.b32	%r103, %r2307, %r2311, %p37;
	selp.b32	%r102, %r2311, %r2315, %p37;
	selp.b32	%r101, %r2315, %r2319, %p37;
	selp.b32	%r108, %r2287, %r2291, %p37;
	selp.b32	%r107, %r2291, %r2295, %p37;
	selp.b32	%r106, %r2295, %r2299, %p37;
	selp.b32	%r105, %r2299, %r2303, %p37;
	selp.b32	%r7765, %r2271, %r2275, %p37;
	selp.b32	%r7766, %r2275, %r2279, %p37;
	selp.b32	%r7767, %r2279, %r2283, %p37;
	selp.b32	%r7768, %r2283, %r2287, %p37;
	selp.b32	%r7769, %r2267, %r2271, %p37;
	selp.b32	%r7770, %r2263, %r2267, %p37;
	selp.b32	%r7771, %r2259, %r2263, %p37;
	selp.b32	%r7772, %r2255, %r2259, %p37;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r100, %r7741;
	bra.uni 	BB3_48;

BB3_67:
	setp.gt.s32	%p59, %r112, 5;
	@%p59 bra 	BB3_71;

	setp.eq.s32	%p62, %r112, 4;
	@%p62 bra 	BB3_105;
	bra.uni 	BB3_69;

BB3_105:
	// inline asm
	prmt.b32 %r108, %r103, %r104, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r97, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	bra.uni 	BB3_110;

BB3_20:
	setp.gt.s32	%p20, %r112, 5;
	@%p20 bra 	BB3_24;

	setp.eq.s32	%p23, %r112, 4;
	@%p23 bra 	BB3_50;
	bra.uni 	BB3_22;

BB3_50:
	and.b32  	%r2674, %r110, 3;
	shl.b32 	%r2658, %r2674, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2591, %r108, %r7741, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2595, %r107, %r108, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2599, %r106, %r107, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2603, %r105, %r106, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2607, %r104, %r105, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2611, %r103, %r104, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2615, %r102, %r103, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2619, %r101, %r102, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2623, %r100, %r101, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2627, %r99, %r100, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2631, %r98, %r99, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2635, %r97, %r98, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2639, %r96, %r97, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2643, %r95, %r96, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2647, %r94, %r95, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2651, %r93, %r94, %r2658;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2655, %r7741, %r93, %r2658;
	// inline asm
	setp.eq.s32	%p41, %r109, 0;
	selp.b32	%r100, %r2639, %r2643, %p41;
	selp.b32	%r99, %r2643, %r2647, %p41;
	selp.b32	%r98, %r2647, %r2651, %p41;
	selp.b32	%r97, %r2651, %r2655, %p41;
	selp.b32	%r104, %r2623, %r2627, %p41;
	selp.b32	%r103, %r2627, %r2631, %p41;
	selp.b32	%r102, %r2631, %r2635, %p41;
	selp.b32	%r101, %r2635, %r2639, %p41;
	selp.b32	%r108, %r2607, %r2611, %p41;
	selp.b32	%r107, %r2611, %r2615, %p41;
	selp.b32	%r106, %r2615, %r2619, %p41;
	selp.b32	%r105, %r2619, %r2623, %p41;
	selp.b32	%r7765, %r2591, %r2595, %p41;
	selp.b32	%r7766, %r2595, %r2599, %p41;
	selp.b32	%r7767, %r2599, %r2603, %p41;
	selp.b32	%r7768, %r2603, %r2607, %p41;
	selp.b32	%r7769, 0, %r2591, %p41;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	bra.uni 	BB3_54;

BB3_82:
	setp.gt.s32	%p48, %r112, 13;
	@%p48 bra 	BB3_86;

	setp.eq.s32	%p51, %r112, 12;
	@%p51 bra 	BB3_93;
	bra.uni 	BB3_84;

BB3_93:
	// inline asm
	prmt.b32 %r108, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r105, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	mov.u32 	%r104, %r96;
	bra.uni 	BB3_94;

BB3_35:
	setp.gt.s32	%p9, %r112, 13;
	@%p9 bra 	BB3_39;

	setp.eq.s32	%p12, %r112, 12;
	@%p12 bra 	BB3_44;
	bra.uni 	BB3_37;

BB3_44:
	and.b32  	%r2002, %r110, 3;
	shl.b32 	%r1986, %r2002, 3;
	mov.u32 	%r7745, 0;
	// inline asm
	shf.r.wrap.b32 %r1919, %r108, %r7745, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1923, %r107, %r108, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1927, %r106, %r107, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1931, %r105, %r106, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1935, %r104, %r105, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1939, %r103, %r104, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1943, %r102, %r103, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1947, %r101, %r102, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1951, %r100, %r101, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1955, %r99, %r100, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1959, %r98, %r99, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1963, %r97, %r98, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1967, %r96, %r97, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1971, %r95, %r96, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1975, %r94, %r95, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1979, %r93, %r94, %r1986;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1983, %r7745, %r93, %r1986;
	// inline asm
	setp.eq.s32	%p33, %r109, 0;
	selp.b32	%r7741, %r1919, %r1923, %p33;
	selp.b32	%r7742, %r1923, %r1927, %p33;
	selp.b32	%r7743, %r1927, %r1931, %p33;
	selp.b32	%r7744, %r1931, %r1935, %p33;
	selp.b32	%r7748, 0, %r1919, %p33;
	selp.b32	%r108, %r1967, %r1971, %p33;
	selp.b32	%r107, %r1971, %r1975, %p33;
	selp.b32	%r106, %r1975, %r1979, %p33;
	selp.b32	%r105, %r1979, %r1983, %p33;
	selp.b32	%r7765, %r1951, %r1955, %p33;
	selp.b32	%r7766, %r1955, %r1959, %p33;
	selp.b32	%r7767, %r1959, %r1963, %p33;
	selp.b32	%r7768, %r1963, %r1967, %p33;
	selp.b32	%r7769, %r1947, %r1951, %p33;
	selp.b32	%r7770, %r1943, %r1947, %p33;
	selp.b32	%r7771, %r1939, %r1943, %p33;
	selp.b32	%r7772, %r1935, %r1939, %p33;
	mov.u32 	%r7746, %r7745;
	mov.u32 	%r7747, %r7745;
	mov.u32 	%r7749, %r7745;
	mov.u32 	%r95, %r7745;
	mov.u32 	%r94, %r7745;
	mov.u32 	%r93, %r7745;
	mov.u32 	%r100, %r7745;
	mov.u32 	%r99, %r7745;
	mov.u32 	%r98, %r7745;
	mov.u32 	%r97, %r7745;
	mov.u32 	%r104, %r7745;
	bra.uni 	BB3_45;

BB3_64:
	setp.eq.s32	%p65, %r112, 2;
	@%p65 bra 	BB3_107;
	bra.uni 	BB3_65;

BB3_107:
	// inline asm
	prmt.b32 %r108, %r105, %r106, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r104, %r105, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r103, %r104, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r96, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r94, 0;
	// inline asm
	prmt.b32 %r95, %r94, %r93, %r421;
	// inline asm
	mov.u32 	%r7776, %r94;
	bra.uni 	BB3_110;

BB3_17:
	setp.eq.s32	%p26, %r112, 2;
	@%p26 bra 	BB3_51;
	bra.uni 	BB3_18;

BB3_51:
	and.b32  	%r2842, %r110, 3;
	shl.b32 	%r2826, %r2842, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2759, %r108, %r7741, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2763, %r107, %r108, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2767, %r106, %r107, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2771, %r105, %r106, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2775, %r104, %r105, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2779, %r103, %r104, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2783, %r102, %r103, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2787, %r101, %r102, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2791, %r100, %r101, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2795, %r99, %r100, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2799, %r98, %r99, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2803, %r97, %r98, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2807, %r96, %r97, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2811, %r95, %r96, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2815, %r94, %r95, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2819, %r93, %r94, %r2826;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2823, %r7741, %r93, %r2826;
	// inline asm
	setp.eq.s32	%p43, %r109, 0;
	selp.b32	%r7749, %r2815, %r2819, %p43;
	selp.b32	%r95, %r2819, %r2823, %p43;
	selp.b32	%r100, %r2799, %r2803, %p43;
	selp.b32	%r99, %r2803, %r2807, %p43;
	selp.b32	%r98, %r2807, %r2811, %p43;
	selp.b32	%r97, %r2811, %r2815, %p43;
	selp.b32	%r104, %r2783, %r2787, %p43;
	selp.b32	%r103, %r2787, %r2791, %p43;
	selp.b32	%r102, %r2791, %r2795, %p43;
	selp.b32	%r101, %r2795, %r2799, %p43;
	selp.b32	%r108, %r2767, %r2771, %p43;
	selp.b32	%r107, %r2771, %r2775, %p43;
	selp.b32	%r106, %r2775, %r2779, %p43;
	selp.b32	%r105, %r2779, %r2783, %p43;
	selp.b32	%r7766, 0, %r2759, %p43;
	selp.b32	%r7767, %r2759, %r2763, %p43;
	selp.b32	%r7768, %r2763, %r2767, %p43;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r7765, %r7741;
	bra.uni 	BB3_53;

BB3_79:
	setp.eq.s32	%p54, %r112, 10;
	@%p54 bra 	BB3_97;
	bra.uni 	BB3_80;

BB3_97:
	// inline asm
	prmt.b32 %r108, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r103, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	bra.uni 	BB3_95;

BB3_32:
	setp.eq.s32	%p15, %r112, 10;
	@%p15 bra 	BB3_46;
	bra.uni 	BB3_33;

BB3_46:
	and.b32  	%r2170, %r110, 3;
	shl.b32 	%r2154, %r2170, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2087, %r108, %r7741, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2091, %r107, %r108, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2095, %r106, %r107, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2099, %r105, %r106, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2103, %r104, %r105, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2107, %r103, %r104, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2111, %r102, %r103, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2115, %r101, %r102, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2119, %r100, %r101, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2123, %r99, %r100, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2127, %r98, %r99, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2131, %r97, %r98, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2135, %r96, %r97, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2139, %r95, %r96, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2143, %r94, %r95, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2147, %r93, %r94, %r2154;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2151, %r7741, %r93, %r2154;
	// inline asm
	setp.eq.s32	%p35, %r109, 0;
	selp.b32	%r7742, 0, %r2087, %p35;
	selp.b32	%r7743, %r2087, %r2091, %p35;
	selp.b32	%r7744, %r2091, %r2095, %p35;
	selp.b32	%r104, %r2143, %r2147, %p35;
	selp.b32	%r103, %r2147, %r2151, %p35;
	selp.b32	%r108, %r2127, %r2131, %p35;
	selp.b32	%r107, %r2131, %r2135, %p35;
	selp.b32	%r106, %r2135, %r2139, %p35;
	selp.b32	%r105, %r2139, %r2143, %p35;
	selp.b32	%r7765, %r2111, %r2115, %p35;
	selp.b32	%r7766, %r2115, %r2119, %p35;
	selp.b32	%r7767, %r2119, %r2123, %p35;
	selp.b32	%r7768, %r2123, %r2127, %p35;
	selp.b32	%r7769, %r2107, %r2111, %p35;
	selp.b32	%r7770, %r2103, %r2107, %p35;
	selp.b32	%r7771, %r2099, %r2103, %p35;
	selp.b32	%r7772, %r2095, %r2099, %p35;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r100, %r7741;
	mov.u32 	%r99, %r7741;
	mov.u32 	%r98, %r7741;
	mov.u32 	%r97, %r7741;
	mov.u32 	%r102, %r7741;
	mov.u32 	%r101, %r7741;
	bra.uni 	BB3_57;

BB3_71:
	setp.eq.s32	%p60, %r112, 6;
	@%p60 bra 	BB3_103;
	bra.uni 	BB3_72;

BB3_103:
	// inline asm
	prmt.b32 %r108, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r99, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	bra.uni 	BB3_101;

BB3_24:
	setp.eq.s32	%p21, %r112, 6;
	@%p21 bra 	BB3_49;
	bra.uni 	BB3_25;

BB3_49:
	and.b32  	%r2506, %r110, 3;
	shl.b32 	%r2490, %r2506, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2423, %r108, %r7741, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2427, %r107, %r108, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2431, %r106, %r107, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2435, %r105, %r106, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2439, %r104, %r105, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2443, %r103, %r104, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2447, %r102, %r103, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2451, %r101, %r102, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2455, %r100, %r101, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2459, %r99, %r100, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2463, %r98, %r99, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2467, %r97, %r98, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2471, %r96, %r97, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2475, %r95, %r96, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2479, %r94, %r95, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2483, %r93, %r94, %r2490;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2487, %r7741, %r93, %r2490;
	// inline asm
	setp.eq.s32	%p39, %r109, 0;
	selp.b32	%r100, %r2479, %r2483, %p39;
	selp.b32	%r99, %r2483, %r2487, %p39;
	selp.b32	%r104, %r2463, %r2467, %p39;
	selp.b32	%r103, %r2467, %r2471, %p39;
	selp.b32	%r102, %r2471, %r2475, %p39;
	selp.b32	%r101, %r2475, %r2479, %p39;
	selp.b32	%r108, %r2447, %r2451, %p39;
	selp.b32	%r107, %r2451, %r2455, %p39;
	selp.b32	%r106, %r2455, %r2459, %p39;
	selp.b32	%r105, %r2459, %r2463, %p39;
	selp.b32	%r7765, %r2431, %r2435, %p39;
	selp.b32	%r7766, %r2435, %r2439, %p39;
	selp.b32	%r7767, %r2439, %r2443, %p39;
	selp.b32	%r7768, %r2443, %r2447, %p39;
	selp.b32	%r7769, %r2427, %r2431, %p39;
	selp.b32	%r7770, %r2423, %r2427, %p39;
	selp.b32	%r7771, 0, %r2423, %p39;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r98, %r7741;
	mov.u32 	%r97, %r7741;
	bra.uni 	BB3_56;

BB3_86:
	setp.eq.s32	%p49, %r112, 14;
	@%p49 bra 	BB3_91;
	bra.uni 	BB3_87;

BB3_91:
	// inline asm
	prmt.b32 %r108, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r107, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	mov.u32 	%r104, %r96;
	mov.u32 	%r103, %r96;
	mov.u32 	%r102, %r96;
	mov.u32 	%r101, %r96;
	bra.uni 	BB3_90;

BB3_39:
	setp.eq.s32	%p10, %r112, 14;
	@%p10 bra 	BB3_43;
	bra.uni 	BB3_40;

BB3_43:
	and.b32  	%r1834, %r110, 3;
	shl.b32 	%r1818, %r1834, 3;
	mov.u32 	%r7745, 0;
	// inline asm
	shf.r.wrap.b32 %r1751, %r108, %r7745, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1755, %r107, %r108, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1759, %r106, %r107, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1763, %r105, %r106, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1767, %r104, %r105, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1771, %r103, %r104, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1775, %r102, %r103, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1779, %r101, %r102, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1783, %r100, %r101, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1787, %r99, %r100, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1791, %r98, %r99, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1795, %r97, %r98, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1799, %r96, %r97, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1803, %r95, %r96, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1807, %r94, %r95, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1811, %r93, %r94, %r1818;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1815, %r7745, %r93, %r1818;
	// inline asm
	setp.eq.s32	%p31, %r109, 0;
	selp.b32	%r7741, %r1759, %r1763, %p31;
	selp.b32	%r7742, %r1763, %r1767, %p31;
	selp.b32	%r7743, %r1767, %r1771, %p31;
	selp.b32	%r7744, %r1771, %r1775, %p31;
	selp.b32	%r7746, 0, %r1751, %p31;
	selp.b32	%r7747, %r1751, %r1755, %p31;
	selp.b32	%r7748, %r1755, %r1759, %p31;
	selp.b32	%r108, %r1807, %r1811, %p31;
	selp.b32	%r107, %r1811, %r1815, %p31;
	selp.b32	%r7765, %r1791, %r1795, %p31;
	selp.b32	%r7766, %r1795, %r1799, %p31;
	selp.b32	%r7767, %r1799, %r1803, %p31;
	selp.b32	%r7768, %r1803, %r1807, %p31;
	selp.b32	%r7769, %r1787, %r1791, %p31;
	selp.b32	%r7770, %r1783, %r1787, %p31;
	selp.b32	%r7771, %r1779, %r1783, %p31;
	selp.b32	%r7772, %r1775, %r1779, %p31;
	mov.u32 	%r7749, %r7745;
	mov.u32 	%r95, %r7745;
	mov.u32 	%r94, %r7745;
	mov.u32 	%r93, %r7745;
	mov.u32 	%r100, %r7745;
	mov.u32 	%r99, %r7745;
	mov.u32 	%r98, %r7745;
	mov.u32 	%r97, %r7745;
	mov.u32 	%r104, %r7745;
	mov.u32 	%r103, %r7745;
	mov.u32 	%r102, %r7745;
	mov.u32 	%r101, %r7745;
	mov.u32 	%r106, %r7745;
	mov.u32 	%r105, %r7745;
	bra.uni 	BB3_57;

BB3_62:
	setp.eq.s32	%p68, %r112, 1;
	@%p68 bra 	BB3_108;
	bra.uni 	BB3_63;

BB3_108:
	// inline asm
	prmt.b32 %r108, %r106, %r107, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r105, %r106, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r104, %r105, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r103, %r104, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r96, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r95, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r7776, 0;
	// inline asm
	prmt.b32 %r94, %r7776, %r93, %r421;
	// inline asm
	bra.uni 	BB3_110;

BB3_15:
	setp.eq.s32	%p29, %r112, 1;
	@%p29 bra 	BB3_16;
	bra.uni 	BB3_41;

BB3_16:
	and.b32  	%r2926, %r110, 3;
	shl.b32 	%r2910, %r2926, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2843, %r108, %r7741, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2847, %r107, %r108, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2851, %r106, %r107, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2855, %r105, %r106, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2859, %r104, %r105, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2863, %r103, %r104, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2867, %r102, %r103, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2871, %r101, %r102, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2875, %r100, %r101, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2879, %r99, %r100, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2883, %r98, %r99, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2887, %r97, %r98, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2891, %r96, %r97, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2895, %r95, %r96, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2899, %r94, %r95, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2903, %r93, %r94, %r2910;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2907, %r7741, %r93, %r2910;
	// inline asm
	setp.eq.s32	%p44, %r109, 0;
	selp.b32	%r7749, %r2895, %r2899, %p44;
	selp.b32	%r95, %r2899, %r2903, %p44;
	selp.b32	%r94, %r2903, %r2907, %p44;
	selp.b32	%r100, %r2879, %r2883, %p44;
	selp.b32	%r99, %r2883, %r2887, %p44;
	selp.b32	%r98, %r2887, %r2891, %p44;
	selp.b32	%r97, %r2891, %r2895, %p44;
	selp.b32	%r104, %r2863, %r2867, %p44;
	selp.b32	%r103, %r2867, %r2871, %p44;
	selp.b32	%r102, %r2871, %r2875, %p44;
	selp.b32	%r101, %r2875, %r2879, %p44;
	selp.b32	%r108, %r2847, %r2851, %p44;
	selp.b32	%r107, %r2851, %r2855, %p44;
	selp.b32	%r106, %r2855, %r2859, %p44;
	selp.b32	%r105, %r2859, %r2863, %p44;
	selp.b32	%r7767, 0, %r2843, %p44;
	selp.b32	%r7768, %r2843, %r2847, %p44;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r7765, %r7741;
	mov.u32 	%r7766, %r7741;
	bra.uni 	BB3_53;

BB3_77:
	setp.eq.s32	%p57, %r112, 9;
	@%p57 bra 	BB3_98;
	bra.uni 	BB3_78;

BB3_98:
	// inline asm
	prmt.b32 %r108, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r102, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	mov.u32 	%r101, %r96;
	bra.uni 	BB3_110;

BB3_30:
	setp.eq.s32	%p18, %r112, 9;
	@%p18 bra 	BB3_31;
	bra.uni 	BB3_41;

BB3_31:
	and.b32  	%r2254, %r110, 3;
	shl.b32 	%r2238, %r2254, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2171, %r108, %r7741, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2175, %r107, %r108, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2179, %r106, %r107, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2183, %r105, %r106, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2187, %r104, %r105, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2191, %r103, %r104, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2195, %r102, %r103, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2199, %r101, %r102, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2203, %r100, %r101, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2207, %r99, %r100, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2211, %r98, %r99, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2215, %r97, %r98, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2219, %r96, %r97, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2223, %r95, %r96, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2227, %r94, %r95, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2231, %r93, %r94, %r2238;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2235, %r7741, %r93, %r2238;
	// inline asm
	setp.eq.s32	%p36, %r109, 0;
	selp.b32	%r7743, 0, %r2171, %p36;
	selp.b32	%r7744, %r2171, %r2175, %p36;
	selp.b32	%r104, %r2223, %r2227, %p36;
	selp.b32	%r103, %r2227, %r2231, %p36;
	selp.b32	%r102, %r2231, %r2235, %p36;
	selp.b32	%r108, %r2207, %r2211, %p36;
	selp.b32	%r107, %r2211, %r2215, %p36;
	selp.b32	%r106, %r2215, %r2219, %p36;
	selp.b32	%r105, %r2219, %r2223, %p36;
	selp.b32	%r7765, %r2191, %r2195, %p36;
	selp.b32	%r7766, %r2195, %r2199, %p36;
	selp.b32	%r7767, %r2199, %r2203, %p36;
	selp.b32	%r7768, %r2203, %r2207, %p36;
	selp.b32	%r7769, %r2187, %r2191, %p36;
	selp.b32	%r7770, %r2183, %r2187, %p36;
	selp.b32	%r7771, %r2179, %r2183, %p36;
	selp.b32	%r7772, %r2175, %r2179, %p36;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r100, %r7741;
	mov.u32 	%r99, %r7741;
	mov.u32 	%r98, %r7741;
	mov.u32 	%r97, %r7741;
	mov.u32 	%r101, %r7741;
	bra.uni 	BB3_57;

BB3_69:
	setp.eq.s32	%p63, %r112, 5;
	@%p63 bra 	BB3_104;
	bra.uni 	BB3_70;

BB3_104:
	// inline asm
	prmt.b32 %r108, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r98, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r97, %r96;
	bra.uni 	BB3_110;

BB3_22:
	setp.eq.s32	%p24, %r112, 5;
	@%p24 bra 	BB3_23;
	bra.uni 	BB3_41;

BB3_23:
	and.b32  	%r2590, %r110, 3;
	shl.b32 	%r2574, %r2590, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2507, %r108, %r7741, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2511, %r107, %r108, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2515, %r106, %r107, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2519, %r105, %r106, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2523, %r104, %r105, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2527, %r103, %r104, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2531, %r102, %r103, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2535, %r101, %r102, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2539, %r100, %r101, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2543, %r99, %r100, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2547, %r98, %r99, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2551, %r97, %r98, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2555, %r96, %r97, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2559, %r95, %r96, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2563, %r94, %r95, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2567, %r93, %r94, %r2574;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2571, %r7741, %r93, %r2574;
	// inline asm
	setp.eq.s32	%p40, %r109, 0;
	selp.b32	%r100, %r2559, %r2563, %p40;
	selp.b32	%r99, %r2563, %r2567, %p40;
	selp.b32	%r98, %r2567, %r2571, %p40;
	selp.b32	%r104, %r2543, %r2547, %p40;
	selp.b32	%r103, %r2547, %r2551, %p40;
	selp.b32	%r102, %r2551, %r2555, %p40;
	selp.b32	%r101, %r2555, %r2559, %p40;
	selp.b32	%r108, %r2527, %r2531, %p40;
	selp.b32	%r107, %r2531, %r2535, %p40;
	selp.b32	%r106, %r2535, %r2539, %p40;
	selp.b32	%r105, %r2539, %r2543, %p40;
	selp.b32	%r7765, %r2511, %r2515, %p40;
	selp.b32	%r7766, %r2515, %r2519, %p40;
	selp.b32	%r7767, %r2519, %r2523, %p40;
	selp.b32	%r7768, %r2523, %r2527, %p40;
	selp.b32	%r7769, %r2507, %r2511, %p40;
	selp.b32	%r7770, 0, %r2507, %p40;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	mov.u32 	%r97, %r7741;
	bra.uni 	BB3_55;

BB3_84:
	setp.eq.s32	%p52, %r112, 13;
	@%p52 bra 	BB3_92;
	bra.uni 	BB3_85;

BB3_92:
	// inline asm
	prmt.b32 %r108, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r106, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	mov.u32 	%r104, %r96;
	mov.u32 	%r103, %r96;
	mov.u32 	%r102, %r96;
	mov.u32 	%r101, %r96;
	mov.u32 	%r105, %r96;
	bra.uni 	BB3_110;

BB3_37:
	setp.eq.s32	%p13, %r112, 13;
	@%p13 bra 	BB3_38;
	bra.uni 	BB3_41;

BB3_38:
	and.b32  	%r1918, %r110, 3;
	shl.b32 	%r1902, %r1918, 3;
	mov.u32 	%r7745, 0;
	// inline asm
	shf.r.wrap.b32 %r1835, %r108, %r7745, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1839, %r107, %r108, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1843, %r106, %r107, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1847, %r105, %r106, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1851, %r104, %r105, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1855, %r103, %r104, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1859, %r102, %r103, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1863, %r101, %r102, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1867, %r100, %r101, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1871, %r99, %r100, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1875, %r98, %r99, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1879, %r97, %r98, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1883, %r96, %r97, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1887, %r95, %r96, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1891, %r94, %r95, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1895, %r93, %r94, %r1902;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1899, %r7745, %r93, %r1902;
	// inline asm
	setp.eq.s32	%p32, %r109, 0;
	selp.b32	%r7741, %r1839, %r1843, %p32;
	selp.b32	%r7742, %r1843, %r1847, %p32;
	selp.b32	%r7743, %r1847, %r1851, %p32;
	selp.b32	%r7744, %r1851, %r1855, %p32;
	selp.b32	%r7747, 0, %r1835, %p32;
	selp.b32	%r7748, %r1835, %r1839, %p32;
	selp.b32	%r108, %r1887, %r1891, %p32;
	selp.b32	%r107, %r1891, %r1895, %p32;
	selp.b32	%r106, %r1895, %r1899, %p32;
	selp.b32	%r7765, %r1871, %r1875, %p32;
	selp.b32	%r7766, %r1875, %r1879, %p32;
	selp.b32	%r7767, %r1879, %r1883, %p32;
	selp.b32	%r7768, %r1883, %r1887, %p32;
	selp.b32	%r7769, %r1867, %r1871, %p32;
	selp.b32	%r7770, %r1863, %r1867, %p32;
	selp.b32	%r7771, %r1859, %r1863, %p32;
	selp.b32	%r7772, %r1855, %r1859, %p32;
	mov.u32 	%r7746, %r7745;
	mov.u32 	%r7749, %r7745;
	mov.u32 	%r95, %r7745;
	mov.u32 	%r94, %r7745;
	mov.u32 	%r93, %r7745;
	mov.u32 	%r100, %r7745;
	mov.u32 	%r99, %r7745;
	mov.u32 	%r98, %r7745;
	mov.u32 	%r97, %r7745;
	mov.u32 	%r104, %r7745;
	mov.u32 	%r103, %r7745;
	mov.u32 	%r102, %r7745;
	mov.u32 	%r101, %r7745;
	mov.u32 	%r105, %r7745;
	bra.uni 	BB3_57;

BB3_65:
	setp.eq.s32	%p66, %r112, 3;
	@%p66 bra 	BB3_106;
	bra.uni 	BB3_66;

BB3_106:
	// inline asm
	prmt.b32 %r108, %r104, %r105, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r103, %r104, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r102, %r103, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r101, %r102, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r95, 0;
	// inline asm
	prmt.b32 %r96, %r95, %r93, %r421;
	// inline asm
	mov.u32 	%r94, %r95;
	mov.u32 	%r7776, %r95;
	bra.uni 	BB3_110;

BB3_18:
	setp.eq.s32	%p27, %r112, 3;
	@%p27 bra 	BB3_19;
	bra.uni 	BB3_41;

BB3_19:
	and.b32  	%r2758, %r110, 3;
	shl.b32 	%r2742, %r2758, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2675, %r108, %r7741, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2679, %r107, %r108, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2683, %r106, %r107, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2687, %r105, %r106, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2691, %r104, %r105, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2695, %r103, %r104, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2699, %r102, %r103, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2703, %r101, %r102, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2707, %r100, %r101, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2711, %r99, %r100, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2715, %r98, %r99, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2719, %r97, %r98, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2723, %r96, %r97, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2727, %r95, %r96, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2731, %r94, %r95, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2735, %r93, %r94, %r2742;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2739, %r7741, %r93, %r2742;
	// inline asm
	setp.eq.s32	%p42, %r109, 0;
	selp.b32	%r7749, %r2735, %r2739, %p42;
	selp.b32	%r100, %r2719, %r2723, %p42;
	selp.b32	%r99, %r2723, %r2727, %p42;
	selp.b32	%r98, %r2727, %r2731, %p42;
	selp.b32	%r97, %r2731, %r2735, %p42;
	selp.b32	%r104, %r2703, %r2707, %p42;
	selp.b32	%r103, %r2707, %r2711, %p42;
	selp.b32	%r102, %r2711, %r2715, %p42;
	selp.b32	%r101, %r2715, %r2719, %p42;
	selp.b32	%r108, %r2687, %r2691, %p42;
	selp.b32	%r107, %r2691, %r2695, %p42;
	selp.b32	%r106, %r2695, %r2699, %p42;
	selp.b32	%r105, %r2699, %r2703, %p42;
	selp.b32	%r7765, 0, %r2675, %p42;
	selp.b32	%r7766, %r2675, %r2679, %p42;
	selp.b32	%r7767, %r2679, %r2683, %p42;
	selp.b32	%r7768, %r2683, %r2687, %p42;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;
	bra.uni 	BB3_53;

BB3_80:
	setp.eq.s32	%p55, %r112, 11;
	@%p55 bra 	BB3_96;
	bra.uni 	BB3_81;

BB3_96:
	// inline asm
	prmt.b32 %r108, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r104, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;

BB3_94:
	mov.u32 	%r103, %r96;

BB3_95:
	mov.u32 	%r102, %r96;
	mov.u32 	%r101, %r96;
	bra.uni 	BB3_110;

BB3_33:
	setp.eq.s32	%p16, %r112, 11;
	@%p16 bra 	BB3_34;
	bra.uni 	BB3_41;

BB3_34:
	and.b32  	%r2086, %r110, 3;
	shl.b32 	%r2070, %r2086, 3;
	mov.u32 	%r7745, 0;
	// inline asm
	shf.r.wrap.b32 %r2003, %r108, %r7745, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2007, %r107, %r108, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2011, %r106, %r107, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2015, %r105, %r106, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2019, %r104, %r105, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2023, %r103, %r104, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2027, %r102, %r103, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2031, %r101, %r102, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2035, %r100, %r101, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2039, %r99, %r100, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2043, %r98, %r99, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2047, %r97, %r98, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2051, %r96, %r97, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2055, %r95, %r96, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2059, %r94, %r95, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2063, %r93, %r94, %r2070;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2067, %r7745, %r93, %r2070;
	// inline asm
	setp.eq.s32	%p34, %r109, 0;
	selp.b32	%r7741, 0, %r2003, %p34;
	selp.b32	%r7742, %r2003, %r2007, %p34;
	selp.b32	%r7743, %r2007, %r2011, %p34;
	selp.b32	%r7744, %r2011, %r2015, %p34;
	selp.b32	%r104, %r2063, %r2067, %p34;
	selp.b32	%r108, %r2047, %r2051, %p34;
	selp.b32	%r107, %r2051, %r2055, %p34;
	selp.b32	%r106, %r2055, %r2059, %p34;
	selp.b32	%r105, %r2059, %r2063, %p34;
	selp.b32	%r7765, %r2031, %r2035, %p34;
	selp.b32	%r7766, %r2035, %r2039, %p34;
	selp.b32	%r7767, %r2039, %r2043, %p34;
	selp.b32	%r7768, %r2043, %r2047, %p34;
	selp.b32	%r7769, %r2027, %r2031, %p34;
	selp.b32	%r7770, %r2023, %r2027, %p34;
	selp.b32	%r7771, %r2019, %r2023, %p34;
	selp.b32	%r7772, %r2015, %r2019, %p34;
	mov.u32 	%r7746, %r7745;
	mov.u32 	%r7747, %r7745;
	mov.u32 	%r7748, %r7745;
	mov.u32 	%r7749, %r7745;
	mov.u32 	%r95, %r7745;
	mov.u32 	%r94, %r7745;
	mov.u32 	%r93, %r7745;
	mov.u32 	%r100, %r7745;
	mov.u32 	%r99, %r7745;
	mov.u32 	%r98, %r7745;
	mov.u32 	%r97, %r7745;

BB3_45:
	mov.u32 	%r103, %r7745;
	mov.u32 	%r102, %r7745;
	mov.u32 	%r101, %r7745;
	bra.uni 	BB3_57;

BB3_72:
	setp.eq.s32	%p61, %r112, 7;
	@%p61 bra 	BB3_102;
	bra.uni 	BB3_73;

BB3_102:
	// inline asm
	prmt.b32 %r108, %r100, %r101, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r99, %r100, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r98, %r99, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r97, %r98, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r96, %r97, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r95, %r96, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r94, %r95, %r421;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r93, %r94, %r421;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r100, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;

BB3_100:
	mov.u32 	%r99, %r96;

BB3_101:
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	bra.uni 	BB3_110;

BB3_25:
	setp.eq.s32	%p22, %r112, 7;
	@%p22 bra 	BB3_26;
	bra.uni 	BB3_41;

BB3_26:
	and.b32  	%r2422, %r110, 3;
	shl.b32 	%r2406, %r2422, 3;
	mov.u32 	%r7741, 0;
	// inline asm
	shf.r.wrap.b32 %r2339, %r108, %r7741, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2343, %r107, %r108, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2347, %r106, %r107, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2351, %r105, %r106, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2355, %r104, %r105, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2359, %r103, %r104, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2363, %r102, %r103, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2367, %r101, %r102, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2371, %r100, %r101, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2375, %r99, %r100, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2379, %r98, %r99, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2383, %r97, %r98, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2387, %r96, %r97, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2391, %r95, %r96, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2395, %r94, %r95, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2399, %r93, %r94, %r2406;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2403, %r7741, %r93, %r2406;
	// inline asm
	setp.eq.s32	%p38, %r109, 0;
	selp.b32	%r100, %r2399, %r2403, %p38;
	selp.b32	%r104, %r2383, %r2387, %p38;
	selp.b32	%r103, %r2387, %r2391, %p38;
	selp.b32	%r102, %r2391, %r2395, %p38;
	selp.b32	%r101, %r2395, %r2399, %p38;
	selp.b32	%r108, %r2367, %r2371, %p38;
	selp.b32	%r107, %r2371, %r2375, %p38;
	selp.b32	%r106, %r2375, %r2379, %p38;
	selp.b32	%r105, %r2379, %r2383, %p38;
	selp.b32	%r7765, %r2351, %r2355, %p38;
	selp.b32	%r7766, %r2355, %r2359, %p38;
	selp.b32	%r7767, %r2359, %r2363, %p38;
	selp.b32	%r7768, %r2363, %r2367, %p38;
	selp.b32	%r7769, %r2347, %r2351, %p38;
	selp.b32	%r7770, %r2343, %r2347, %p38;
	selp.b32	%r7771, %r2339, %r2343, %p38;
	selp.b32	%r7772, 0, %r2339, %p38;
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r7741;
	mov.u32 	%r95, %r7741;
	mov.u32 	%r94, %r7741;
	mov.u32 	%r93, %r7741;

BB3_48:
	mov.u32 	%r99, %r7741;
	mov.u32 	%r98, %r7741;
	mov.u32 	%r97, %r7741;
	bra.uni 	BB3_57;

BB3_87:
	setp.ne.s32	%p50, %r112, 15;
	@%p50 bra 	BB3_88;

	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r108, %r96, %r93, %r421;
	// inline asm
	mov.u32 	%r95, %r96;
	mov.u32 	%r94, %r96;
	mov.u32 	%r7776, %r96;
	mov.u32 	%r100, %r96;
	mov.u32 	%r99, %r96;
	mov.u32 	%r98, %r96;
	mov.u32 	%r97, %r96;
	mov.u32 	%r104, %r96;
	mov.u32 	%r103, %r96;
	mov.u32 	%r102, %r96;
	mov.u32 	%r101, %r96;
	mov.u32 	%r107, %r96;

BB3_90:
	mov.u32 	%r106, %r96;
	mov.u32 	%r105, %r96;
	bra.uni 	BB3_110;

BB3_40:
	setp.ne.s32	%p11, %r112, 15;
	@%p11 bra 	BB3_41;

	and.b32  	%r1750, %r110, 3;
	shl.b32 	%r1734, %r1750, 3;
	mov.u32 	%r7749, 0;
	// inline asm
	shf.r.wrap.b32 %r1667, %r108, %r7749, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1671, %r107, %r108, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1675, %r106, %r107, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1679, %r105, %r106, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1683, %r104, %r105, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1687, %r103, %r104, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1691, %r102, %r103, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1695, %r101, %r102, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1699, %r100, %r101, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1703, %r99, %r100, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1707, %r98, %r99, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1711, %r97, %r98, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1715, %r96, %r97, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1719, %r95, %r96, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1723, %r94, %r95, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1727, %r93, %r94, %r1734;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1731, %r7749, %r93, %r1734;
	// inline asm
	setp.eq.s32	%p30, %r109, 0;
	selp.b32	%r7741, %r1679, %r1683, %p30;
	selp.b32	%r7742, %r1683, %r1687, %p30;
	selp.b32	%r7743, %r1687, %r1691, %p30;
	selp.b32	%r7744, %r1691, %r1695, %p30;
	selp.b32	%r7745, 0, %r1667, %p30;
	selp.b32	%r7746, %r1667, %r1671, %p30;
	selp.b32	%r7747, %r1671, %r1675, %p30;
	selp.b32	%r7748, %r1675, %r1679, %p30;
	selp.b32	%r108, %r1727, %r1731, %p30;
	selp.b32	%r7765, %r1711, %r1715, %p30;
	selp.b32	%r7766, %r1715, %r1719, %p30;
	selp.b32	%r7767, %r1719, %r1723, %p30;
	selp.b32	%r7768, %r1723, %r1727, %p30;
	selp.b32	%r7769, %r1707, %r1711, %p30;
	selp.b32	%r7770, %r1703, %r1707, %p30;
	selp.b32	%r7771, %r1699, %r1703, %p30;
	selp.b32	%r7772, %r1695, %r1699, %p30;
	mov.u32 	%r95, %r7749;
	mov.u32 	%r94, %r7749;
	mov.u32 	%r93, %r7749;
	mov.u32 	%r100, %r7749;
	mov.u32 	%r99, %r7749;
	mov.u32 	%r98, %r7749;
	mov.u32 	%r97, %r7749;
	mov.u32 	%r104, %r7749;
	mov.u32 	%r103, %r7749;
	mov.u32 	%r102, %r7749;
	mov.u32 	%r101, %r7749;
	mov.u32 	%r107, %r7749;
	mov.u32 	%r106, %r7749;
	mov.u32 	%r105, %r7749;
	bra.uni 	BB3_57;

BB3_41:
	mov.u32 	%r7742, %r7741;
	mov.u32 	%r7743, %r7741;
	mov.u32 	%r7744, %r7741;
	mov.u32 	%r7745, %r7741;
	mov.u32 	%r7746, %r7741;
	mov.u32 	%r7747, %r7741;
	mov.u32 	%r7748, %r7741;
	mov.u32 	%r7749, %r96;
	mov.u32 	%r7765, %r7741;
	mov.u32 	%r7766, %r7741;
	mov.u32 	%r7767, %r7741;
	mov.u32 	%r7768, %r7741;

BB3_53:
	mov.u32 	%r7769, %r7741;

BB3_54:
	mov.u32 	%r7770, %r7741;

BB3_55:
	mov.u32 	%r7771, %r7741;

BB3_56:
	mov.u32 	%r7772, %r7741;

BB3_57:
	xor.b32  	%r3011, %r88, %r87;
	and.b32  	%r3012, %r89, %r3011;
	xor.b32  	%r3013, %r3012, %r87;
	add.s32 	%r3014, %r90, %r3013;
	or.b32  	%r3015, %r93, %r86;
	add.s32 	%r3016, %r3014, %r3015;
	add.s32 	%r3017, %r3016, -680876936;
	shf.l.wrap.b32 	%r3018, %r3017, %r3017, 7;
	add.s32 	%r3019, %r3018, %r89;
	xor.b32  	%r3020, %r89, %r88;
	and.b32  	%r3021, %r3019, %r3020;
	xor.b32  	%r3022, %r3021, %r88;
	or.b32  	%r3023, %r94, %r85;
	add.s32 	%r3024, %r87, %r3023;
	add.s32 	%r3025, %r3024, %r3022;
	add.s32 	%r3026, %r3025, -389564586;
	shf.l.wrap.b32 	%r3027, %r3026, %r3026, 12;
	add.s32 	%r3028, %r3027, %r3019;
	xor.b32  	%r3029, %r3019, %r89;
	and.b32  	%r3030, %r3028, %r3029;
	xor.b32  	%r3031, %r3030, %r89;
	or.b32  	%r3032, %r95, %r84;
	add.s32 	%r3033, %r88, %r3032;
	add.s32 	%r3034, %r3033, %r3031;
	add.s32 	%r3035, %r3034, 606105819;
	shf.l.wrap.b32 	%r3036, %r3035, %r3035, 17;
	add.s32 	%r3037, %r3036, %r3028;
	xor.b32  	%r3038, %r3028, %r3019;
	and.b32  	%r3039, %r3037, %r3038;
	xor.b32  	%r3040, %r3039, %r3019;
	or.b32  	%r3041, %r7749, %r83;
	add.s32 	%r3042, %r89, %r3041;
	add.s32 	%r3043, %r3042, %r3040;
	add.s32 	%r3044, %r3043, -1044525330;
	shf.l.wrap.b32 	%r3045, %r3044, %r3044, 22;
	add.s32 	%r3046, %r3045, %r3037;
	xor.b32  	%r3047, %r3037, %r3028;
	and.b32  	%r3048, %r3046, %r3047;
	xor.b32  	%r3049, %r3048, %r3028;
	or.b32  	%r3050, %r97, %r82;
	add.s32 	%r3051, %r3050, %r3019;
	add.s32 	%r3052, %r3051, %r3049;
	add.s32 	%r3053, %r3052, -176418897;
	shf.l.wrap.b32 	%r3054, %r3053, %r3053, 7;
	add.s32 	%r3055, %r3054, %r3046;
	xor.b32  	%r3056, %r3046, %r3037;
	and.b32  	%r3057, %r3055, %r3056;
	xor.b32  	%r3058, %r3057, %r3037;
	or.b32  	%r3059, %r98, %r81;
	add.s32 	%r3060, %r3059, %r3028;
	add.s32 	%r3061, %r3060, %r3058;
	add.s32 	%r3062, %r3061, 1200080426;
	shf.l.wrap.b32 	%r3063, %r3062, %r3062, 12;
	add.s32 	%r3064, %r3063, %r3055;
	xor.b32  	%r3065, %r3055, %r3046;
	and.b32  	%r3066, %r3064, %r3065;
	xor.b32  	%r3067, %r3066, %r3046;
	or.b32  	%r3068, %r99, %r80;
	add.s32 	%r3069, %r3068, %r3037;
	add.s32 	%r3070, %r3069, %r3067;
	add.s32 	%r3071, %r3070, -1473231341;
	shf.l.wrap.b32 	%r3072, %r3071, %r3071, 17;
	add.s32 	%r3073, %r3072, %r3064;
	xor.b32  	%r3074, %r3064, %r3055;
	and.b32  	%r3075, %r3073, %r3074;
	xor.b32  	%r3076, %r3075, %r3055;
	or.b32  	%r3077, %r100, %r79;
	add.s32 	%r3078, %r3077, %r3046;
	add.s32 	%r3079, %r3078, %r3076;
	add.s32 	%r3080, %r3079, -45705983;
	shf.l.wrap.b32 	%r3081, %r3080, %r3080, 22;
	add.s32 	%r3082, %r3081, %r3073;
	xor.b32  	%r3083, %r3073, %r3064;
	and.b32  	%r3084, %r3082, %r3083;
	xor.b32  	%r3085, %r3084, %r3064;
	or.b32  	%r3086, %r101, %r78;
	add.s32 	%r3087, %r3086, %r3055;
	add.s32 	%r3088, %r3087, %r3085;
	add.s32 	%r3089, %r3088, 1770035416;
	shf.l.wrap.b32 	%r3090, %r3089, %r3089, 7;
	add.s32 	%r3091, %r3090, %r3082;
	xor.b32  	%r3092, %r3082, %r3073;
	and.b32  	%r3093, %r3091, %r3092;
	xor.b32  	%r3094, %r3093, %r3073;
	or.b32  	%r3095, %r102, %r77;
	add.s32 	%r3096, %r3095, %r3064;
	add.s32 	%r3097, %r3096, %r3094;
	add.s32 	%r3098, %r3097, -1958414417;
	shf.l.wrap.b32 	%r3099, %r3098, %r3098, 12;
	add.s32 	%r3100, %r3099, %r3091;
	xor.b32  	%r3101, %r3091, %r3082;
	and.b32  	%r3102, %r3100, %r3101;
	xor.b32  	%r3103, %r3102, %r3082;
	or.b32  	%r3104, %r103, %r76;
	add.s32 	%r3105, %r3104, %r3073;
	add.s32 	%r3106, %r3105, %r3103;
	add.s32 	%r3107, %r3106, -42063;
	shf.l.wrap.b32 	%r3108, %r3107, %r3107, 17;
	add.s32 	%r3109, %r3108, %r3100;
	xor.b32  	%r3110, %r3100, %r3091;
	and.b32  	%r3111, %r3109, %r3110;
	xor.b32  	%r3112, %r3111, %r3091;
	or.b32  	%r3113, %r104, %r75;
	add.s32 	%r3114, %r3113, %r3082;
	add.s32 	%r3115, %r3114, %r3112;
	add.s32 	%r3116, %r3115, -1990404162;
	shf.l.wrap.b32 	%r3117, %r3116, %r3116, 22;
	add.s32 	%r3118, %r3117, %r3109;
	xor.b32  	%r3119, %r3109, %r3100;
	and.b32  	%r3120, %r3118, %r3119;
	xor.b32  	%r3121, %r3120, %r3100;
	or.b32  	%r3122, %r105, %r74;
	add.s32 	%r3123, %r3122, %r3091;
	add.s32 	%r3124, %r3123, %r3121;
	add.s32 	%r3125, %r3124, 1804603682;
	shf.l.wrap.b32 	%r3126, %r3125, %r3125, 7;
	add.s32 	%r3127, %r3126, %r3118;
	xor.b32  	%r3128, %r3118, %r3109;
	and.b32  	%r3129, %r3127, %r3128;
	xor.b32  	%r3130, %r3129, %r3109;
	or.b32  	%r3131, %r106, %r73;
	add.s32 	%r3132, %r3131, %r3100;
	add.s32 	%r3133, %r3132, %r3130;
	add.s32 	%r3134, %r3133, -40341101;
	shf.l.wrap.b32 	%r3135, %r3134, %r3134, 12;
	add.s32 	%r3136, %r3135, %r3127;
	xor.b32  	%r3137, %r3127, %r3118;
	and.b32  	%r3138, %r3136, %r3137;
	xor.b32  	%r3139, %r3138, %r3118;
	or.b32  	%r3140, %r107, %r72;
	add.s32 	%r3141, %r3140, %r3109;
	add.s32 	%r3142, %r3141, %r3139;
	add.s32 	%r3143, %r3142, -1502002290;
	shf.l.wrap.b32 	%r3144, %r3143, %r3143, 17;
	add.s32 	%r3145, %r3144, %r3136;
	xor.b32  	%r3146, %r3136, %r3127;
	and.b32  	%r3147, %r3145, %r3146;
	xor.b32  	%r3148, %r3147, %r3127;
	or.b32  	%r3149, %r108, %r71;
	add.s32 	%r3150, %r3149, %r3118;
	add.s32 	%r3151, %r3150, %r3148;
	add.s32 	%r3152, %r3151, 1236535329;
	shf.l.wrap.b32 	%r3153, %r3152, %r3152, 22;
	add.s32 	%r3154, %r3153, %r3145;
	xor.b32  	%r3155, %r3154, %r3145;
	and.b32  	%r3156, %r3155, %r3136;
	xor.b32  	%r3157, %r3156, %r3145;
	add.s32 	%r3158, %r3023, %r3127;
	add.s32 	%r3159, %r3158, %r3157;
	add.s32 	%r3160, %r3159, -165796510;
	shf.l.wrap.b32 	%r3161, %r3160, %r3160, 5;
	add.s32 	%r3162, %r3161, %r3154;
	xor.b32  	%r3163, %r3162, %r3154;
	and.b32  	%r3164, %r3163, %r3145;
	xor.b32  	%r3165, %r3164, %r3154;
	add.s32 	%r3166, %r3068, %r3136;
	add.s32 	%r3167, %r3166, %r3165;
	add.s32 	%r3168, %r3167, -1069501632;
	shf.l.wrap.b32 	%r3169, %r3168, %r3168, 9;
	add.s32 	%r3170, %r3169, %r3162;
	xor.b32  	%r3171, %r3170, %r3162;
	and.b32  	%r3172, %r3171, %r3154;
	xor.b32  	%r3173, %r3172, %r3162;
	add.s32 	%r3174, %r3113, %r3145;
	add.s32 	%r3175, %r3174, %r3173;
	add.s32 	%r3176, %r3175, 643717713;
	shf.l.wrap.b32 	%r3177, %r3176, %r3176, 14;
	add.s32 	%r3178, %r3177, %r3170;
	xor.b32  	%r3179, %r3178, %r3170;
	and.b32  	%r3180, %r3179, %r3162;
	xor.b32  	%r3181, %r3180, %r3170;
	add.s32 	%r3182, %r3015, %r3154;
	add.s32 	%r3183, %r3182, %r3181;
	add.s32 	%r3184, %r3183, -373897302;
	shf.l.wrap.b32 	%r3185, %r3184, %r3184, 20;
	add.s32 	%r3186, %r3185, %r3178;
	xor.b32  	%r3187, %r3186, %r3178;
	and.b32  	%r3188, %r3187, %r3170;
	xor.b32  	%r3189, %r3188, %r3178;
	add.s32 	%r3190, %r3059, %r3162;
	add.s32 	%r3191, %r3190, %r3189;
	add.s32 	%r3192, %r3191, -701558691;
	shf.l.wrap.b32 	%r3193, %r3192, %r3192, 5;
	add.s32 	%r3194, %r3193, %r3186;
	xor.b32  	%r3195, %r3194, %r3186;
	and.b32  	%r3196, %r3195, %r3178;
	xor.b32  	%r3197, %r3196, %r3186;
	add.s32 	%r3198, %r3104, %r3170;
	add.s32 	%r3199, %r3198, %r3197;
	add.s32 	%r3200, %r3199, 38016083;
	shf.l.wrap.b32 	%r3201, %r3200, %r3200, 9;
	add.s32 	%r3202, %r3201, %r3194;
	xor.b32  	%r3203, %r3202, %r3194;
	and.b32  	%r3204, %r3203, %r3186;
	xor.b32  	%r3205, %r3204, %r3194;
	add.s32 	%r3206, %r3149, %r3178;
	add.s32 	%r3207, %r3206, %r3205;
	add.s32 	%r3208, %r3207, -660478335;
	shf.l.wrap.b32 	%r3209, %r3208, %r3208, 14;
	add.s32 	%r3210, %r3209, %r3202;
	xor.b32  	%r3211, %r3210, %r3202;
	and.b32  	%r3212, %r3211, %r3194;
	xor.b32  	%r3213, %r3212, %r3202;
	add.s32 	%r3214, %r3050, %r3186;
	add.s32 	%r3215, %r3214, %r3213;
	add.s32 	%r3216, %r3215, -405537848;
	shf.l.wrap.b32 	%r3217, %r3216, %r3216, 20;
	add.s32 	%r3218, %r3217, %r3210;
	xor.b32  	%r3219, %r3218, %r3210;
	and.b32  	%r3220, %r3219, %r3202;
	xor.b32  	%r3221, %r3220, %r3210;
	add.s32 	%r3222, %r3095, %r3194;
	add.s32 	%r3223, %r3222, %r3221;
	add.s32 	%r3224, %r3223, 568446438;
	shf.l.wrap.b32 	%r3225, %r3224, %r3224, 5;
	add.s32 	%r3226, %r3225, %r3218;
	xor.b32  	%r3227, %r3226, %r3218;
	and.b32  	%r3228, %r3227, %r3210;
	xor.b32  	%r3229, %r3228, %r3218;
	add.s32 	%r3230, %r3140, %r3202;
	add.s32 	%r3231, %r3230, %r3229;
	add.s32 	%r3232, %r3231, -1019803690;
	shf.l.wrap.b32 	%r3233, %r3232, %r3232, 9;
	add.s32 	%r3234, %r3233, %r3226;
	xor.b32  	%r3235, %r3234, %r3226;
	and.b32  	%r3236, %r3235, %r3218;
	xor.b32  	%r3237, %r3236, %r3226;
	add.s32 	%r3238, %r3041, %r3210;
	add.s32 	%r3239, %r3238, %r3237;
	add.s32 	%r3240, %r3239, -187363961;
	shf.l.wrap.b32 	%r3241, %r3240, %r3240, 14;
	add.s32 	%r3242, %r3241, %r3234;
	xor.b32  	%r3243, %r3242, %r3234;
	and.b32  	%r3244, %r3243, %r3226;
	xor.b32  	%r3245, %r3244, %r3234;
	add.s32 	%r3246, %r3086, %r3218;
	add.s32 	%r3247, %r3246, %r3245;
	add.s32 	%r3248, %r3247, 1163531501;
	shf.l.wrap.b32 	%r3249, %r3248, %r3248, 20;
	add.s32 	%r3250, %r3249, %r3242;
	xor.b32  	%r3251, %r3250, %r3242;
	and.b32  	%r3252, %r3251, %r3234;
	xor.b32  	%r3253, %r3252, %r3242;
	add.s32 	%r3254, %r3131, %r3226;
	add.s32 	%r3255, %r3254, %r3253;
	add.s32 	%r3256, %r3255, -1444681467;
	shf.l.wrap.b32 	%r3257, %r3256, %r3256, 5;
	add.s32 	%r3258, %r3257, %r3250;
	xor.b32  	%r3259, %r3258, %r3250;
	and.b32  	%r3260, %r3259, %r3242;
	xor.b32  	%r3261, %r3260, %r3250;
	add.s32 	%r3262, %r3032, %r3234;
	add.s32 	%r3263, %r3262, %r3261;
	add.s32 	%r3264, %r3263, -51403784;
	shf.l.wrap.b32 	%r3265, %r3264, %r3264, 9;
	add.s32 	%r3266, %r3265, %r3258;
	xor.b32  	%r3267, %r3266, %r3258;
	and.b32  	%r3268, %r3267, %r3250;
	xor.b32  	%r3269, %r3268, %r3258;
	add.s32 	%r3270, %r3077, %r3242;
	add.s32 	%r3271, %r3270, %r3269;
	add.s32 	%r3272, %r3271, 1735328473;
	shf.l.wrap.b32 	%r3273, %r3272, %r3272, 14;
	add.s32 	%r3274, %r3273, %r3266;
	xor.b32  	%r3275, %r3274, %r3266;
	and.b32  	%r3276, %r3275, %r3258;
	xor.b32  	%r3277, %r3276, %r3266;
	add.s32 	%r3278, %r3122, %r3250;
	add.s32 	%r3279, %r3278, %r3277;
	add.s32 	%r3280, %r3279, -1926607734;
	shf.l.wrap.b32 	%r3281, %r3280, %r3280, 20;
	add.s32 	%r3282, %r3281, %r3274;
	xor.b32  	%r3283, %r3282, %r3274;
	xor.b32  	%r3284, %r3283, %r3266;
	add.s32 	%r3285, %r3059, %r3258;
	add.s32 	%r3286, %r3285, %r3284;
	add.s32 	%r3287, %r3286, -378558;
	shf.l.wrap.b32 	%r3288, %r3287, %r3287, 4;
	add.s32 	%r3289, %r3288, %r3282;
	xor.b32  	%r3290, %r3289, %r3283;
	add.s32 	%r3291, %r3086, %r3266;
	add.s32 	%r3292, %r3291, %r3290;
	add.s32 	%r3293, %r3292, -2022574463;
	shf.l.wrap.b32 	%r3294, %r3293, %r3293, 11;
	add.s32 	%r3295, %r3294, %r3289;
	xor.b32  	%r3296, %r3295, %r3289;
	xor.b32  	%r3297, %r3296, %r3282;
	add.s32 	%r3298, %r3113, %r3274;
	add.s32 	%r3299, %r3298, %r3297;
	add.s32 	%r3300, %r3299, 1839030562;
	shf.l.wrap.b32 	%r3301, %r3300, %r3300, 16;
	add.s32 	%r3302, %r3301, %r3295;
	xor.b32  	%r3303, %r3302, %r3296;
	add.s32 	%r3304, %r3140, %r3282;
	add.s32 	%r3305, %r3304, %r3303;
	add.s32 	%r3306, %r3305, -35309556;
	shf.l.wrap.b32 	%r3307, %r3306, %r3306, 23;
	add.s32 	%r3308, %r3307, %r3302;
	xor.b32  	%r3309, %r3308, %r3302;
	xor.b32  	%r3310, %r3309, %r3295;
	add.s32 	%r3311, %r3023, %r3289;
	add.s32 	%r3312, %r3311, %r3310;
	add.s32 	%r3313, %r3312, -1530992060;
	shf.l.wrap.b32 	%r3314, %r3313, %r3313, 4;
	add.s32 	%r3315, %r3314, %r3308;
	xor.b32  	%r3316, %r3315, %r3309;
	add.s32 	%r3317, %r3050, %r3295;
	add.s32 	%r3318, %r3317, %r3316;
	add.s32 	%r3319, %r3318, 1272893353;
	shf.l.wrap.b32 	%r3320, %r3319, %r3319, 11;
	add.s32 	%r3321, %r3320, %r3315;
	xor.b32  	%r3322, %r3321, %r3315;
	xor.b32  	%r3323, %r3322, %r3308;
	add.s32 	%r3324, %r3077, %r3302;
	add.s32 	%r3325, %r3324, %r3323;
	add.s32 	%r3326, %r3325, -155497632;
	shf.l.wrap.b32 	%r3327, %r3326, %r3326, 16;
	add.s32 	%r3328, %r3327, %r3321;
	xor.b32  	%r3329, %r3328, %r3322;
	add.s32 	%r3330, %r3104, %r3308;
	add.s32 	%r3331, %r3330, %r3329;
	add.s32 	%r3332, %r3331, -1094730640;
	shf.l.wrap.b32 	%r3333, %r3332, %r3332, 23;
	add.s32 	%r3334, %r3333, %r3328;
	xor.b32  	%r3335, %r3334, %r3328;
	xor.b32  	%r3336, %r3335, %r3321;
	add.s32 	%r3337, %r3131, %r3315;
	add.s32 	%r3338, %r3337, %r3336;
	add.s32 	%r3339, %r3338, 681279174;
	shf.l.wrap.b32 	%r3340, %r3339, %r3339, 4;
	add.s32 	%r3341, %r3340, %r3334;
	xor.b32  	%r3342, %r3341, %r3335;
	add.s32 	%r3343, %r3015, %r3321;
	add.s32 	%r3344, %r3343, %r3342;
	add.s32 	%r3345, %r3344, -358537222;
	shf.l.wrap.b32 	%r3346, %r3345, %r3345, 11;
	add.s32 	%r3347, %r3346, %r3341;
	xor.b32  	%r3348, %r3347, %r3341;
	xor.b32  	%r3349, %r3348, %r3334;
	add.s32 	%r3350, %r3041, %r3328;
	add.s32 	%r3351, %r3350, %r3349;
	add.s32 	%r3352, %r3351, -722521979;
	shf.l.wrap.b32 	%r3353, %r3352, %r3352, 16;
	add.s32 	%r3354, %r3353, %r3347;
	xor.b32  	%r3355, %r3354, %r3348;
	add.s32 	%r3356, %r3068, %r3334;
	add.s32 	%r3357, %r3356, %r3355;
	add.s32 	%r3358, %r3357, 76029189;
	shf.l.wrap.b32 	%r3359, %r3358, %r3358, 23;
	add.s32 	%r3360, %r3359, %r3354;
	xor.b32  	%r3361, %r3360, %r3354;
	xor.b32  	%r3362, %r3361, %r3347;
	add.s32 	%r3363, %r3095, %r3341;
	add.s32 	%r3364, %r3363, %r3362;
	add.s32 	%r3365, %r3364, -640364487;
	shf.l.wrap.b32 	%r3366, %r3365, %r3365, 4;
	add.s32 	%r3367, %r3366, %r3360;
	xor.b32  	%r3368, %r3367, %r3361;
	add.s32 	%r3369, %r3122, %r3347;
	add.s32 	%r3370, %r3369, %r3368;
	add.s32 	%r3371, %r3370, -421815835;
	shf.l.wrap.b32 	%r3372, %r3371, %r3371, 11;
	add.s32 	%r3373, %r3372, %r3367;
	xor.b32  	%r3374, %r3373, %r3367;
	xor.b32  	%r3375, %r3374, %r3360;
	add.s32 	%r3376, %r3149, %r3354;
	add.s32 	%r3377, %r3376, %r3375;
	add.s32 	%r3378, %r3377, 530742520;
	shf.l.wrap.b32 	%r3379, %r3378, %r3378, 16;
	add.s32 	%r3380, %r3379, %r3373;
	xor.b32  	%r3381, %r3380, %r3374;
	add.s32 	%r3382, %r3032, %r3360;
	add.s32 	%r3383, %r3382, %r3381;
	add.s32 	%r3384, %r3383, -995338651;
	shf.l.wrap.b32 	%r3385, %r3384, %r3384, 23;
	add.s32 	%r3386, %r3385, %r3380;
	not.b32 	%r3387, %r3373;
	or.b32  	%r3388, %r3386, %r3387;
	xor.b32  	%r3389, %r3388, %r3380;
	add.s32 	%r3390, %r3015, %r3367;
	add.s32 	%r3391, %r3390, %r3389;
	add.s32 	%r3392, %r3391, -198630844;
	shf.l.wrap.b32 	%r3393, %r3392, %r3392, 6;
	add.s32 	%r3394, %r3393, %r3386;
	not.b32 	%r3395, %r3380;
	or.b32  	%r3396, %r3394, %r3395;
	xor.b32  	%r3397, %r3396, %r3386;
	add.s32 	%r3398, %r3077, %r3373;
	add.s32 	%r3399, %r3398, %r3397;
	add.s32 	%r3400, %r3399, 1126891415;
	shf.l.wrap.b32 	%r3401, %r3400, %r3400, 10;
	add.s32 	%r3402, %r3401, %r3394;
	not.b32 	%r3403, %r3386;
	or.b32  	%r3404, %r3402, %r3403;
	xor.b32  	%r3405, %r3404, %r3394;
	add.s32 	%r3406, %r3140, %r3380;
	add.s32 	%r3407, %r3406, %r3405;
	add.s32 	%r3408, %r3407, -1416354905;
	shf.l.wrap.b32 	%r3409, %r3408, %r3408, 15;
	add.s32 	%r3410, %r3409, %r3402;
	not.b32 	%r3411, %r3394;
	or.b32  	%r3412, %r3410, %r3411;
	xor.b32  	%r3413, %r3412, %r3402;
	add.s32 	%r3414, %r3059, %r3386;
	add.s32 	%r3415, %r3414, %r3413;
	add.s32 	%r3416, %r3415, -57434055;
	shf.l.wrap.b32 	%r3417, %r3416, %r3416, 21;
	add.s32 	%r3418, %r3417, %r3410;
	not.b32 	%r3419, %r3402;
	or.b32  	%r3420, %r3418, %r3419;
	xor.b32  	%r3421, %r3420, %r3410;
	add.s32 	%r3422, %r3122, %r3394;
	add.s32 	%r3423, %r3422, %r3421;
	add.s32 	%r3424, %r3423, 1700485571;
	shf.l.wrap.b32 	%r3425, %r3424, %r3424, 6;
	add.s32 	%r3426, %r3425, %r3418;
	not.b32 	%r3427, %r3410;
	or.b32  	%r3428, %r3426, %r3427;
	xor.b32  	%r3429, %r3428, %r3418;
	add.s32 	%r3430, %r3041, %r3402;
	add.s32 	%r3431, %r3430, %r3429;
	add.s32 	%r3432, %r3431, -1894986606;
	shf.l.wrap.b32 	%r3433, %r3432, %r3432, 10;
	add.s32 	%r3434, %r3433, %r3426;
	not.b32 	%r3435, %r3418;
	or.b32  	%r3436, %r3434, %r3435;
	xor.b32  	%r3437, %r3436, %r3426;
	add.s32 	%r3438, %r3104, %r3410;
	add.s32 	%r3439, %r3438, %r3437;
	add.s32 	%r3440, %r3439, -1051523;
	shf.l.wrap.b32 	%r3441, %r3440, %r3440, 15;
	add.s32 	%r3442, %r3441, %r3434;
	not.b32 	%r3443, %r3426;
	or.b32  	%r3444, %r3442, %r3443;
	xor.b32  	%r3445, %r3444, %r3434;
	add.s32 	%r3446, %r3023, %r3418;
	add.s32 	%r3447, %r3446, %r3445;
	add.s32 	%r3448, %r3447, -2054922799;
	shf.l.wrap.b32 	%r3449, %r3448, %r3448, 21;
	add.s32 	%r3450, %r3449, %r3442;
	not.b32 	%r3451, %r3434;
	or.b32  	%r3452, %r3450, %r3451;
	xor.b32  	%r3453, %r3452, %r3442;
	add.s32 	%r3454, %r3086, %r3426;
	add.s32 	%r3455, %r3454, %r3453;
	add.s32 	%r3456, %r3455, 1873313359;
	shf.l.wrap.b32 	%r3457, %r3456, %r3456, 6;
	add.s32 	%r3458, %r3457, %r3450;
	not.b32 	%r3459, %r3442;
	or.b32  	%r3460, %r3458, %r3459;
	xor.b32  	%r3461, %r3460, %r3450;
	add.s32 	%r3462, %r3149, %r3434;
	add.s32 	%r3463, %r3462, %r3461;
	add.s32 	%r3464, %r3463, -30611744;
	shf.l.wrap.b32 	%r3465, %r3464, %r3464, 10;
	add.s32 	%r3466, %r3465, %r3458;
	not.b32 	%r3467, %r3450;
	or.b32  	%r3468, %r3466, %r3467;
	xor.b32  	%r3469, %r3468, %r3458;
	add.s32 	%r3470, %r3068, %r3442;
	add.s32 	%r3471, %r3470, %r3469;
	add.s32 	%r3472, %r3471, -1560198380;
	shf.l.wrap.b32 	%r3473, %r3472, %r3472, 15;
	add.s32 	%r3474, %r3473, %r3466;
	not.b32 	%r3475, %r3458;
	or.b32  	%r3476, %r3474, %r3475;
	xor.b32  	%r3477, %r3476, %r3466;
	add.s32 	%r3478, %r3131, %r3450;
	add.s32 	%r3479, %r3478, %r3477;
	add.s32 	%r3480, %r3479, 1309151649;
	shf.l.wrap.b32 	%r3481, %r3480, %r3480, 21;
	add.s32 	%r3482, %r3481, %r3474;
	not.b32 	%r3483, %r3466;
	or.b32  	%r3484, %r3482, %r3483;
	xor.b32  	%r3485, %r3484, %r3474;
	add.s32 	%r3486, %r3050, %r3458;
	add.s32 	%r3487, %r3486, %r3485;
	add.s32 	%r3488, %r3487, -145523070;
	shf.l.wrap.b32 	%r3489, %r3488, %r3488, 6;
	add.s32 	%r3490, %r3489, %r3482;
	not.b32 	%r3491, %r3474;
	or.b32  	%r3492, %r3490, %r3491;
	xor.b32  	%r3493, %r3492, %r3482;
	add.s32 	%r3494, %r3113, %r3466;
	add.s32 	%r3495, %r3494, %r3493;
	add.s32 	%r3496, %r3495, -1120210379;
	shf.l.wrap.b32 	%r3497, %r3496, %r3496, 10;
	add.s32 	%r3498, %r3497, %r3490;
	not.b32 	%r3499, %r3482;
	or.b32  	%r3500, %r3498, %r3499;
	xor.b32  	%r3501, %r3500, %r3490;
	add.s32 	%r3502, %r3032, %r3474;
	add.s32 	%r3503, %r3502, %r3501;
	add.s32 	%r3504, %r3503, 718787259;
	shf.l.wrap.b32 	%r3505, %r3504, %r3504, 15;
	add.s32 	%r3506, %r3505, %r3498;
	not.b32 	%r3507, %r3490;
	or.b32  	%r3508, %r3506, %r3507;
	xor.b32  	%r3509, %r3508, %r3498;
	add.s32 	%r3510, %r3095, %r3482;
	add.s32 	%r3511, %r3510, %r3509;
	add.s32 	%r3512, %r3511, -343485551;
	shf.l.wrap.b32 	%r3513, %r3512, %r3512, 21;
	add.s32 	%r90, %r3490, %r90;
	add.s32 	%r3514, %r3506, %r89;
	add.s32 	%r89, %r3514, %r3513;
	add.s32 	%r88, %r3506, %r88;
	add.s32 	%r87, %r3498, %r87;
	bra.uni 	BB3_111;

BB3_63:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_78:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_70:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_85:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_66:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_81:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_73:
	mov.u32 	%r7776, %r93;
	bra.uni 	BB3_110;

BB3_88:
	mov.u32 	%r7776, %r93;

BB3_110:
	or.b32  	%r7768, %r7776, %r86;
	or.b32  	%r7767, %r94, %r85;
	or.b32  	%r7766, %r95, %r84;
	or.b32  	%r7765, %r96, %r83;
	or.b32  	%r7769, %r97, %r82;
	or.b32  	%r7770, %r98, %r81;
	or.b32  	%r7771, %r99, %r80;
	or.b32  	%r7772, %r100, %r79;
	or.b32  	%r7744, %r101, %r78;
	or.b32  	%r7743, %r102, %r77;
	or.b32  	%r7742, %r103, %r76;
	or.b32  	%r7741, %r104, %r75;
	or.b32  	%r7748, %r105, %r74;
	or.b32  	%r7747, %r106, %r73;
	or.b32  	%r7746, %r107, %r72;
	or.b32  	%r7745, %r108, %r71;

BB3_111:
	bfe.u32 	%r4182, %r111, 2, 2;
	and.b32  	%r4183, %r111, 3;
	shl.b32 	%r4184, %r4183, 3;
	mov.u32 	%r4185, 255;
	shl.b32 	%r4186, %r4185, %r4184;
	setp.eq.s32	%p69, %r4182, 0;
	selp.b32	%r4187, %r4186, 0, %p69;
	setp.eq.s32	%p70, %r4182, 1;
	selp.b32	%r4188, %r4186, 0, %p70;
	setp.eq.s32	%p71, %r4182, 2;
	selp.b32	%r4189, %r4186, 0, %p71;
	setp.eq.s32	%p72, %r4182, 3;
	selp.b32	%r4190, %r4186, 0, %p72;
	and.b32  	%r4191, %r111, 63;
	bfe.u32 	%r4192, %r111, 4, 2;
	setp.eq.s32	%p73, %r4192, 0;
	selp.b32	%r4193, -2139062144, 0, %p73;
	and.b32  	%r4194, %r4187, %r4193;
	or.b32  	%r7822, %r7768, %r4194;
	and.b32  	%r4195, %r4188, %r4193;
	or.b32  	%r7821, %r7767, %r4195;
	and.b32  	%r4196, %r4189, %r4193;
	or.b32  	%r7820, %r7766, %r4196;
	and.b32  	%r4197, %r4190, %r4193;
	or.b32  	%r7819, %r7765, %r4197;
	setp.eq.s32	%p74, %r4192, 1;
	selp.b32	%r4198, -2139062144, 0, %p74;
	and.b32  	%r4199, %r4187, %r4198;
	or.b32  	%r7818, %r7769, %r4199;
	and.b32  	%r4200, %r4188, %r4198;
	or.b32  	%r7817, %r7770, %r4200;
	and.b32  	%r4201, %r4189, %r4198;
	or.b32  	%r7816, %r7771, %r4201;
	and.b32  	%r4202, %r4190, %r4198;
	or.b32  	%r7815, %r7772, %r4202;
	setp.eq.s32	%p75, %r4192, 2;
	selp.b32	%r4203, -2139062144, 0, %p75;
	and.b32  	%r4204, %r4187, %r4203;
	or.b32  	%r7814, %r7744, %r4204;
	and.b32  	%r4205, %r4188, %r4203;
	or.b32  	%r7813, %r7743, %r4205;
	and.b32  	%r4206, %r4189, %r4203;
	or.b32  	%r7812, %r7742, %r4206;
	and.b32  	%r4207, %r4190, %r4203;
	or.b32  	%r7811, %r7741, %r4207;
	setp.eq.s32	%p76, %r4192, 3;
	selp.b32	%r4208, -2139062144, 0, %p76;
	and.b32  	%r4209, %r4187, %r4208;
	or.b32  	%r7810, %r7748, %r4209;
	and.b32  	%r4210, %r4188, %r4208;
	or.b32  	%r7809, %r7747, %r4210;
	and.b32  	%r4211, %r4189, %r4208;
	or.b32  	%r624, %r7746, %r4211;
	and.b32  	%r4212, %r4190, %r4208;
	or.b32  	%r625, %r7745, %r4212;
	setp.lt.u32	%p77, %r4191, 56;
	@%p77 bra 	BB3_113;

	xor.b32  	%r4227, %r88, %r87;
	and.b32  	%r4228, %r89, %r4227;
	xor.b32  	%r4229, %r4228, %r87;
	add.s32 	%r4230, %r7822, %r90;
	add.s32 	%r4231, %r4230, %r4229;
	add.s32 	%r4232, %r4231, -680876936;
	shf.l.wrap.b32 	%r4233, %r4232, %r4232, 7;
	add.s32 	%r4234, %r4233, %r89;
	xor.b32  	%r4235, %r89, %r88;
	and.b32  	%r4236, %r4234, %r4235;
	xor.b32  	%r4237, %r4236, %r88;
	add.s32 	%r4238, %r7821, %r87;
	add.s32 	%r4239, %r4238, %r4237;
	add.s32 	%r4240, %r4239, -389564586;
	shf.l.wrap.b32 	%r4241, %r4240, %r4240, 12;
	add.s32 	%r4242, %r4241, %r4234;
	xor.b32  	%r4243, %r4234, %r89;
	and.b32  	%r4244, %r4242, %r4243;
	xor.b32  	%r4245, %r4244, %r89;
	add.s32 	%r4246, %r7820, %r88;
	add.s32 	%r4247, %r4246, %r4245;
	add.s32 	%r4248, %r4247, 606105819;
	shf.l.wrap.b32 	%r4249, %r4248, %r4248, 17;
	add.s32 	%r4250, %r4249, %r4242;
	xor.b32  	%r4251, %r4242, %r4234;
	and.b32  	%r4252, %r4250, %r4251;
	xor.b32  	%r4253, %r4252, %r4234;
	add.s32 	%r4254, %r7819, %r89;
	add.s32 	%r4255, %r4254, %r4253;
	add.s32 	%r4256, %r4255, -1044525330;
	shf.l.wrap.b32 	%r4257, %r4256, %r4256, 22;
	add.s32 	%r4258, %r4257, %r4250;
	xor.b32  	%r4259, %r4250, %r4242;
	and.b32  	%r4260, %r4258, %r4259;
	xor.b32  	%r4261, %r4260, %r4242;
	add.s32 	%r4262, %r7818, %r4234;
	add.s32 	%r4263, %r4262, %r4261;
	add.s32 	%r4264, %r4263, -176418897;
	shf.l.wrap.b32 	%r4265, %r4264, %r4264, 7;
	add.s32 	%r4266, %r4265, %r4258;
	xor.b32  	%r4267, %r4258, %r4250;
	and.b32  	%r4268, %r4266, %r4267;
	xor.b32  	%r4269, %r4268, %r4250;
	add.s32 	%r4270, %r7817, %r4242;
	add.s32 	%r4271, %r4270, %r4269;
	add.s32 	%r4272, %r4271, 1200080426;
	shf.l.wrap.b32 	%r4273, %r4272, %r4272, 12;
	add.s32 	%r4274, %r4273, %r4266;
	xor.b32  	%r4275, %r4266, %r4258;
	and.b32  	%r4276, %r4274, %r4275;
	xor.b32  	%r4277, %r4276, %r4258;
	add.s32 	%r4278, %r7816, %r4250;
	add.s32 	%r4279, %r4278, %r4277;
	add.s32 	%r4280, %r4279, -1473231341;
	shf.l.wrap.b32 	%r4281, %r4280, %r4280, 17;
	add.s32 	%r4282, %r4281, %r4274;
	xor.b32  	%r4283, %r4274, %r4266;
	and.b32  	%r4284, %r4282, %r4283;
	xor.b32  	%r4285, %r4284, %r4266;
	add.s32 	%r4286, %r7815, %r4258;
	add.s32 	%r4287, %r4286, %r4285;
	add.s32 	%r4288, %r4287, -45705983;
	shf.l.wrap.b32 	%r4289, %r4288, %r4288, 22;
	add.s32 	%r4290, %r4289, %r4282;
	xor.b32  	%r4291, %r4282, %r4274;
	and.b32  	%r4292, %r4290, %r4291;
	xor.b32  	%r4293, %r4292, %r4274;
	add.s32 	%r4294, %r7814, %r4266;
	add.s32 	%r4295, %r4294, %r4293;
	add.s32 	%r4296, %r4295, 1770035416;
	shf.l.wrap.b32 	%r4297, %r4296, %r4296, 7;
	add.s32 	%r4298, %r4297, %r4290;
	xor.b32  	%r4299, %r4290, %r4282;
	and.b32  	%r4300, %r4298, %r4299;
	xor.b32  	%r4301, %r4300, %r4282;
	add.s32 	%r4302, %r7813, %r4274;
	add.s32 	%r4303, %r4302, %r4301;
	add.s32 	%r4304, %r4303, -1958414417;
	shf.l.wrap.b32 	%r4305, %r4304, %r4304, 12;
	add.s32 	%r4306, %r4305, %r4298;
	xor.b32  	%r4307, %r4298, %r4290;
	and.b32  	%r4308, %r4306, %r4307;
	xor.b32  	%r4309, %r4308, %r4290;
	add.s32 	%r4310, %r7812, %r4282;
	add.s32 	%r4311, %r4310, %r4309;
	add.s32 	%r4312, %r4311, -42063;
	shf.l.wrap.b32 	%r4313, %r4312, %r4312, 17;
	add.s32 	%r4314, %r4313, %r4306;
	xor.b32  	%r4315, %r4306, %r4298;
	and.b32  	%r4316, %r4314, %r4315;
	xor.b32  	%r4317, %r4316, %r4298;
	add.s32 	%r4318, %r7811, %r4290;
	add.s32 	%r4319, %r4318, %r4317;
	add.s32 	%r4320, %r4319, -1990404162;
	shf.l.wrap.b32 	%r4321, %r4320, %r4320, 22;
	add.s32 	%r4322, %r4321, %r4314;
	xor.b32  	%r4323, %r4314, %r4306;
	and.b32  	%r4324, %r4322, %r4323;
	xor.b32  	%r4325, %r4324, %r4306;
	add.s32 	%r4326, %r7810, %r4298;
	add.s32 	%r4327, %r4326, %r4325;
	add.s32 	%r4328, %r4327, 1804603682;
	shf.l.wrap.b32 	%r4329, %r4328, %r4328, 7;
	add.s32 	%r4330, %r4329, %r4322;
	xor.b32  	%r4331, %r4322, %r4314;
	and.b32  	%r4332, %r4330, %r4331;
	xor.b32  	%r4333, %r4332, %r4314;
	add.s32 	%r4334, %r7809, %r4306;
	add.s32 	%r4335, %r4334, %r4333;
	add.s32 	%r4336, %r4335, -40341101;
	shf.l.wrap.b32 	%r4337, %r4336, %r4336, 12;
	add.s32 	%r4338, %r4337, %r4330;
	xor.b32  	%r4339, %r4330, %r4322;
	and.b32  	%r4340, %r4338, %r4339;
	xor.b32  	%r4341, %r4340, %r4322;
	add.s32 	%r4342, %r624, %r4314;
	add.s32 	%r4343, %r4342, %r4341;
	add.s32 	%r4344, %r4343, -1502002290;
	shf.l.wrap.b32 	%r4345, %r4344, %r4344, 17;
	add.s32 	%r4346, %r4345, %r4338;
	xor.b32  	%r4347, %r4338, %r4330;
	and.b32  	%r4348, %r4346, %r4347;
	xor.b32  	%r4349, %r4348, %r4330;
	add.s32 	%r4350, %r625, %r4322;
	add.s32 	%r4351, %r4350, %r4349;
	add.s32 	%r4352, %r4351, 1236535329;
	shf.l.wrap.b32 	%r4353, %r4352, %r4352, 22;
	add.s32 	%r4354, %r4353, %r4346;
	xor.b32  	%r4355, %r4354, %r4346;
	and.b32  	%r4356, %r4355, %r4338;
	xor.b32  	%r4357, %r4356, %r4346;
	add.s32 	%r4358, %r7821, %r4330;
	add.s32 	%r4359, %r4358, %r4357;
	add.s32 	%r4360, %r4359, -165796510;
	shf.l.wrap.b32 	%r4361, %r4360, %r4360, 5;
	add.s32 	%r4362, %r4361, %r4354;
	xor.b32  	%r4363, %r4362, %r4354;
	and.b32  	%r4364, %r4363, %r4346;
	xor.b32  	%r4365, %r4364, %r4354;
	add.s32 	%r4366, %r7816, %r4338;
	add.s32 	%r4367, %r4366, %r4365;
	add.s32 	%r4368, %r4367, -1069501632;
	shf.l.wrap.b32 	%r4369, %r4368, %r4368, 9;
	add.s32 	%r4370, %r4369, %r4362;
	xor.b32  	%r4371, %r4370, %r4362;
	and.b32  	%r4372, %r4371, %r4354;
	xor.b32  	%r4373, %r4372, %r4362;
	add.s32 	%r4374, %r7811, %r4346;
	add.s32 	%r4375, %r4374, %r4373;
	add.s32 	%r4376, %r4375, 643717713;
	shf.l.wrap.b32 	%r4377, %r4376, %r4376, 14;
	add.s32 	%r4378, %r4377, %r4370;
	xor.b32  	%r4379, %r4378, %r4370;
	and.b32  	%r4380, %r4379, %r4362;
	xor.b32  	%r4381, %r4380, %r4370;
	add.s32 	%r4382, %r7822, %r4354;
	add.s32 	%r4383, %r4382, %r4381;
	add.s32 	%r4384, %r4383, -373897302;
	shf.l.wrap.b32 	%r4385, %r4384, %r4384, 20;
	add.s32 	%r4386, %r4385, %r4378;
	xor.b32  	%r4387, %r4386, %r4378;
	and.b32  	%r4388, %r4387, %r4370;
	xor.b32  	%r4389, %r4388, %r4378;
	add.s32 	%r4390, %r7817, %r4362;
	add.s32 	%r4391, %r4390, %r4389;
	add.s32 	%r4392, %r4391, -701558691;
	shf.l.wrap.b32 	%r4393, %r4392, %r4392, 5;
	add.s32 	%r4394, %r4393, %r4386;
	xor.b32  	%r4395, %r4394, %r4386;
	and.b32  	%r4396, %r4395, %r4378;
	xor.b32  	%r4397, %r4396, %r4386;
	add.s32 	%r4398, %r7812, %r4370;
	add.s32 	%r4399, %r4398, %r4397;
	add.s32 	%r4400, %r4399, 38016083;
	shf.l.wrap.b32 	%r4401, %r4400, %r4400, 9;
	add.s32 	%r4402, %r4401, %r4394;
	xor.b32  	%r4403, %r4402, %r4394;
	and.b32  	%r4404, %r4403, %r4386;
	xor.b32  	%r4405, %r4404, %r4394;
	add.s32 	%r4406, %r625, %r4378;
	add.s32 	%r4407, %r4406, %r4405;
	add.s32 	%r4408, %r4407, -660478335;
	shf.l.wrap.b32 	%r4409, %r4408, %r4408, 14;
	add.s32 	%r4410, %r4409, %r4402;
	xor.b32  	%r4411, %r4410, %r4402;
	and.b32  	%r4412, %r4411, %r4394;
	xor.b32  	%r4413, %r4412, %r4402;
	add.s32 	%r4414, %r7818, %r4386;
	add.s32 	%r4415, %r4414, %r4413;
	add.s32 	%r4416, %r4415, -405537848;
	shf.l.wrap.b32 	%r4417, %r4416, %r4416, 20;
	add.s32 	%r4418, %r4417, %r4410;
	xor.b32  	%r4419, %r4418, %r4410;
	and.b32  	%r4420, %r4419, %r4402;
	xor.b32  	%r4421, %r4420, %r4410;
	add.s32 	%r4422, %r7813, %r4394;
	add.s32 	%r4423, %r4422, %r4421;
	add.s32 	%r4424, %r4423, 568446438;
	shf.l.wrap.b32 	%r4425, %r4424, %r4424, 5;
	add.s32 	%r4426, %r4425, %r4418;
	xor.b32  	%r4427, %r4426, %r4418;
	and.b32  	%r4428, %r4427, %r4410;
	xor.b32  	%r4429, %r4428, %r4418;
	add.s32 	%r4430, %r624, %r4402;
	add.s32 	%r4431, %r4430, %r4429;
	add.s32 	%r4432, %r4431, -1019803690;
	shf.l.wrap.b32 	%r4433, %r4432, %r4432, 9;
	add.s32 	%r4434, %r4433, %r4426;
	xor.b32  	%r4435, %r4434, %r4426;
	and.b32  	%r4436, %r4435, %r4418;
	xor.b32  	%r4437, %r4436, %r4426;
	add.s32 	%r4438, %r7819, %r4410;
	add.s32 	%r4439, %r4438, %r4437;
	add.s32 	%r4440, %r4439, -187363961;
	shf.l.wrap.b32 	%r4441, %r4440, %r4440, 14;
	add.s32 	%r4442, %r4441, %r4434;
	xor.b32  	%r4443, %r4442, %r4434;
	and.b32  	%r4444, %r4443, %r4426;
	xor.b32  	%r4445, %r4444, %r4434;
	add.s32 	%r4446, %r7814, %r4418;
	add.s32 	%r4447, %r4446, %r4445;
	add.s32 	%r4448, %r4447, 1163531501;
	shf.l.wrap.b32 	%r4449, %r4448, %r4448, 20;
	add.s32 	%r4450, %r4449, %r4442;
	xor.b32  	%r4451, %r4450, %r4442;
	and.b32  	%r4452, %r4451, %r4434;
	xor.b32  	%r4453, %r4452, %r4442;
	add.s32 	%r4454, %r7809, %r4426;
	add.s32 	%r4455, %r4454, %r4453;
	add.s32 	%r4456, %r4455, -1444681467;
	shf.l.wrap.b32 	%r4457, %r4456, %r4456, 5;
	add.s32 	%r4458, %r4457, %r4450;
	xor.b32  	%r4459, %r4458, %r4450;
	and.b32  	%r4460, %r4459, %r4442;
	xor.b32  	%r4461, %r4460, %r4450;
	add.s32 	%r4462, %r7820, %r4434;
	add.s32 	%r4463, %r4462, %r4461;
	add.s32 	%r4464, %r4463, -51403784;
	shf.l.wrap.b32 	%r4465, %r4464, %r4464, 9;
	add.s32 	%r4466, %r4465, %r4458;
	xor.b32  	%r4467, %r4466, %r4458;
	and.b32  	%r4468, %r4467, %r4450;
	xor.b32  	%r4469, %r4468, %r4458;
	add.s32 	%r4470, %r7815, %r4442;
	add.s32 	%r4471, %r4470, %r4469;
	add.s32 	%r4472, %r4471, 1735328473;
	shf.l.wrap.b32 	%r4473, %r4472, %r4472, 14;
	add.s32 	%r4474, %r4473, %r4466;
	xor.b32  	%r4475, %r4474, %r4466;
	and.b32  	%r4476, %r4475, %r4458;
	xor.b32  	%r4477, %r4476, %r4466;
	add.s32 	%r4478, %r7810, %r4450;
	add.s32 	%r4479, %r4478, %r4477;
	add.s32 	%r4480, %r4479, -1926607734;
	shf.l.wrap.b32 	%r4481, %r4480, %r4480, 20;
	add.s32 	%r4482, %r4481, %r4474;
	xor.b32  	%r4483, %r4482, %r4474;
	xor.b32  	%r4484, %r4483, %r4466;
	add.s32 	%r4485, %r7817, %r4458;
	add.s32 	%r4486, %r4485, %r4484;
	add.s32 	%r4487, %r4486, -378558;
	shf.l.wrap.b32 	%r4488, %r4487, %r4487, 4;
	add.s32 	%r4489, %r4488, %r4482;
	xor.b32  	%r4490, %r4489, %r4483;
	add.s32 	%r4491, %r7814, %r4466;
	add.s32 	%r4492, %r4491, %r4490;
	add.s32 	%r4493, %r4492, -2022574463;
	shf.l.wrap.b32 	%r4494, %r4493, %r4493, 11;
	add.s32 	%r4495, %r4494, %r4489;
	xor.b32  	%r4496, %r4495, %r4489;
	xor.b32  	%r4497, %r4496, %r4482;
	add.s32 	%r4498, %r7811, %r4474;
	add.s32 	%r4499, %r4498, %r4497;
	add.s32 	%r4500, %r4499, 1839030562;
	shf.l.wrap.b32 	%r4501, %r4500, %r4500, 16;
	add.s32 	%r4502, %r4501, %r4495;
	xor.b32  	%r4503, %r4502, %r4496;
	add.s32 	%r4504, %r624, %r4482;
	add.s32 	%r4505, %r4504, %r4503;
	add.s32 	%r4506, %r4505, -35309556;
	shf.l.wrap.b32 	%r4507, %r4506, %r4506, 23;
	add.s32 	%r4508, %r4507, %r4502;
	xor.b32  	%r4509, %r4508, %r4502;
	xor.b32  	%r4510, %r4509, %r4495;
	add.s32 	%r4511, %r7821, %r4489;
	add.s32 	%r4512, %r4511, %r4510;
	add.s32 	%r4513, %r4512, -1530992060;
	shf.l.wrap.b32 	%r4514, %r4513, %r4513, 4;
	add.s32 	%r4515, %r4514, %r4508;
	xor.b32  	%r4516, %r4515, %r4509;
	add.s32 	%r4517, %r7818, %r4495;
	add.s32 	%r4518, %r4517, %r4516;
	add.s32 	%r4519, %r4518, 1272893353;
	shf.l.wrap.b32 	%r4520, %r4519, %r4519, 11;
	add.s32 	%r4521, %r4520, %r4515;
	xor.b32  	%r4522, %r4521, %r4515;
	xor.b32  	%r4523, %r4522, %r4508;
	add.s32 	%r4524, %r7815, %r4502;
	add.s32 	%r4525, %r4524, %r4523;
	add.s32 	%r4526, %r4525, -155497632;
	shf.l.wrap.b32 	%r4527, %r4526, %r4526, 16;
	add.s32 	%r4528, %r4527, %r4521;
	xor.b32  	%r4529, %r4528, %r4522;
	add.s32 	%r4530, %r7812, %r4508;
	add.s32 	%r4531, %r4530, %r4529;
	add.s32 	%r4532, %r4531, -1094730640;
	shf.l.wrap.b32 	%r4533, %r4532, %r4532, 23;
	add.s32 	%r4534, %r4533, %r4528;
	xor.b32  	%r4535, %r4534, %r4528;
	xor.b32  	%r4536, %r4535, %r4521;
	add.s32 	%r4537, %r7809, %r4515;
	add.s32 	%r4538, %r4537, %r4536;
	add.s32 	%r4539, %r4538, 681279174;
	shf.l.wrap.b32 	%r4540, %r4539, %r4539, 4;
	add.s32 	%r4541, %r4540, %r4534;
	xor.b32  	%r4542, %r4541, %r4535;
	add.s32 	%r4543, %r7822, %r4521;
	add.s32 	%r4544, %r4543, %r4542;
	add.s32 	%r4545, %r4544, -358537222;
	shf.l.wrap.b32 	%r4546, %r4545, %r4545, 11;
	add.s32 	%r4547, %r4546, %r4541;
	xor.b32  	%r4548, %r4547, %r4541;
	xor.b32  	%r4549, %r4548, %r4534;
	add.s32 	%r4550, %r7819, %r4528;
	add.s32 	%r4551, %r4550, %r4549;
	add.s32 	%r4552, %r4551, -722521979;
	shf.l.wrap.b32 	%r4553, %r4552, %r4552, 16;
	add.s32 	%r4554, %r4553, %r4547;
	xor.b32  	%r4555, %r4554, %r4548;
	add.s32 	%r4556, %r7816, %r4534;
	add.s32 	%r4557, %r4556, %r4555;
	add.s32 	%r4558, %r4557, 76029189;
	shf.l.wrap.b32 	%r4559, %r4558, %r4558, 23;
	add.s32 	%r4560, %r4559, %r4554;
	xor.b32  	%r4561, %r4560, %r4554;
	xor.b32  	%r4562, %r4561, %r4547;
	add.s32 	%r4563, %r7813, %r4541;
	add.s32 	%r4564, %r4563, %r4562;
	add.s32 	%r4565, %r4564, -640364487;
	shf.l.wrap.b32 	%r4566, %r4565, %r4565, 4;
	add.s32 	%r4567, %r4566, %r4560;
	xor.b32  	%r4568, %r4567, %r4561;
	add.s32 	%r4569, %r7810, %r4547;
	add.s32 	%r4570, %r4569, %r4568;
	add.s32 	%r4571, %r4570, -421815835;
	shf.l.wrap.b32 	%r4572, %r4571, %r4571, 11;
	add.s32 	%r4573, %r4572, %r4567;
	xor.b32  	%r4574, %r4573, %r4567;
	xor.b32  	%r4575, %r4574, %r4560;
	add.s32 	%r4576, %r625, %r4554;
	add.s32 	%r4577, %r4576, %r4575;
	add.s32 	%r4578, %r4577, 530742520;
	shf.l.wrap.b32 	%r4579, %r4578, %r4578, 16;
	add.s32 	%r4580, %r4579, %r4573;
	xor.b32  	%r4581, %r4580, %r4574;
	add.s32 	%r4582, %r7820, %r4560;
	add.s32 	%r4583, %r4582, %r4581;
	add.s32 	%r4584, %r4583, -995338651;
	shf.l.wrap.b32 	%r4585, %r4584, %r4584, 23;
	add.s32 	%r4586, %r4585, %r4580;
	not.b32 	%r4587, %r4573;
	or.b32  	%r4588, %r4586, %r4587;
	xor.b32  	%r4589, %r4588, %r4580;
	add.s32 	%r4590, %r7822, %r4567;
	add.s32 	%r4591, %r4590, %r4589;
	add.s32 	%r4592, %r4591, -198630844;
	shf.l.wrap.b32 	%r4593, %r4592, %r4592, 6;
	add.s32 	%r4594, %r4593, %r4586;
	not.b32 	%r4595, %r4580;
	or.b32  	%r4596, %r4594, %r4595;
	xor.b32  	%r4597, %r4596, %r4586;
	add.s32 	%r4598, %r7815, %r4573;
	add.s32 	%r4599, %r4598, %r4597;
	add.s32 	%r4600, %r4599, 1126891415;
	shf.l.wrap.b32 	%r4601, %r4600, %r4600, 10;
	add.s32 	%r4602, %r4601, %r4594;
	not.b32 	%r4603, %r4586;
	or.b32  	%r4604, %r4602, %r4603;
	xor.b32  	%r4605, %r4604, %r4594;
	add.s32 	%r4606, %r624, %r4580;
	add.s32 	%r4607, %r4606, %r4605;
	add.s32 	%r4608, %r4607, -1416354905;
	shf.l.wrap.b32 	%r4609, %r4608, %r4608, 15;
	add.s32 	%r4610, %r4609, %r4602;
	not.b32 	%r4611, %r4594;
	or.b32  	%r4612, %r4610, %r4611;
	xor.b32  	%r4613, %r4612, %r4602;
	add.s32 	%r4614, %r7817, %r4586;
	add.s32 	%r4615, %r4614, %r4613;
	add.s32 	%r4616, %r4615, -57434055;
	shf.l.wrap.b32 	%r4617, %r4616, %r4616, 21;
	add.s32 	%r4618, %r4617, %r4610;
	not.b32 	%r4619, %r4602;
	or.b32  	%r4620, %r4618, %r4619;
	xor.b32  	%r4621, %r4620, %r4610;
	add.s32 	%r4622, %r7810, %r4594;
	add.s32 	%r4623, %r4622, %r4621;
	add.s32 	%r4624, %r4623, 1700485571;
	shf.l.wrap.b32 	%r4625, %r4624, %r4624, 6;
	add.s32 	%r4626, %r4625, %r4618;
	not.b32 	%r4627, %r4610;
	or.b32  	%r4628, %r4626, %r4627;
	xor.b32  	%r4629, %r4628, %r4618;
	add.s32 	%r4630, %r7819, %r4602;
	add.s32 	%r4631, %r4630, %r4629;
	add.s32 	%r4632, %r4631, -1894986606;
	shf.l.wrap.b32 	%r4633, %r4632, %r4632, 10;
	add.s32 	%r4634, %r4633, %r4626;
	not.b32 	%r4635, %r4618;
	or.b32  	%r4636, %r4634, %r4635;
	xor.b32  	%r4637, %r4636, %r4626;
	add.s32 	%r4638, %r7812, %r4610;
	add.s32 	%r4639, %r4638, %r4637;
	add.s32 	%r4640, %r4639, -1051523;
	shf.l.wrap.b32 	%r4641, %r4640, %r4640, 15;
	add.s32 	%r4642, %r4641, %r4634;
	not.b32 	%r4643, %r4626;
	or.b32  	%r4644, %r4642, %r4643;
	xor.b32  	%r4645, %r4644, %r4634;
	add.s32 	%r4646, %r7821, %r4618;
	add.s32 	%r4647, %r4646, %r4645;
	add.s32 	%r4648, %r4647, -2054922799;
	shf.l.wrap.b32 	%r4649, %r4648, %r4648, 21;
	add.s32 	%r4650, %r4649, %r4642;
	not.b32 	%r4651, %r4634;
	or.b32  	%r4652, %r4650, %r4651;
	xor.b32  	%r4653, %r4652, %r4642;
	add.s32 	%r4654, %r7814, %r4626;
	add.s32 	%r4655, %r4654, %r4653;
	add.s32 	%r4656, %r4655, 1873313359;
	shf.l.wrap.b32 	%r4657, %r4656, %r4656, 6;
	add.s32 	%r4658, %r4657, %r4650;
	not.b32 	%r4659, %r4642;
	or.b32  	%r4660, %r4658, %r4659;
	xor.b32  	%r4661, %r4660, %r4650;
	add.s32 	%r4662, %r625, %r4634;
	add.s32 	%r4663, %r4662, %r4661;
	add.s32 	%r4664, %r4663, -30611744;
	shf.l.wrap.b32 	%r4665, %r4664, %r4664, 10;
	add.s32 	%r4666, %r4665, %r4658;
	not.b32 	%r4667, %r4650;
	or.b32  	%r4668, %r4666, %r4667;
	xor.b32  	%r4669, %r4668, %r4658;
	add.s32 	%r4670, %r7816, %r4642;
	add.s32 	%r4671, %r4670, %r4669;
	add.s32 	%r4672, %r4671, -1560198380;
	shf.l.wrap.b32 	%r4673, %r4672, %r4672, 15;
	add.s32 	%r4674, %r4673, %r4666;
	not.b32 	%r4675, %r4658;
	or.b32  	%r4676, %r4674, %r4675;
	xor.b32  	%r4677, %r4676, %r4666;
	add.s32 	%r4678, %r7809, %r4650;
	add.s32 	%r4679, %r4678, %r4677;
	add.s32 	%r4680, %r4679, 1309151649;
	shf.l.wrap.b32 	%r4681, %r4680, %r4680, 21;
	add.s32 	%r4682, %r4681, %r4674;
	not.b32 	%r4683, %r4666;
	or.b32  	%r4684, %r4682, %r4683;
	xor.b32  	%r4685, %r4684, %r4674;
	add.s32 	%r4686, %r7818, %r4658;
	add.s32 	%r4687, %r4686, %r4685;
	add.s32 	%r4688, %r4687, -145523070;
	shf.l.wrap.b32 	%r4689, %r4688, %r4688, 6;
	add.s32 	%r4690, %r4689, %r4682;
	not.b32 	%r4691, %r4674;
	or.b32  	%r4692, %r4690, %r4691;
	xor.b32  	%r4693, %r4692, %r4682;
	add.s32 	%r4694, %r7811, %r4666;
	add.s32 	%r4695, %r4694, %r4693;
	add.s32 	%r4696, %r4695, -1120210379;
	shf.l.wrap.b32 	%r4697, %r4696, %r4696, 10;
	add.s32 	%r4698, %r4697, %r4690;
	not.b32 	%r4699, %r4682;
	or.b32  	%r4700, %r4698, %r4699;
	xor.b32  	%r4701, %r4700, %r4690;
	add.s32 	%r4702, %r7820, %r4674;
	add.s32 	%r4703, %r4702, %r4701;
	add.s32 	%r4704, %r4703, 718787259;
	shf.l.wrap.b32 	%r4705, %r4704, %r4704, 15;
	add.s32 	%r4706, %r4705, %r4698;
	not.b32 	%r4707, %r4690;
	or.b32  	%r4708, %r4706, %r4707;
	xor.b32  	%r4709, %r4708, %r4698;
	add.s32 	%r4710, %r7813, %r4682;
	add.s32 	%r4711, %r4710, %r4709;
	add.s32 	%r4712, %r4711, -343485551;
	shf.l.wrap.b32 	%r4713, %r4712, %r4712, 21;
	add.s32 	%r90, %r4690, %r90;
	add.s32 	%r4714, %r4706, %r89;
	add.s32 	%r89, %r4714, %r4713;
	add.s32 	%r88, %r4706, %r88;
	add.s32 	%r87, %r4698, %r87;
	mov.u32 	%r7809, 0;
	mov.u32 	%r7810, %r7809;
	mov.u32 	%r7811, %r7809;
	mov.u32 	%r7812, %r7809;
	mov.u32 	%r7813, %r7809;
	mov.u32 	%r7814, %r7809;
	mov.u32 	%r7815, %r7809;
	mov.u32 	%r7816, %r7809;
	mov.u32 	%r7817, %r7809;
	mov.u32 	%r7818, %r7809;
	mov.u32 	%r7819, %r7809;
	mov.u32 	%r7820, %r7809;
	mov.u32 	%r7821, %r7809;
	mov.u32 	%r7822, %r7809;

BB3_113:
	ld.param.u64 	%rd62, [m00000_mxx_param_6];
	xor.b32  	%r4715, %r88, %r87;
	and.b32  	%r4716, %r89, %r4715;
	xor.b32  	%r4717, %r4716, %r87;
	add.s32 	%r4718, %r7822, %r90;
	add.s32 	%r4719, %r4718, %r4717;
	add.s32 	%r4720, %r4719, -680876936;
	shf.l.wrap.b32 	%r4721, %r4720, %r4720, 7;
	add.s32 	%r4722, %r4721, %r89;
	xor.b32  	%r4723, %r89, %r88;
	and.b32  	%r4724, %r4722, %r4723;
	xor.b32  	%r4725, %r4724, %r88;
	add.s32 	%r4726, %r7821, %r87;
	add.s32 	%r4727, %r4726, %r4725;
	add.s32 	%r4728, %r4727, -389564586;
	shf.l.wrap.b32 	%r4729, %r4728, %r4728, 12;
	add.s32 	%r4730, %r4729, %r4722;
	xor.b32  	%r4731, %r4722, %r89;
	and.b32  	%r4732, %r4730, %r4731;
	xor.b32  	%r4733, %r4732, %r89;
	add.s32 	%r4734, %r7820, %r88;
	add.s32 	%r4735, %r4734, %r4733;
	add.s32 	%r4736, %r4735, 606105819;
	shf.l.wrap.b32 	%r4737, %r4736, %r4736, 17;
	add.s32 	%r4738, %r4737, %r4730;
	xor.b32  	%r4739, %r4730, %r4722;
	and.b32  	%r4740, %r4738, %r4739;
	xor.b32  	%r4741, %r4740, %r4722;
	add.s32 	%r4742, %r7819, %r89;
	add.s32 	%r4743, %r4742, %r4741;
	add.s32 	%r4744, %r4743, -1044525330;
	shf.l.wrap.b32 	%r4745, %r4744, %r4744, 22;
	add.s32 	%r4746, %r4745, %r4738;
	xor.b32  	%r4747, %r4738, %r4730;
	and.b32  	%r4748, %r4746, %r4747;
	xor.b32  	%r4749, %r4748, %r4730;
	add.s32 	%r4750, %r7818, %r4722;
	add.s32 	%r4751, %r4750, %r4749;
	add.s32 	%r4752, %r4751, -176418897;
	shf.l.wrap.b32 	%r4753, %r4752, %r4752, 7;
	add.s32 	%r4754, %r4753, %r4746;
	xor.b32  	%r4755, %r4746, %r4738;
	and.b32  	%r4756, %r4754, %r4755;
	xor.b32  	%r4757, %r4756, %r4738;
	add.s32 	%r4758, %r7817, %r4730;
	add.s32 	%r4759, %r4758, %r4757;
	add.s32 	%r4760, %r4759, 1200080426;
	shf.l.wrap.b32 	%r4761, %r4760, %r4760, 12;
	add.s32 	%r4762, %r4761, %r4754;
	xor.b32  	%r4763, %r4754, %r4746;
	and.b32  	%r4764, %r4762, %r4763;
	xor.b32  	%r4765, %r4764, %r4746;
	add.s32 	%r4766, %r7816, %r4738;
	add.s32 	%r4767, %r4766, %r4765;
	add.s32 	%r4768, %r4767, -1473231341;
	shf.l.wrap.b32 	%r4769, %r4768, %r4768, 17;
	add.s32 	%r4770, %r4769, %r4762;
	xor.b32  	%r4771, %r4762, %r4754;
	and.b32  	%r4772, %r4770, %r4771;
	xor.b32  	%r4773, %r4772, %r4754;
	add.s32 	%r4774, %r7815, %r4746;
	add.s32 	%r4775, %r4774, %r4773;
	add.s32 	%r4776, %r4775, -45705983;
	shf.l.wrap.b32 	%r4777, %r4776, %r4776, 22;
	add.s32 	%r4778, %r4777, %r4770;
	xor.b32  	%r4779, %r4770, %r4762;
	and.b32  	%r4780, %r4778, %r4779;
	xor.b32  	%r4781, %r4780, %r4762;
	add.s32 	%r4782, %r7814, %r4754;
	add.s32 	%r4783, %r4782, %r4781;
	add.s32 	%r4784, %r4783, 1770035416;
	shf.l.wrap.b32 	%r4785, %r4784, %r4784, 7;
	add.s32 	%r4786, %r4785, %r4778;
	xor.b32  	%r4787, %r4778, %r4770;
	and.b32  	%r4788, %r4786, %r4787;
	xor.b32  	%r4789, %r4788, %r4770;
	add.s32 	%r4790, %r7813, %r4762;
	add.s32 	%r4791, %r4790, %r4789;
	add.s32 	%r4792, %r4791, -1958414417;
	shf.l.wrap.b32 	%r4793, %r4792, %r4792, 12;
	add.s32 	%r4794, %r4793, %r4786;
	xor.b32  	%r4795, %r4786, %r4778;
	and.b32  	%r4796, %r4794, %r4795;
	xor.b32  	%r4797, %r4796, %r4778;
	add.s32 	%r4798, %r7812, %r4770;
	add.s32 	%r4799, %r4798, %r4797;
	add.s32 	%r4800, %r4799, -42063;
	shf.l.wrap.b32 	%r4801, %r4800, %r4800, 17;
	add.s32 	%r4802, %r4801, %r4794;
	xor.b32  	%r4803, %r4794, %r4786;
	and.b32  	%r4804, %r4802, %r4803;
	xor.b32  	%r4805, %r4804, %r4786;
	add.s32 	%r4806, %r7811, %r4778;
	add.s32 	%r4807, %r4806, %r4805;
	add.s32 	%r4808, %r4807, -1990404162;
	shf.l.wrap.b32 	%r4809, %r4808, %r4808, 22;
	add.s32 	%r4810, %r4809, %r4802;
	xor.b32  	%r4811, %r4802, %r4794;
	and.b32  	%r4812, %r4810, %r4811;
	xor.b32  	%r4813, %r4812, %r4794;
	add.s32 	%r4814, %r7810, %r4786;
	add.s32 	%r4815, %r4814, %r4813;
	add.s32 	%r4816, %r4815, 1804603682;
	shf.l.wrap.b32 	%r4817, %r4816, %r4816, 7;
	add.s32 	%r4818, %r4817, %r4810;
	xor.b32  	%r4819, %r4810, %r4802;
	and.b32  	%r4820, %r4818, %r4819;
	xor.b32  	%r4821, %r4820, %r4802;
	add.s32 	%r4822, %r7809, %r4794;
	add.s32 	%r4823, %r4822, %r4821;
	add.s32 	%r4824, %r4823, -40341101;
	shf.l.wrap.b32 	%r4825, %r4824, %r4824, 12;
	add.s32 	%r4826, %r4825, %r4818;
	xor.b32  	%r4827, %r4818, %r4810;
	and.b32  	%r4828, %r4826, %r4827;
	xor.b32  	%r4829, %r4828, %r4810;
	shl.b32 	%r4830, %r111, 3;
	add.s32 	%r4831, %r4830, %r4802;
	add.s32 	%r4832, %r4831, %r4829;
	add.s32 	%r4833, %r4832, -1502002290;
	shf.l.wrap.b32 	%r4834, %r4833, %r4833, 17;
	add.s32 	%r4835, %r4834, %r4826;
	xor.b32  	%r4836, %r4826, %r4818;
	and.b32  	%r4837, %r4835, %r4836;
	xor.b32  	%r4838, %r4837, %r4818;
	add.s32 	%r4839, %r4810, %r4838;
	add.s32 	%r4840, %r4839, 1236535329;
	shf.l.wrap.b32 	%r4841, %r4840, %r4840, 22;
	add.s32 	%r4842, %r4841, %r4835;
	xor.b32  	%r4843, %r4842, %r4835;
	and.b32  	%r4844, %r4843, %r4826;
	xor.b32  	%r4845, %r4844, %r4835;
	add.s32 	%r4846, %r7821, %r4818;
	add.s32 	%r4847, %r4846, %r4845;
	add.s32 	%r4848, %r4847, -165796510;
	shf.l.wrap.b32 	%r4849, %r4848, %r4848, 5;
	add.s32 	%r4850, %r4849, %r4842;
	xor.b32  	%r4851, %r4850, %r4842;
	and.b32  	%r4852, %r4851, %r4835;
	xor.b32  	%r4853, %r4852, %r4842;
	add.s32 	%r4854, %r7816, %r4826;
	add.s32 	%r4855, %r4854, %r4853;
	add.s32 	%r4856, %r4855, -1069501632;
	shf.l.wrap.b32 	%r4857, %r4856, %r4856, 9;
	add.s32 	%r4858, %r4857, %r4850;
	xor.b32  	%r4859, %r4858, %r4850;
	and.b32  	%r4860, %r4859, %r4842;
	xor.b32  	%r4861, %r4860, %r4850;
	add.s32 	%r4862, %r7811, %r4835;
	add.s32 	%r4863, %r4862, %r4861;
	add.s32 	%r4864, %r4863, 643717713;
	shf.l.wrap.b32 	%r4865, %r4864, %r4864, 14;
	add.s32 	%r4866, %r4865, %r4858;
	xor.b32  	%r4867, %r4866, %r4858;
	and.b32  	%r4868, %r4867, %r4850;
	xor.b32  	%r4869, %r4868, %r4858;
	add.s32 	%r4870, %r7822, %r4842;
	add.s32 	%r4871, %r4870, %r4869;
	add.s32 	%r4872, %r4871, -373897302;
	shf.l.wrap.b32 	%r4873, %r4872, %r4872, 20;
	add.s32 	%r4874, %r4873, %r4866;
	xor.b32  	%r4875, %r4874, %r4866;
	and.b32  	%r4876, %r4875, %r4858;
	xor.b32  	%r4877, %r4876, %r4866;
	add.s32 	%r4878, %r7817, %r4850;
	add.s32 	%r4879, %r4878, %r4877;
	add.s32 	%r4880, %r4879, -701558691;
	shf.l.wrap.b32 	%r4881, %r4880, %r4880, 5;
	add.s32 	%r4882, %r4881, %r4874;
	xor.b32  	%r4883, %r4882, %r4874;
	and.b32  	%r4884, %r4883, %r4866;
	xor.b32  	%r4885, %r4884, %r4874;
	add.s32 	%r4886, %r7812, %r4858;
	add.s32 	%r4887, %r4886, %r4885;
	add.s32 	%r4888, %r4887, 38016083;
	shf.l.wrap.b32 	%r4889, %r4888, %r4888, 9;
	add.s32 	%r4890, %r4889, %r4882;
	xor.b32  	%r4891, %r4890, %r4882;
	and.b32  	%r4892, %r4891, %r4874;
	xor.b32  	%r4893, %r4892, %r4882;
	add.s32 	%r4894, %r4866, %r4893;
	add.s32 	%r4895, %r4894, -660478335;
	shf.l.wrap.b32 	%r4896, %r4895, %r4895, 14;
	add.s32 	%r4897, %r4896, %r4890;
	xor.b32  	%r4898, %r4897, %r4890;
	and.b32  	%r4899, %r4898, %r4882;
	xor.b32  	%r4900, %r4899, %r4890;
	add.s32 	%r4901, %r7818, %r4874;
	add.s32 	%r4902, %r4901, %r4900;
	add.s32 	%r4903, %r4902, -405537848;
	shf.l.wrap.b32 	%r4904, %r4903, %r4903, 20;
	add.s32 	%r4905, %r4904, %r4897;
	xor.b32  	%r4906, %r4905, %r4897;
	and.b32  	%r4907, %r4906, %r4890;
	xor.b32  	%r4908, %r4907, %r4897;
	add.s32 	%r4909, %r7813, %r4882;
	add.s32 	%r4910, %r4909, %r4908;
	add.s32 	%r4911, %r4910, 568446438;
	shf.l.wrap.b32 	%r4912, %r4911, %r4911, 5;
	add.s32 	%r4913, %r4912, %r4905;
	xor.b32  	%r4914, %r4913, %r4905;
	and.b32  	%r4915, %r4914, %r4897;
	xor.b32  	%r4916, %r4915, %r4905;
	add.s32 	%r4917, %r4830, %r4890;
	add.s32 	%r4918, %r4917, %r4916;
	add.s32 	%r4919, %r4918, -1019803690;
	shf.l.wrap.b32 	%r4920, %r4919, %r4919, 9;
	add.s32 	%r4921, %r4920, %r4913;
	xor.b32  	%r4922, %r4921, %r4913;
	and.b32  	%r4923, %r4922, %r4905;
	xor.b32  	%r4924, %r4923, %r4913;
	add.s32 	%r4925, %r7819, %r4897;
	add.s32 	%r4926, %r4925, %r4924;
	add.s32 	%r4927, %r4926, -187363961;
	shf.l.wrap.b32 	%r4928, %r4927, %r4927, 14;
	add.s32 	%r4929, %r4928, %r4921;
	xor.b32  	%r4930, %r4929, %r4921;
	and.b32  	%r4931, %r4930, %r4913;
	xor.b32  	%r4932, %r4931, %r4921;
	add.s32 	%r4933, %r7814, %r4905;
	add.s32 	%r4934, %r4933, %r4932;
	add.s32 	%r4935, %r4934, 1163531501;
	shf.l.wrap.b32 	%r4936, %r4935, %r4935, 20;
	add.s32 	%r4937, %r4936, %r4929;
	xor.b32  	%r4938, %r4937, %r4929;
	and.b32  	%r4939, %r4938, %r4921;
	xor.b32  	%r4940, %r4939, %r4929;
	add.s32 	%r4941, %r7809, %r4913;
	add.s32 	%r4942, %r4941, %r4940;
	add.s32 	%r4943, %r4942, -1444681467;
	shf.l.wrap.b32 	%r4944, %r4943, %r4943, 5;
	add.s32 	%r4945, %r4944, %r4937;
	xor.b32  	%r4946, %r4945, %r4937;
	and.b32  	%r4947, %r4946, %r4929;
	xor.b32  	%r4948, %r4947, %r4937;
	add.s32 	%r4949, %r7820, %r4921;
	add.s32 	%r4950, %r4949, %r4948;
	add.s32 	%r4951, %r4950, -51403784;
	shf.l.wrap.b32 	%r4952, %r4951, %r4951, 9;
	add.s32 	%r4953, %r4952, %r4945;
	xor.b32  	%r4954, %r4953, %r4945;
	and.b32  	%r4955, %r4954, %r4937;
	xor.b32  	%r4956, %r4955, %r4945;
	add.s32 	%r4957, %r7815, %r4929;
	add.s32 	%r4958, %r4957, %r4956;
	add.s32 	%r4959, %r4958, 1735328473;
	shf.l.wrap.b32 	%r4960, %r4959, %r4959, 14;
	add.s32 	%r4961, %r4960, %r4953;
	xor.b32  	%r4962, %r4961, %r4953;
	and.b32  	%r4963, %r4962, %r4945;
	xor.b32  	%r4964, %r4963, %r4953;
	add.s32 	%r4965, %r7810, %r4937;
	add.s32 	%r4966, %r4965, %r4964;
	add.s32 	%r4967, %r4966, -1926607734;
	shf.l.wrap.b32 	%r4968, %r4967, %r4967, 20;
	add.s32 	%r4969, %r4968, %r4961;
	xor.b32  	%r4970, %r4969, %r4961;
	xor.b32  	%r4971, %r4970, %r4953;
	add.s32 	%r4972, %r7817, %r4945;
	add.s32 	%r4973, %r4972, %r4971;
	add.s32 	%r4974, %r4973, -378558;
	shf.l.wrap.b32 	%r4975, %r4974, %r4974, 4;
	add.s32 	%r4976, %r4975, %r4969;
	xor.b32  	%r4977, %r4976, %r4970;
	add.s32 	%r4978, %r7814, %r4953;
	add.s32 	%r4979, %r4978, %r4977;
	add.s32 	%r4980, %r4979, -2022574463;
	shf.l.wrap.b32 	%r4981, %r4980, %r4980, 11;
	add.s32 	%r4982, %r4981, %r4976;
	xor.b32  	%r4983, %r4982, %r4976;
	xor.b32  	%r4984, %r4983, %r4969;
	add.s32 	%r4985, %r7811, %r4961;
	add.s32 	%r4986, %r4985, %r4984;
	add.s32 	%r4987, %r4986, 1839030562;
	shf.l.wrap.b32 	%r4988, %r4987, %r4987, 16;
	add.s32 	%r4989, %r4988, %r4982;
	xor.b32  	%r4990, %r4989, %r4983;
	add.s32 	%r4991, %r4830, %r4969;
	add.s32 	%r4992, %r4991, %r4990;
	add.s32 	%r4993, %r4992, -35309556;
	shf.l.wrap.b32 	%r4994, %r4993, %r4993, 23;
	add.s32 	%r4995, %r4994, %r4989;
	xor.b32  	%r4996, %r4995, %r4989;
	xor.b32  	%r4997, %r4996, %r4982;
	add.s32 	%r4998, %r7821, %r4976;
	add.s32 	%r4999, %r4998, %r4997;
	add.s32 	%r5000, %r4999, -1530992060;
	shf.l.wrap.b32 	%r5001, %r5000, %r5000, 4;
	add.s32 	%r5002, %r5001, %r4995;
	xor.b32  	%r5003, %r5002, %r4996;
	add.s32 	%r5004, %r7818, %r4982;
	add.s32 	%r5005, %r5004, %r5003;
	add.s32 	%r5006, %r5005, 1272893353;
	shf.l.wrap.b32 	%r5007, %r5006, %r5006, 11;
	add.s32 	%r5008, %r5007, %r5002;
	xor.b32  	%r5009, %r5008, %r5002;
	xor.b32  	%r5010, %r5009, %r4995;
	add.s32 	%r5011, %r7815, %r4989;
	add.s32 	%r5012, %r5011, %r5010;
	add.s32 	%r5013, %r5012, -155497632;
	shf.l.wrap.b32 	%r5014, %r5013, %r5013, 16;
	add.s32 	%r5015, %r5014, %r5008;
	xor.b32  	%r5016, %r5015, %r5009;
	add.s32 	%r5017, %r7812, %r4995;
	add.s32 	%r5018, %r5017, %r5016;
	add.s32 	%r5019, %r5018, -1094730640;
	shf.l.wrap.b32 	%r5020, %r5019, %r5019, 23;
	add.s32 	%r5021, %r5020, %r5015;
	xor.b32  	%r5022, %r5021, %r5015;
	xor.b32  	%r5023, %r5022, %r5008;
	add.s32 	%r5024, %r7809, %r5002;
	add.s32 	%r5025, %r5024, %r5023;
	add.s32 	%r5026, %r5025, 681279174;
	shf.l.wrap.b32 	%r5027, %r5026, %r5026, 4;
	add.s32 	%r5028, %r5027, %r5021;
	xor.b32  	%r5029, %r5028, %r5022;
	add.s32 	%r5030, %r7822, %r5008;
	add.s32 	%r5031, %r5030, %r5029;
	add.s32 	%r5032, %r5031, -358537222;
	shf.l.wrap.b32 	%r5033, %r5032, %r5032, 11;
	add.s32 	%r5034, %r5033, %r5028;
	xor.b32  	%r5035, %r5034, %r5028;
	xor.b32  	%r5036, %r5035, %r5021;
	add.s32 	%r5037, %r7819, %r5015;
	add.s32 	%r5038, %r5037, %r5036;
	add.s32 	%r5039, %r5038, -722521979;
	shf.l.wrap.b32 	%r5040, %r5039, %r5039, 16;
	add.s32 	%r5041, %r5040, %r5034;
	xor.b32  	%r5042, %r5041, %r5035;
	add.s32 	%r5043, %r7816, %r5021;
	add.s32 	%r5044, %r5043, %r5042;
	add.s32 	%r5045, %r5044, 76029189;
	shf.l.wrap.b32 	%r5046, %r5045, %r5045, 23;
	add.s32 	%r5047, %r5046, %r5041;
	xor.b32  	%r5048, %r5047, %r5041;
	xor.b32  	%r5049, %r5048, %r5034;
	add.s32 	%r5050, %r7813, %r5028;
	add.s32 	%r5051, %r5050, %r5049;
	add.s32 	%r5052, %r5051, -640364487;
	shf.l.wrap.b32 	%r5053, %r5052, %r5052, 4;
	add.s32 	%r5054, %r5053, %r5047;
	xor.b32  	%r5055, %r5054, %r5048;
	add.s32 	%r5056, %r7810, %r5034;
	add.s32 	%r5057, %r5056, %r5055;
	add.s32 	%r5058, %r5057, -421815835;
	shf.l.wrap.b32 	%r5059, %r5058, %r5058, 11;
	add.s32 	%r5060, %r5059, %r5054;
	xor.b32  	%r5061, %r5060, %r5054;
	xor.b32  	%r5062, %r5061, %r5047;
	add.s32 	%r5063, %r5041, %r5062;
	add.s32 	%r5064, %r5063, 530742520;
	shf.l.wrap.b32 	%r5065, %r5064, %r5064, 16;
	add.s32 	%r5066, %r5065, %r5060;
	xor.b32  	%r5067, %r5066, %r5061;
	add.s32 	%r5068, %r7820, %r5047;
	add.s32 	%r5069, %r5068, %r5067;
	add.s32 	%r5070, %r5069, -995338651;
	shf.l.wrap.b32 	%r5071, %r5070, %r5070, 23;
	add.s32 	%r5072, %r5071, %r5066;
	not.b32 	%r5073, %r5060;
	or.b32  	%r5074, %r5072, %r5073;
	xor.b32  	%r5075, %r5074, %r5066;
	add.s32 	%r5076, %r7822, %r5054;
	add.s32 	%r5077, %r5076, %r5075;
	add.s32 	%r5078, %r5077, -198630844;
	shf.l.wrap.b32 	%r5079, %r5078, %r5078, 6;
	add.s32 	%r5080, %r5079, %r5072;
	not.b32 	%r5081, %r5066;
	or.b32  	%r5082, %r5080, %r5081;
	xor.b32  	%r5083, %r5082, %r5072;
	add.s32 	%r5084, %r7815, %r5060;
	add.s32 	%r5085, %r5084, %r5083;
	add.s32 	%r5086, %r5085, 1126891415;
	shf.l.wrap.b32 	%r5087, %r5086, %r5086, 10;
	add.s32 	%r5088, %r5087, %r5080;
	not.b32 	%r5089, %r5072;
	or.b32  	%r5090, %r5088, %r5089;
	xor.b32  	%r5091, %r5090, %r5080;
	add.s32 	%r5092, %r4830, %r5066;
	add.s32 	%r5093, %r5092, %r5091;
	add.s32 	%r5094, %r5093, -1416354905;
	shf.l.wrap.b32 	%r5095, %r5094, %r5094, 15;
	add.s32 	%r5096, %r5095, %r5088;
	not.b32 	%r5097, %r5080;
	or.b32  	%r5098, %r5096, %r5097;
	xor.b32  	%r5099, %r5098, %r5088;
	add.s32 	%r5100, %r7817, %r5072;
	add.s32 	%r5101, %r5100, %r5099;
	add.s32 	%r5102, %r5101, -57434055;
	shf.l.wrap.b32 	%r5103, %r5102, %r5102, 21;
	add.s32 	%r5104, %r5103, %r5096;
	not.b32 	%r5105, %r5088;
	or.b32  	%r5106, %r5104, %r5105;
	xor.b32  	%r5107, %r5106, %r5096;
	add.s32 	%r5108, %r7810, %r5080;
	add.s32 	%r5109, %r5108, %r5107;
	add.s32 	%r5110, %r5109, 1700485571;
	shf.l.wrap.b32 	%r5111, %r5110, %r5110, 6;
	add.s32 	%r5112, %r5111, %r5104;
	not.b32 	%r5113, %r5096;
	or.b32  	%r5114, %r5112, %r5113;
	xor.b32  	%r5115, %r5114, %r5104;
	add.s32 	%r5116, %r7819, %r5088;
	add.s32 	%r5117, %r5116, %r5115;
	add.s32 	%r5118, %r5117, -1894986606;
	shf.l.wrap.b32 	%r5119, %r5118, %r5118, 10;
	add.s32 	%r5120, %r5119, %r5112;
	not.b32 	%r5121, %r5104;
	or.b32  	%r5122, %r5120, %r5121;
	xor.b32  	%r5123, %r5122, %r5112;
	add.s32 	%r5124, %r7812, %r5096;
	add.s32 	%r5125, %r5124, %r5123;
	add.s32 	%r5126, %r5125, -1051523;
	shf.l.wrap.b32 	%r5127, %r5126, %r5126, 15;
	add.s32 	%r5128, %r5127, %r5120;
	not.b32 	%r5129, %r5112;
	or.b32  	%r5130, %r5128, %r5129;
	xor.b32  	%r5131, %r5130, %r5120;
	add.s32 	%r5132, %r7821, %r5104;
	add.s32 	%r5133, %r5132, %r5131;
	add.s32 	%r5134, %r5133, -2054922799;
	shf.l.wrap.b32 	%r5135, %r5134, %r5134, 21;
	add.s32 	%r5136, %r5135, %r5128;
	not.b32 	%r5137, %r5120;
	or.b32  	%r5138, %r5136, %r5137;
	xor.b32  	%r5139, %r5138, %r5128;
	add.s32 	%r5140, %r7814, %r5112;
	add.s32 	%r5141, %r5140, %r5139;
	add.s32 	%r5142, %r5141, 1873313359;
	shf.l.wrap.b32 	%r5143, %r5142, %r5142, 6;
	add.s32 	%r5144, %r5143, %r5136;
	not.b32 	%r5145, %r5128;
	or.b32  	%r5146, %r5144, %r5145;
	xor.b32  	%r5147, %r5146, %r5136;
	add.s32 	%r5148, %r5120, %r5147;
	add.s32 	%r5149, %r5148, -30611744;
	shf.l.wrap.b32 	%r5150, %r5149, %r5149, 10;
	add.s32 	%r5151, %r5150, %r5144;
	not.b32 	%r5152, %r5136;
	or.b32  	%r5153, %r5151, %r5152;
	xor.b32  	%r5154, %r5153, %r5144;
	add.s32 	%r5155, %r7816, %r5128;
	add.s32 	%r5156, %r5155, %r5154;
	add.s32 	%r5157, %r5156, -1560198380;
	shf.l.wrap.b32 	%r5158, %r5157, %r5157, 15;
	add.s32 	%r5159, %r5158, %r5151;
	not.b32 	%r5160, %r5144;
	or.b32  	%r5161, %r5159, %r5160;
	xor.b32  	%r5162, %r5161, %r5151;
	add.s32 	%r5163, %r7809, %r5136;
	add.s32 	%r5164, %r5163, %r5162;
	add.s32 	%r5165, %r5164, 1309151649;
	shf.l.wrap.b32 	%r5166, %r5165, %r5165, 21;
	add.s32 	%r5167, %r5166, %r5159;
	not.b32 	%r5168, %r5151;
	or.b32  	%r5169, %r5167, %r5168;
	xor.b32  	%r5170, %r5169, %r5159;
	add.s32 	%r5171, %r7818, %r5144;
	add.s32 	%r5172, %r5171, %r5170;
	add.s32 	%r5173, %r5172, -145523070;
	shf.l.wrap.b32 	%r5174, %r5173, %r5173, 6;
	add.s32 	%r5175, %r5174, %r5167;
	not.b32 	%r5176, %r5159;
	or.b32  	%r5177, %r5175, %r5176;
	xor.b32  	%r5178, %r5177, %r5167;
	add.s32 	%r5179, %r7811, %r5151;
	add.s32 	%r5180, %r5179, %r5178;
	add.s32 	%r5181, %r5180, -1120210379;
	shf.l.wrap.b32 	%r5182, %r5181, %r5181, 10;
	add.s32 	%r5183, %r5182, %r5175;
	not.b32 	%r5184, %r5167;
	or.b32  	%r5185, %r5183, %r5184;
	xor.b32  	%r5186, %r5185, %r5175;
	add.s32 	%r5187, %r7820, %r5159;
	add.s32 	%r5188, %r5187, %r5186;
	add.s32 	%r5189, %r5188, 718787259;
	shf.l.wrap.b32 	%r5190, %r5189, %r5189, 15;
	add.s32 	%r5191, %r5190, %r5183;
	not.b32 	%r5192, %r5175;
	or.b32  	%r5193, %r5191, %r5192;
	xor.b32  	%r5194, %r5193, %r5183;
	add.s32 	%r5195, %r7813, %r5167;
	add.s32 	%r5196, %r5195, %r5194;
	add.s32 	%r5197, %r5196, -343485551;
	shf.l.wrap.b32 	%r5198, %r5197, %r5197, 21;
	add.s32 	%r648, %r5175, %r90;
	add.s32 	%r5199, %r5191, %r89;
	add.s32 	%r649, %r5199, %r5198;
	add.s32 	%r650, %r5191, %r88;
	add.s32 	%r651, %r5183, %r87;
	shr.u32 	%r5200, %r648, %r66;
	and.b32  	%r5201, %r5200, %r989;
	mul.wide.u32 	%rd32, %r5201, 4;
	add.s64 	%rd33, %rd62, %rd32;
	and.b32  	%r5202, %r648, 31;
	mov.u32 	%r5203, 1;
	shl.b32 	%r652, %r5203, %r5202;
	ld.global.nc.u32 	%r5204, [%rd33];
	and.b32  	%r5205, %r5204, %r652;
	setp.eq.s32	%p78, %r5205, 0;
	@%p78 bra 	BB3_140;

	mov.u32 	%r7677, 1;
	ld.param.u64 	%rd55, [m00000_mxx_param_7];
	shr.u32 	%r5206, %r651, %r66;
	and.b32  	%r5207, %r5206, %r989;
	mul.wide.u32 	%rd34, %r5207, 4;
	add.s64 	%rd35, %rd55, %rd34;
	and.b32  	%r5208, %r651, 31;
	shl.b32 	%r653, %r7677, %r5208;
	ld.global.nc.u32 	%r5210, [%rd35];
	and.b32  	%r5211, %r5210, %r653;
	setp.eq.s32	%p79, %r5211, 0;
	@%p79 bra 	BB3_140;

	mov.u32 	%r7678, 1;
	ld.param.u64 	%rd56, [m00000_mxx_param_8];
	shr.u32 	%r5212, %r650, %r66;
	and.b32  	%r5213, %r5212, %r989;
	mul.wide.u32 	%rd36, %r5213, 4;
	add.s64 	%rd37, %rd56, %rd36;
	and.b32  	%r5214, %r650, 31;
	shl.b32 	%r654, %r7678, %r5214;
	ld.global.nc.u32 	%r5216, [%rd37];
	and.b32  	%r5217, %r5216, %r654;
	setp.eq.s32	%p80, %r5217, 0;
	@%p80 bra 	BB3_140;

	mov.u32 	%r7679, 1;
	ld.param.u64 	%rd57, [m00000_mxx_param_9];
	shr.u32 	%r5218, %r649, %r66;
	and.b32  	%r5219, %r5218, %r989;
	mul.wide.u32 	%rd38, %r5219, 4;
	add.s64 	%rd39, %rd57, %rd38;
	and.b32  	%r5220, %r649, 31;
	shl.b32 	%r655, %r7679, %r5220;
	ld.global.nc.u32 	%r5222, [%rd39];
	and.b32  	%r5223, %r5222, %r655;
	setp.eq.s32	%p81, %r5223, 0;
	@%p81 bra 	BB3_140;

	and.b32  	%r7682, %r648, 31;
	mov.u32 	%r7681, 1;
	shl.b32 	%r7680, %r7681, %r7682;
	ld.param.u64 	%rd58, [m00000_mxx_param_10];
	shr.u32 	%r5224, %r648, %r67;
	and.b32  	%r5225, %r5224, %r989;
	mul.wide.u32 	%rd40, %r5225, 4;
	add.s64 	%rd41, %rd58, %rd40;
	ld.global.nc.u32 	%r5226, [%rd41];
	and.b32  	%r5227, %r5226, %r7680;
	setp.eq.s32	%p82, %r5227, 0;
	@%p82 bra 	BB3_140;

	ld.param.u64 	%rd59, [m00000_mxx_param_11];
	shr.u32 	%r5228, %r651, %r67;
	and.b32  	%r5229, %r5228, %r989;
	mul.wide.u32 	%rd42, %r5229, 4;
	add.s64 	%rd43, %rd59, %rd42;
	ld.global.nc.u32 	%r5230, [%rd43];
	and.b32  	%r5231, %r5230, %r653;
	setp.eq.s32	%p83, %r5231, 0;
	@%p83 bra 	BB3_140;

	ld.param.u64 	%rd60, [m00000_mxx_param_12];
	shr.u32 	%r5232, %r650, %r67;
	and.b32  	%r5233, %r5232, %r989;
	mul.wide.u32 	%rd44, %r5233, 4;
	add.s64 	%rd45, %rd60, %rd44;
	ld.global.nc.u32 	%r5234, [%rd45];
	and.b32  	%r5235, %r5234, %r654;
	setp.eq.s32	%p84, %r5235, 0;
	@%p84 bra 	BB3_140;

	ld.param.u64 	%rd61, [m00000_mxx_param_13];
	shr.u32 	%r5236, %r649, %r67;
	and.b32  	%r5237, %r5236, %r989;
	mul.wide.u32 	%rd46, %r5237, 4;
	add.s64 	%rd47, %rd61, %rd46;
	ld.global.nc.u32 	%r5238, [%rd47];
	and.b32  	%r5239, %r5238, %r655;
	setp.eq.s32	%p85, %r5239, 0;
	@%p85 bra 	BB3_140;

	setp.eq.s32	%p86, %r994, 0;
	mov.u32 	%r7828, 0;
	mov.u32 	%r5240, -1;
	mov.u32 	%r7827, %r994;
	@%p86 bra 	BB3_134;

BB3_122:
	mov.u32 	%r7829, 1;
	ld.param.u64 	%rd63, [m00000_mxx_param_15];
	shr.u32 	%r658, %r7827, 1;
	add.s32 	%r7830, %r658, %r7828;
	cvt.u64.u32	%rd48, %r7830;
	add.s64 	%rd49, %rd48, %rd2;
	shl.b64 	%rd50, %rd49, 4;
	add.s64 	%rd4, %rd63, %rd50;
	ld.global.nc.u32 	%r660, [%rd4+4];
	setp.gt.u32	%p87, %r649, %r660;
	@%p87 bra 	BB3_132;

	setp.lt.u32	%p88, %r649, %r660;
	mov.u32 	%r5243, -1;
	@%p88 bra 	BB3_124;
	bra.uni 	BB3_125;

BB3_124:
	mov.u32 	%r7829, %r5243;
	bra.uni 	BB3_132;

BB3_125:
	mov.u32 	%r7829, 1;
	ld.global.nc.u32 	%r661, [%rd4+8];
	setp.gt.u32	%p89, %r650, %r661;
	@%p89 bra 	BB3_132;

	setp.lt.u32	%p90, %r650, %r661;
	@%p90 bra 	BB3_127;
	bra.uni 	BB3_128;

BB3_127:
	mov.u32 	%r7829, %r5243;
	bra.uni 	BB3_132;

BB3_128:
	mov.u32 	%r7829, 1;
	ld.global.nc.u32 	%r662, [%rd4+12];
	setp.gt.u32	%p91, %r651, %r662;
	@%p91 bra 	BB3_132;

	setp.lt.u32	%p92, %r651, %r662;
	mov.u32 	%r7829, %r5243;
	@%p92 bra 	BB3_132;

	mov.u32 	%r7829, 1;
	ld.global.nc.u32 	%r663, [%rd4];
	setp.gt.u32	%p93, %r648, %r663;
	@%p93 bra 	BB3_132;

	setp.lt.u32	%p94, %r648, %r663;
	selp.b32	%r7829, -1, 0, %p94;

BB3_132:
	add.s32 	%r5249, %r658, 1;
	setp.gt.s32	%p95, %r7829, 0;
	selp.b32	%r5250, %r5249, 0, %p95;
	add.s32 	%r7828, %r5250, %r7828;
	selp.b32	%r5251, -1, 0, %p95;
	add.s32 	%r5252, %r5251, %r7827;
	shr.u32 	%r7827, %r5252, 1;
	setp.eq.s32	%p96, %r7829, 0;
	@%p96 bra 	BB3_135;

	setp.ne.s32	%p97, %r7827, 0;
	@%p97 bra 	BB3_122;

BB3_134:
	mov.u32 	%r7830, %r5240;

BB3_135:
	setp.eq.s32	%p98, %r7830, -1;
	@%p98 bra 	BB3_140;

	ld.param.u64 	%rd64, [m00000_mxx_param_16];
	ld.param.u32 	%r7673, [m00000_mxx_param_32];
	add.s32 	%r669, %r7830, %r7673;
	mul.wide.u32 	%rd51, %r669, 4;
	add.s64 	%rd52, %rd64, %rd51;
	atom.global.add.u32 	%r5254, [%rd52], 1;
	setp.ne.s32	%p99, %r5254, 0;
	@%p99 bra 	BB3_140;

	atom.global.add.u32 	%r670, [%rd18], 1;
	setp.lt.u32	%p100, %r670, %r994;
	@%p100 bra 	BB3_139;
	bra.uni 	BB3_138;

BB3_139:
	ld.param.u32 	%r7676, [m00000_mxx_param_27];
	ld.param.u64 	%rd65, [m00000_mxx_param_14];
	mul.wide.u32 	%rd53, %r670, 24;
	add.s64 	%rd54, %rd65, %rd53;
	st.global.v2.u32 	[%rd54+16], {%r7830, %r669};
	st.global.v2.u32 	[%rd54+8], {%r7717, %r7676};
	st.global.u64 	[%rd54], %rd1;
	bra.uni 	BB3_140;

BB3_138:
	atom.global.add.u32 	%r5255, [%rd18], -1;

BB3_140:
	ld.param.u32 	%r7674, [m00000_mxx_param_30];
	add.s32 	%r7717, %r7717, 1;
	setp.lt.u32	%p101, %r7717, %r7674;
	@%p101 bra 	BB3_8;

BB3_141:
	ret;
}

	// .globl	m00000_sxx
.entry m00000_sxx(
	.param .u64 .ptr .global .align 4 m00000_sxx_param_0,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_1,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_2,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_3,
	.param .u64 .ptr .global .align 1 m00000_sxx_param_4,
	.param .u64 .ptr .global .align 1 m00000_sxx_param_5,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_6,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_7,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_8,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_9,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_10,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_11,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_12,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_13,
	.param .u64 .ptr .global .align 8 m00000_sxx_param_14,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_15,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_16,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_17,
	.param .u64 .ptr .global .align 1 m00000_sxx_param_18,
	.param .u64 .ptr .global .align 4 m00000_sxx_param_19,
	.param .u64 .ptr .global .align 16 m00000_sxx_param_20,
	.param .u64 .ptr .global .align 16 m00000_sxx_param_21,
	.param .u64 .ptr .global .align 16 m00000_sxx_param_22,
	.param .u64 .ptr .global .align 16 m00000_sxx_param_23,
	.param .u32 m00000_sxx_param_24,
	.param .u32 m00000_sxx_param_25,
	.param .u32 m00000_sxx_param_26,
	.param .u32 m00000_sxx_param_27,
	.param .u32 m00000_sxx_param_28,
	.param .u32 m00000_sxx_param_29,
	.param .u32 m00000_sxx_param_30,
	.param .u32 m00000_sxx_param_31,
	.param .u32 m00000_sxx_param_32,
	.param .u32 m00000_sxx_param_33,
	.param .u64 m00000_sxx_param_34
)
{
	.reg .pred 	%p<127>;
	.reg .b32 	%r<7775>;
	.reg .b64 	%rd<32>;


	ld.param.u64 	%rd5, [m00000_sxx_param_0];
	ld.param.u64 	%rd6, [m00000_sxx_param_2];
	ld.param.u64 	%rd8, [m00000_sxx_param_15];
	ld.param.u64 	%rd10, [m00000_sxx_param_19];
	ld.param.u32 	%r972, [m00000_sxx_param_32];
	ld.param.u64 	%rd11, [m00000_sxx_param_34];
	mov.b32	%r973, %envreg3;
	mov.u32 	%r974, %ctaid.x;
	mov.u32 	%r975, %ntid.x;
	mad.lo.s32 	%r976, %r974, %r975, %r973;
	mov.u32 	%r977, %tid.x;
	add.s32 	%r1, %r976, %r977;
	cvt.s64.s32	%rd1, %r1;
	setp.ge.u64	%p1, %rd1, %rd11;
	@%p1 bra 	BB4_119;

	cvt.u64.u32	%rd2, %r972;
	mul.wide.u32 	%rd12, %r972, 16;
	add.s64 	%rd13, %rd8, %rd12;
	ld.global.nc.u32 	%r2, [%rd13];
	ld.global.nc.u32 	%r3, [%rd13+12];
	ld.global.nc.u32 	%r4, [%rd13+8];
	ld.global.nc.u32 	%r5, [%rd13+4];
	mul.wide.s32 	%rd14, %r1, 260;
	add.s64 	%rd15, %rd5, %rd14;
	ld.global.nc.u32 	%r984, [%rd15+256];
	and.b32  	%r6, %r984, 255;
	mov.u32 	%r7607, 0;
	mov.u32 	%r11, 1732584193;
	mov.u32 	%r10, -271733879;
	mov.u32 	%r9, -1732584194;
	mov.u32 	%r8, 271733878;
	mov.u32 	%r7612, %r7607;
	bra.uni 	BB4_2;

BB4_167:
	add.s32 	%r7607, %r7607, 64;
	mov.u32 	%r7112, 0;
	// inline asm
	shf.r.wrap.b32 %r7049, %r28, %r7112, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7053, %r27, %r28, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7057, %r26, %r27, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7061, %r25, %r26, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7065, %r24, %r25, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7069, %r23, %r24, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7073, %r22, %r23, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7077, %r21, %r22, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7081, %r20, %r21, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7085, %r19, %r20, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7089, %r18, %r19, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7093, %r17, %r18, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7097, %r16, %r17, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7101, %r15, %r16, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7105, %r14, %r15, %r7112;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r7109, %r13, %r14, %r7112;
	// inline asm
	xor.b32  	%r7113, %r9, %r8;
	and.b32  	%r7114, %r10, %r7113;
	xor.b32  	%r7115, %r7114, %r8;
	add.s32 	%r7116, %r11, %r7115;
	add.s32 	%r7117, %r7116, %r7109;
	add.s32 	%r7118, %r7117, -680876936;
	shf.l.wrap.b32 	%r7119, %r7118, %r7118, 7;
	add.s32 	%r7120, %r7119, %r10;
	xor.b32  	%r7121, %r10, %r9;
	and.b32  	%r7122, %r7120, %r7121;
	xor.b32  	%r7123, %r7122, %r9;
	add.s32 	%r7124, %r8, %r7105;
	add.s32 	%r7125, %r7124, %r7123;
	add.s32 	%r7126, %r7125, -389564586;
	shf.l.wrap.b32 	%r7127, %r7126, %r7126, 12;
	add.s32 	%r7128, %r7127, %r7120;
	xor.b32  	%r7129, %r7120, %r10;
	and.b32  	%r7130, %r7128, %r7129;
	xor.b32  	%r7131, %r7130, %r10;
	add.s32 	%r7132, %r9, %r7101;
	add.s32 	%r7133, %r7132, %r7131;
	add.s32 	%r7134, %r7133, 606105819;
	shf.l.wrap.b32 	%r7135, %r7134, %r7134, 17;
	add.s32 	%r7136, %r7135, %r7128;
	xor.b32  	%r7137, %r7128, %r7120;
	and.b32  	%r7138, %r7136, %r7137;
	xor.b32  	%r7139, %r7138, %r7120;
	add.s32 	%r7140, %r10, %r7097;
	add.s32 	%r7141, %r7140, %r7139;
	add.s32 	%r7142, %r7141, -1044525330;
	shf.l.wrap.b32 	%r7143, %r7142, %r7142, 22;
	add.s32 	%r7144, %r7143, %r7136;
	xor.b32  	%r7145, %r7136, %r7128;
	and.b32  	%r7146, %r7144, %r7145;
	xor.b32  	%r7147, %r7146, %r7128;
	add.s32 	%r7148, %r7093, %r7120;
	add.s32 	%r7149, %r7148, %r7147;
	add.s32 	%r7150, %r7149, -176418897;
	shf.l.wrap.b32 	%r7151, %r7150, %r7150, 7;
	add.s32 	%r7152, %r7151, %r7144;
	xor.b32  	%r7153, %r7144, %r7136;
	and.b32  	%r7154, %r7152, %r7153;
	xor.b32  	%r7155, %r7154, %r7136;
	add.s32 	%r7156, %r7089, %r7128;
	add.s32 	%r7157, %r7156, %r7155;
	add.s32 	%r7158, %r7157, 1200080426;
	shf.l.wrap.b32 	%r7159, %r7158, %r7158, 12;
	add.s32 	%r7160, %r7159, %r7152;
	xor.b32  	%r7161, %r7152, %r7144;
	and.b32  	%r7162, %r7160, %r7161;
	xor.b32  	%r7163, %r7162, %r7144;
	add.s32 	%r7164, %r7085, %r7136;
	add.s32 	%r7165, %r7164, %r7163;
	add.s32 	%r7166, %r7165, -1473231341;
	shf.l.wrap.b32 	%r7167, %r7166, %r7166, 17;
	add.s32 	%r7168, %r7167, %r7160;
	xor.b32  	%r7169, %r7160, %r7152;
	and.b32  	%r7170, %r7168, %r7169;
	xor.b32  	%r7171, %r7170, %r7152;
	add.s32 	%r7172, %r7081, %r7144;
	add.s32 	%r7173, %r7172, %r7171;
	add.s32 	%r7174, %r7173, -45705983;
	shf.l.wrap.b32 	%r7175, %r7174, %r7174, 22;
	add.s32 	%r7176, %r7175, %r7168;
	xor.b32  	%r7177, %r7168, %r7160;
	and.b32  	%r7178, %r7176, %r7177;
	xor.b32  	%r7179, %r7178, %r7160;
	add.s32 	%r7180, %r7077, %r7152;
	add.s32 	%r7181, %r7180, %r7179;
	add.s32 	%r7182, %r7181, 1770035416;
	shf.l.wrap.b32 	%r7183, %r7182, %r7182, 7;
	add.s32 	%r7184, %r7183, %r7176;
	xor.b32  	%r7185, %r7176, %r7168;
	and.b32  	%r7186, %r7184, %r7185;
	xor.b32  	%r7187, %r7186, %r7168;
	add.s32 	%r7188, %r7073, %r7160;
	add.s32 	%r7189, %r7188, %r7187;
	add.s32 	%r7190, %r7189, -1958414417;
	shf.l.wrap.b32 	%r7191, %r7190, %r7190, 12;
	add.s32 	%r7192, %r7191, %r7184;
	xor.b32  	%r7193, %r7184, %r7176;
	and.b32  	%r7194, %r7192, %r7193;
	xor.b32  	%r7195, %r7194, %r7176;
	add.s32 	%r7196, %r7069, %r7168;
	add.s32 	%r7197, %r7196, %r7195;
	add.s32 	%r7198, %r7197, -42063;
	shf.l.wrap.b32 	%r7199, %r7198, %r7198, 17;
	add.s32 	%r7200, %r7199, %r7192;
	xor.b32  	%r7201, %r7192, %r7184;
	and.b32  	%r7202, %r7200, %r7201;
	xor.b32  	%r7203, %r7202, %r7184;
	add.s32 	%r7204, %r7065, %r7176;
	add.s32 	%r7205, %r7204, %r7203;
	add.s32 	%r7206, %r7205, -1990404162;
	shf.l.wrap.b32 	%r7207, %r7206, %r7206, 22;
	add.s32 	%r7208, %r7207, %r7200;
	xor.b32  	%r7209, %r7200, %r7192;
	and.b32  	%r7210, %r7208, %r7209;
	xor.b32  	%r7211, %r7210, %r7192;
	add.s32 	%r7212, %r7061, %r7184;
	add.s32 	%r7213, %r7212, %r7211;
	add.s32 	%r7214, %r7213, 1804603682;
	shf.l.wrap.b32 	%r7215, %r7214, %r7214, 7;
	add.s32 	%r7216, %r7215, %r7208;
	xor.b32  	%r7217, %r7208, %r7200;
	and.b32  	%r7218, %r7216, %r7217;
	xor.b32  	%r7219, %r7218, %r7200;
	add.s32 	%r7220, %r7057, %r7192;
	add.s32 	%r7221, %r7220, %r7219;
	add.s32 	%r7222, %r7221, -40341101;
	shf.l.wrap.b32 	%r7223, %r7222, %r7222, 12;
	add.s32 	%r7224, %r7223, %r7216;
	xor.b32  	%r7225, %r7216, %r7208;
	and.b32  	%r7226, %r7224, %r7225;
	xor.b32  	%r7227, %r7226, %r7208;
	add.s32 	%r7228, %r7053, %r7200;
	add.s32 	%r7229, %r7228, %r7227;
	add.s32 	%r7230, %r7229, -1502002290;
	shf.l.wrap.b32 	%r7231, %r7230, %r7230, 17;
	add.s32 	%r7232, %r7231, %r7224;
	xor.b32  	%r7233, %r7224, %r7216;
	and.b32  	%r7234, %r7232, %r7233;
	xor.b32  	%r7235, %r7234, %r7216;
	add.s32 	%r7236, %r7049, %r7208;
	add.s32 	%r7237, %r7236, %r7235;
	add.s32 	%r7238, %r7237, 1236535329;
	shf.l.wrap.b32 	%r7239, %r7238, %r7238, 22;
	add.s32 	%r7240, %r7239, %r7232;
	xor.b32  	%r7241, %r7240, %r7232;
	and.b32  	%r7242, %r7241, %r7224;
	xor.b32  	%r7243, %r7242, %r7232;
	add.s32 	%r7244, %r7105, %r7216;
	add.s32 	%r7245, %r7244, %r7243;
	add.s32 	%r7246, %r7245, -165796510;
	shf.l.wrap.b32 	%r7247, %r7246, %r7246, 5;
	add.s32 	%r7248, %r7247, %r7240;
	xor.b32  	%r7249, %r7248, %r7240;
	and.b32  	%r7250, %r7249, %r7232;
	xor.b32  	%r7251, %r7250, %r7240;
	add.s32 	%r7252, %r7085, %r7224;
	add.s32 	%r7253, %r7252, %r7251;
	add.s32 	%r7254, %r7253, -1069501632;
	shf.l.wrap.b32 	%r7255, %r7254, %r7254, 9;
	add.s32 	%r7256, %r7255, %r7248;
	xor.b32  	%r7257, %r7256, %r7248;
	and.b32  	%r7258, %r7257, %r7240;
	xor.b32  	%r7259, %r7258, %r7248;
	add.s32 	%r7260, %r7065, %r7232;
	add.s32 	%r7261, %r7260, %r7259;
	add.s32 	%r7262, %r7261, 643717713;
	shf.l.wrap.b32 	%r7263, %r7262, %r7262, 14;
	add.s32 	%r7264, %r7263, %r7256;
	xor.b32  	%r7265, %r7264, %r7256;
	and.b32  	%r7266, %r7265, %r7248;
	xor.b32  	%r7267, %r7266, %r7256;
	add.s32 	%r7268, %r7109, %r7240;
	add.s32 	%r7269, %r7268, %r7267;
	add.s32 	%r7270, %r7269, -373897302;
	shf.l.wrap.b32 	%r7271, %r7270, %r7270, 20;
	add.s32 	%r7272, %r7271, %r7264;
	xor.b32  	%r7273, %r7272, %r7264;
	and.b32  	%r7274, %r7273, %r7256;
	xor.b32  	%r7275, %r7274, %r7264;
	add.s32 	%r7276, %r7089, %r7248;
	add.s32 	%r7277, %r7276, %r7275;
	add.s32 	%r7278, %r7277, -701558691;
	shf.l.wrap.b32 	%r7279, %r7278, %r7278, 5;
	add.s32 	%r7280, %r7279, %r7272;
	xor.b32  	%r7281, %r7280, %r7272;
	and.b32  	%r7282, %r7281, %r7264;
	xor.b32  	%r7283, %r7282, %r7272;
	add.s32 	%r7284, %r7069, %r7256;
	add.s32 	%r7285, %r7284, %r7283;
	add.s32 	%r7286, %r7285, 38016083;
	shf.l.wrap.b32 	%r7287, %r7286, %r7286, 9;
	add.s32 	%r7288, %r7287, %r7280;
	xor.b32  	%r7289, %r7288, %r7280;
	and.b32  	%r7290, %r7289, %r7272;
	xor.b32  	%r7291, %r7290, %r7280;
	add.s32 	%r7292, %r7049, %r7264;
	add.s32 	%r7293, %r7292, %r7291;
	add.s32 	%r7294, %r7293, -660478335;
	shf.l.wrap.b32 	%r7295, %r7294, %r7294, 14;
	add.s32 	%r7296, %r7295, %r7288;
	xor.b32  	%r7297, %r7296, %r7288;
	and.b32  	%r7298, %r7297, %r7280;
	xor.b32  	%r7299, %r7298, %r7288;
	add.s32 	%r7300, %r7093, %r7272;
	add.s32 	%r7301, %r7300, %r7299;
	add.s32 	%r7302, %r7301, -405537848;
	shf.l.wrap.b32 	%r7303, %r7302, %r7302, 20;
	add.s32 	%r7304, %r7303, %r7296;
	xor.b32  	%r7305, %r7304, %r7296;
	and.b32  	%r7306, %r7305, %r7288;
	xor.b32  	%r7307, %r7306, %r7296;
	add.s32 	%r7308, %r7073, %r7280;
	add.s32 	%r7309, %r7308, %r7307;
	add.s32 	%r7310, %r7309, 568446438;
	shf.l.wrap.b32 	%r7311, %r7310, %r7310, 5;
	add.s32 	%r7312, %r7311, %r7304;
	xor.b32  	%r7313, %r7312, %r7304;
	and.b32  	%r7314, %r7313, %r7296;
	xor.b32  	%r7315, %r7314, %r7304;
	add.s32 	%r7316, %r7053, %r7288;
	add.s32 	%r7317, %r7316, %r7315;
	add.s32 	%r7318, %r7317, -1019803690;
	shf.l.wrap.b32 	%r7319, %r7318, %r7318, 9;
	add.s32 	%r7320, %r7319, %r7312;
	xor.b32  	%r7321, %r7320, %r7312;
	and.b32  	%r7322, %r7321, %r7304;
	xor.b32  	%r7323, %r7322, %r7312;
	add.s32 	%r7324, %r7097, %r7296;
	add.s32 	%r7325, %r7324, %r7323;
	add.s32 	%r7326, %r7325, -187363961;
	shf.l.wrap.b32 	%r7327, %r7326, %r7326, 14;
	add.s32 	%r7328, %r7327, %r7320;
	xor.b32  	%r7329, %r7328, %r7320;
	and.b32  	%r7330, %r7329, %r7312;
	xor.b32  	%r7331, %r7330, %r7320;
	add.s32 	%r7332, %r7077, %r7304;
	add.s32 	%r7333, %r7332, %r7331;
	add.s32 	%r7334, %r7333, 1163531501;
	shf.l.wrap.b32 	%r7335, %r7334, %r7334, 20;
	add.s32 	%r7336, %r7335, %r7328;
	xor.b32  	%r7337, %r7336, %r7328;
	and.b32  	%r7338, %r7337, %r7320;
	xor.b32  	%r7339, %r7338, %r7328;
	add.s32 	%r7340, %r7057, %r7312;
	add.s32 	%r7341, %r7340, %r7339;
	add.s32 	%r7342, %r7341, -1444681467;
	shf.l.wrap.b32 	%r7343, %r7342, %r7342, 5;
	add.s32 	%r7344, %r7343, %r7336;
	xor.b32  	%r7345, %r7344, %r7336;
	and.b32  	%r7346, %r7345, %r7328;
	xor.b32  	%r7347, %r7346, %r7336;
	add.s32 	%r7348, %r7101, %r7320;
	add.s32 	%r7349, %r7348, %r7347;
	add.s32 	%r7350, %r7349, -51403784;
	shf.l.wrap.b32 	%r7351, %r7350, %r7350, 9;
	add.s32 	%r7352, %r7351, %r7344;
	xor.b32  	%r7353, %r7352, %r7344;
	and.b32  	%r7354, %r7353, %r7336;
	xor.b32  	%r7355, %r7354, %r7344;
	add.s32 	%r7356, %r7081, %r7328;
	add.s32 	%r7357, %r7356, %r7355;
	add.s32 	%r7358, %r7357, 1735328473;
	shf.l.wrap.b32 	%r7359, %r7358, %r7358, 14;
	add.s32 	%r7360, %r7359, %r7352;
	xor.b32  	%r7361, %r7360, %r7352;
	and.b32  	%r7362, %r7361, %r7344;
	xor.b32  	%r7363, %r7362, %r7352;
	add.s32 	%r7364, %r7061, %r7336;
	add.s32 	%r7365, %r7364, %r7363;
	add.s32 	%r7366, %r7365, -1926607734;
	shf.l.wrap.b32 	%r7367, %r7366, %r7366, 20;
	add.s32 	%r7368, %r7367, %r7360;
	xor.b32  	%r7369, %r7368, %r7360;
	xor.b32  	%r7370, %r7369, %r7352;
	add.s32 	%r7371, %r7089, %r7344;
	add.s32 	%r7372, %r7371, %r7370;
	add.s32 	%r7373, %r7372, -378558;
	shf.l.wrap.b32 	%r7374, %r7373, %r7373, 4;
	add.s32 	%r7375, %r7374, %r7368;
	xor.b32  	%r7376, %r7375, %r7369;
	add.s32 	%r7377, %r7077, %r7352;
	add.s32 	%r7378, %r7377, %r7376;
	add.s32 	%r7379, %r7378, -2022574463;
	shf.l.wrap.b32 	%r7380, %r7379, %r7379, 11;
	add.s32 	%r7381, %r7380, %r7375;
	xor.b32  	%r7382, %r7381, %r7375;
	xor.b32  	%r7383, %r7382, %r7368;
	add.s32 	%r7384, %r7065, %r7360;
	add.s32 	%r7385, %r7384, %r7383;
	add.s32 	%r7386, %r7385, 1839030562;
	shf.l.wrap.b32 	%r7387, %r7386, %r7386, 16;
	add.s32 	%r7388, %r7387, %r7381;
	xor.b32  	%r7389, %r7388, %r7382;
	add.s32 	%r7390, %r7053, %r7368;
	add.s32 	%r7391, %r7390, %r7389;
	add.s32 	%r7392, %r7391, -35309556;
	shf.l.wrap.b32 	%r7393, %r7392, %r7392, 23;
	add.s32 	%r7394, %r7393, %r7388;
	xor.b32  	%r7395, %r7394, %r7388;
	xor.b32  	%r7396, %r7395, %r7381;
	add.s32 	%r7397, %r7105, %r7375;
	add.s32 	%r7398, %r7397, %r7396;
	add.s32 	%r7399, %r7398, -1530992060;
	shf.l.wrap.b32 	%r7400, %r7399, %r7399, 4;
	add.s32 	%r7401, %r7400, %r7394;
	xor.b32  	%r7402, %r7401, %r7395;
	add.s32 	%r7403, %r7093, %r7381;
	add.s32 	%r7404, %r7403, %r7402;
	add.s32 	%r7405, %r7404, 1272893353;
	shf.l.wrap.b32 	%r7406, %r7405, %r7405, 11;
	add.s32 	%r7407, %r7406, %r7401;
	xor.b32  	%r7408, %r7407, %r7401;
	xor.b32  	%r7409, %r7408, %r7394;
	add.s32 	%r7410, %r7081, %r7388;
	add.s32 	%r7411, %r7410, %r7409;
	add.s32 	%r7412, %r7411, -155497632;
	shf.l.wrap.b32 	%r7413, %r7412, %r7412, 16;
	add.s32 	%r7414, %r7413, %r7407;
	xor.b32  	%r7415, %r7414, %r7408;
	add.s32 	%r7416, %r7069, %r7394;
	add.s32 	%r7417, %r7416, %r7415;
	add.s32 	%r7418, %r7417, -1094730640;
	shf.l.wrap.b32 	%r7419, %r7418, %r7418, 23;
	add.s32 	%r7420, %r7419, %r7414;
	xor.b32  	%r7421, %r7420, %r7414;
	xor.b32  	%r7422, %r7421, %r7407;
	add.s32 	%r7423, %r7057, %r7401;
	add.s32 	%r7424, %r7423, %r7422;
	add.s32 	%r7425, %r7424, 681279174;
	shf.l.wrap.b32 	%r7426, %r7425, %r7425, 4;
	add.s32 	%r7427, %r7426, %r7420;
	xor.b32  	%r7428, %r7427, %r7421;
	add.s32 	%r7429, %r7109, %r7407;
	add.s32 	%r7430, %r7429, %r7428;
	add.s32 	%r7431, %r7430, -358537222;
	shf.l.wrap.b32 	%r7432, %r7431, %r7431, 11;
	add.s32 	%r7433, %r7432, %r7427;
	xor.b32  	%r7434, %r7433, %r7427;
	xor.b32  	%r7435, %r7434, %r7420;
	add.s32 	%r7436, %r7097, %r7414;
	add.s32 	%r7437, %r7436, %r7435;
	add.s32 	%r7438, %r7437, -722521979;
	shf.l.wrap.b32 	%r7439, %r7438, %r7438, 16;
	add.s32 	%r7440, %r7439, %r7433;
	xor.b32  	%r7441, %r7440, %r7434;
	add.s32 	%r7442, %r7085, %r7420;
	add.s32 	%r7443, %r7442, %r7441;
	add.s32 	%r7444, %r7443, 76029189;
	shf.l.wrap.b32 	%r7445, %r7444, %r7444, 23;
	add.s32 	%r7446, %r7445, %r7440;
	xor.b32  	%r7447, %r7446, %r7440;
	xor.b32  	%r7448, %r7447, %r7433;
	add.s32 	%r7449, %r7073, %r7427;
	add.s32 	%r7450, %r7449, %r7448;
	add.s32 	%r7451, %r7450, -640364487;
	shf.l.wrap.b32 	%r7452, %r7451, %r7451, 4;
	add.s32 	%r7453, %r7452, %r7446;
	xor.b32  	%r7454, %r7453, %r7447;
	add.s32 	%r7455, %r7061, %r7433;
	add.s32 	%r7456, %r7455, %r7454;
	add.s32 	%r7457, %r7456, -421815835;
	shf.l.wrap.b32 	%r7458, %r7457, %r7457, 11;
	add.s32 	%r7459, %r7458, %r7453;
	xor.b32  	%r7460, %r7459, %r7453;
	xor.b32  	%r7461, %r7460, %r7446;
	add.s32 	%r7462, %r7049, %r7440;
	add.s32 	%r7463, %r7462, %r7461;
	add.s32 	%r7464, %r7463, 530742520;
	shf.l.wrap.b32 	%r7465, %r7464, %r7464, 16;
	add.s32 	%r7466, %r7465, %r7459;
	xor.b32  	%r7467, %r7466, %r7460;
	add.s32 	%r7468, %r7101, %r7446;
	add.s32 	%r7469, %r7468, %r7467;
	add.s32 	%r7470, %r7469, -995338651;
	shf.l.wrap.b32 	%r7471, %r7470, %r7470, 23;
	add.s32 	%r7472, %r7471, %r7466;
	not.b32 	%r7473, %r7459;
	or.b32  	%r7474, %r7472, %r7473;
	xor.b32  	%r7475, %r7474, %r7466;
	add.s32 	%r7476, %r7109, %r7453;
	add.s32 	%r7477, %r7476, %r7475;
	add.s32 	%r7478, %r7477, -198630844;
	shf.l.wrap.b32 	%r7479, %r7478, %r7478, 6;
	add.s32 	%r7480, %r7479, %r7472;
	not.b32 	%r7481, %r7466;
	or.b32  	%r7482, %r7480, %r7481;
	xor.b32  	%r7483, %r7482, %r7472;
	add.s32 	%r7484, %r7081, %r7459;
	add.s32 	%r7485, %r7484, %r7483;
	add.s32 	%r7486, %r7485, 1126891415;
	shf.l.wrap.b32 	%r7487, %r7486, %r7486, 10;
	add.s32 	%r7488, %r7487, %r7480;
	not.b32 	%r7489, %r7472;
	or.b32  	%r7490, %r7488, %r7489;
	xor.b32  	%r7491, %r7490, %r7480;
	add.s32 	%r7492, %r7053, %r7466;
	add.s32 	%r7493, %r7492, %r7491;
	add.s32 	%r7494, %r7493, -1416354905;
	shf.l.wrap.b32 	%r7495, %r7494, %r7494, 15;
	add.s32 	%r7496, %r7495, %r7488;
	not.b32 	%r7497, %r7480;
	or.b32  	%r7498, %r7496, %r7497;
	xor.b32  	%r7499, %r7498, %r7488;
	add.s32 	%r7500, %r7089, %r7472;
	add.s32 	%r7501, %r7500, %r7499;
	add.s32 	%r7502, %r7501, -57434055;
	shf.l.wrap.b32 	%r7503, %r7502, %r7502, 21;
	add.s32 	%r7504, %r7503, %r7496;
	not.b32 	%r7505, %r7488;
	or.b32  	%r7506, %r7504, %r7505;
	xor.b32  	%r7507, %r7506, %r7496;
	add.s32 	%r7508, %r7061, %r7480;
	add.s32 	%r7509, %r7508, %r7507;
	add.s32 	%r7510, %r7509, 1700485571;
	shf.l.wrap.b32 	%r7511, %r7510, %r7510, 6;
	add.s32 	%r7512, %r7511, %r7504;
	not.b32 	%r7513, %r7496;
	or.b32  	%r7514, %r7512, %r7513;
	xor.b32  	%r7515, %r7514, %r7504;
	add.s32 	%r7516, %r7097, %r7488;
	add.s32 	%r7517, %r7516, %r7515;
	add.s32 	%r7518, %r7517, -1894986606;
	shf.l.wrap.b32 	%r7519, %r7518, %r7518, 10;
	add.s32 	%r7520, %r7519, %r7512;
	not.b32 	%r7521, %r7504;
	or.b32  	%r7522, %r7520, %r7521;
	xor.b32  	%r7523, %r7522, %r7512;
	add.s32 	%r7524, %r7069, %r7496;
	add.s32 	%r7525, %r7524, %r7523;
	add.s32 	%r7526, %r7525, -1051523;
	shf.l.wrap.b32 	%r7527, %r7526, %r7526, 15;
	add.s32 	%r7528, %r7527, %r7520;
	not.b32 	%r7529, %r7512;
	or.b32  	%r7530, %r7528, %r7529;
	xor.b32  	%r7531, %r7530, %r7520;
	add.s32 	%r7532, %r7105, %r7504;
	add.s32 	%r7533, %r7532, %r7531;
	add.s32 	%r7534, %r7533, -2054922799;
	shf.l.wrap.b32 	%r7535, %r7534, %r7534, 21;
	add.s32 	%r7536, %r7535, %r7528;
	not.b32 	%r7537, %r7520;
	or.b32  	%r7538, %r7536, %r7537;
	xor.b32  	%r7539, %r7538, %r7528;
	add.s32 	%r7540, %r7077, %r7512;
	add.s32 	%r7541, %r7540, %r7539;
	add.s32 	%r7542, %r7541, 1873313359;
	shf.l.wrap.b32 	%r7543, %r7542, %r7542, 6;
	add.s32 	%r7544, %r7543, %r7536;
	not.b32 	%r7545, %r7528;
	or.b32  	%r7546, %r7544, %r7545;
	xor.b32  	%r7547, %r7546, %r7536;
	add.s32 	%r7548, %r7049, %r7520;
	add.s32 	%r7549, %r7548, %r7547;
	add.s32 	%r7550, %r7549, -30611744;
	shf.l.wrap.b32 	%r7551, %r7550, %r7550, 10;
	add.s32 	%r7552, %r7551, %r7544;
	not.b32 	%r7553, %r7536;
	or.b32  	%r7554, %r7552, %r7553;
	xor.b32  	%r7555, %r7554, %r7544;
	add.s32 	%r7556, %r7085, %r7528;
	add.s32 	%r7557, %r7556, %r7555;
	add.s32 	%r7558, %r7557, -1560198380;
	shf.l.wrap.b32 	%r7559, %r7558, %r7558, 15;
	add.s32 	%r7560, %r7559, %r7552;
	not.b32 	%r7561, %r7544;
	or.b32  	%r7562, %r7560, %r7561;
	xor.b32  	%r7563, %r7562, %r7552;
	add.s32 	%r7564, %r7057, %r7536;
	add.s32 	%r7565, %r7564, %r7563;
	add.s32 	%r7566, %r7565, 1309151649;
	shf.l.wrap.b32 	%r7567, %r7566, %r7566, 21;
	add.s32 	%r7568, %r7567, %r7560;
	not.b32 	%r7569, %r7552;
	or.b32  	%r7570, %r7568, %r7569;
	xor.b32  	%r7571, %r7570, %r7560;
	add.s32 	%r7572, %r7093, %r7544;
	add.s32 	%r7573, %r7572, %r7571;
	add.s32 	%r7574, %r7573, -145523070;
	shf.l.wrap.b32 	%r7575, %r7574, %r7574, 6;
	add.s32 	%r7576, %r7575, %r7568;
	not.b32 	%r7577, %r7560;
	or.b32  	%r7578, %r7576, %r7577;
	xor.b32  	%r7579, %r7578, %r7568;
	add.s32 	%r7580, %r7065, %r7552;
	add.s32 	%r7581, %r7580, %r7579;
	add.s32 	%r7582, %r7581, -1120210379;
	shf.l.wrap.b32 	%r7583, %r7582, %r7582, 10;
	add.s32 	%r7584, %r7583, %r7576;
	not.b32 	%r7585, %r7568;
	or.b32  	%r7586, %r7584, %r7585;
	xor.b32  	%r7587, %r7586, %r7576;
	add.s32 	%r7588, %r7101, %r7560;
	add.s32 	%r7589, %r7588, %r7587;
	add.s32 	%r7590, %r7589, 718787259;
	shf.l.wrap.b32 	%r7591, %r7590, %r7590, 15;
	add.s32 	%r7592, %r7591, %r7584;
	not.b32 	%r7593, %r7576;
	or.b32  	%r7594, %r7592, %r7593;
	xor.b32  	%r7595, %r7594, %r7584;
	add.s32 	%r7596, %r7073, %r7568;
	add.s32 	%r7597, %r7596, %r7595;
	add.s32 	%r7598, %r7597, -343485551;
	shf.l.wrap.b32 	%r7599, %r7598, %r7598, 21;
	add.s32 	%r11, %r7576, %r11;
	add.s32 	%r7600, %r7592, %r10;
	add.s32 	%r10, %r7600, %r7599;
	add.s32 	%r9, %r7592, %r9;
	add.s32 	%r8, %r7584, %r8;
	add.s32 	%r7612, %r7612, 16;

BB4_2:
	add.s32 	%r985, %r6, -64;
	setp.lt.s32	%p2, %r7607, %r985;
	mul.wide.s32 	%rd18, %r7612, 4;
	add.s64 	%rd19, %rd15, %rd18;
	ld.global.nc.u32 	%r13, [%rd19];
	ld.global.nc.u32 	%r14, [%rd19+4];
	ld.global.nc.u32 	%r15, [%rd19+8];
	ld.global.nc.u32 	%r16, [%rd19+12];
	ld.global.nc.u32 	%r17, [%rd19+16];
	ld.global.nc.u32 	%r18, [%rd19+20];
	ld.global.nc.u32 	%r19, [%rd19+24];
	ld.global.nc.u32 	%r20, [%rd19+28];
	ld.global.nc.u32 	%r21, [%rd19+32];
	ld.global.nc.u32 	%r22, [%rd19+36];
	ld.global.nc.u32 	%r23, [%rd19+40];
	ld.global.nc.u32 	%r24, [%rd19+44];
	ld.global.nc.u32 	%r25, [%rd19+48];
	ld.global.nc.u32 	%r26, [%rd19+52];
	ld.global.nc.u32 	%r27, [%rd19+56];
	ld.global.nc.u32 	%r28, [%rd19+60];
	@%p2 bra 	BB4_167;

	sub.s32 	%r986, %r6, %r7607;
	setp.lt.s32	%p3, %r986, 64;
	@%p3 bra 	BB4_5;
	bra.uni 	BB4_4;

BB4_5:
	mov.u32 	%r1618, 30292;
	// inline asm
	prmt.b32 %r7613, %r27, %r28, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7614, %r26, %r27, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7615, %r25, %r26, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7616, %r24, %r25, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7617, %r23, %r24, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7618, %r22, %r23, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7619, %r21, %r22, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7620, %r20, %r21, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7621, %r19, %r20, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7622, %r18, %r19, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7623, %r17, %r18, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7624, %r16, %r17, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7625, %r15, %r16, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7626, %r14, %r15, %r1618;
	// inline asm
	// inline asm
	prmt.b32 %r7627, %r13, %r14, %r1618;
	// inline asm
	mov.u32 	%r1616, 0;
	// inline asm
	prmt.b32 %r7628, %r1616, %r13, %r1618;
	// inline asm
	bra.uni 	BB4_6;

BB4_4:
	mov.u32 	%r7613, 0;
	// inline asm
	shf.r.wrap.b32 %r987, %r28, %r7613, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r991, %r27, %r28, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r995, %r26, %r27, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r999, %r25, %r26, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1003, %r24, %r25, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1007, %r23, %r24, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1011, %r22, %r23, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1015, %r21, %r22, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1019, %r20, %r21, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1023, %r19, %r20, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1027, %r18, %r19, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1031, %r17, %r18, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1035, %r16, %r17, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1039, %r15, %r16, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1043, %r14, %r15, %r7613;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1047, %r13, %r14, %r7613;
	// inline asm
	xor.b32  	%r1067, %r9, %r8;
	and.b32  	%r1068, %r10, %r1067;
	xor.b32  	%r1069, %r1068, %r8;
	add.s32 	%r1070, %r11, %r1069;
	add.s32 	%r1071, %r1070, %r1047;
	add.s32 	%r1072, %r1071, -680876936;
	shf.l.wrap.b32 	%r1073, %r1072, %r1072, 7;
	add.s32 	%r1074, %r1073, %r10;
	xor.b32  	%r1075, %r10, %r9;
	and.b32  	%r1076, %r1074, %r1075;
	xor.b32  	%r1077, %r1076, %r9;
	add.s32 	%r1078, %r8, %r1043;
	add.s32 	%r1079, %r1078, %r1077;
	add.s32 	%r1080, %r1079, -389564586;
	shf.l.wrap.b32 	%r1081, %r1080, %r1080, 12;
	add.s32 	%r1082, %r1081, %r1074;
	xor.b32  	%r1083, %r1074, %r10;
	and.b32  	%r1084, %r1082, %r1083;
	xor.b32  	%r1085, %r1084, %r10;
	add.s32 	%r1086, %r9, %r1039;
	add.s32 	%r1087, %r1086, %r1085;
	add.s32 	%r1088, %r1087, 606105819;
	shf.l.wrap.b32 	%r1089, %r1088, %r1088, 17;
	add.s32 	%r1090, %r1089, %r1082;
	xor.b32  	%r1091, %r1082, %r1074;
	and.b32  	%r1092, %r1090, %r1091;
	xor.b32  	%r1093, %r1092, %r1074;
	add.s32 	%r1094, %r10, %r1035;
	add.s32 	%r1095, %r1094, %r1093;
	add.s32 	%r1096, %r1095, -1044525330;
	shf.l.wrap.b32 	%r1097, %r1096, %r1096, 22;
	add.s32 	%r1098, %r1097, %r1090;
	xor.b32  	%r1099, %r1090, %r1082;
	and.b32  	%r1100, %r1098, %r1099;
	xor.b32  	%r1101, %r1100, %r1082;
	add.s32 	%r1102, %r1031, %r1074;
	add.s32 	%r1103, %r1102, %r1101;
	add.s32 	%r1104, %r1103, -176418897;
	shf.l.wrap.b32 	%r1105, %r1104, %r1104, 7;
	add.s32 	%r1106, %r1105, %r1098;
	xor.b32  	%r1107, %r1098, %r1090;
	and.b32  	%r1108, %r1106, %r1107;
	xor.b32  	%r1109, %r1108, %r1090;
	add.s32 	%r1110, %r1027, %r1082;
	add.s32 	%r1111, %r1110, %r1109;
	add.s32 	%r1112, %r1111, 1200080426;
	shf.l.wrap.b32 	%r1113, %r1112, %r1112, 12;
	add.s32 	%r1114, %r1113, %r1106;
	xor.b32  	%r1115, %r1106, %r1098;
	and.b32  	%r1116, %r1114, %r1115;
	xor.b32  	%r1117, %r1116, %r1098;
	add.s32 	%r1118, %r1023, %r1090;
	add.s32 	%r1119, %r1118, %r1117;
	add.s32 	%r1120, %r1119, -1473231341;
	shf.l.wrap.b32 	%r1121, %r1120, %r1120, 17;
	add.s32 	%r1122, %r1121, %r1114;
	xor.b32  	%r1123, %r1114, %r1106;
	and.b32  	%r1124, %r1122, %r1123;
	xor.b32  	%r1125, %r1124, %r1106;
	add.s32 	%r1126, %r1019, %r1098;
	add.s32 	%r1127, %r1126, %r1125;
	add.s32 	%r1128, %r1127, -45705983;
	shf.l.wrap.b32 	%r1129, %r1128, %r1128, 22;
	add.s32 	%r1130, %r1129, %r1122;
	xor.b32  	%r1131, %r1122, %r1114;
	and.b32  	%r1132, %r1130, %r1131;
	xor.b32  	%r1133, %r1132, %r1114;
	add.s32 	%r1134, %r1015, %r1106;
	add.s32 	%r1135, %r1134, %r1133;
	add.s32 	%r1136, %r1135, 1770035416;
	shf.l.wrap.b32 	%r1137, %r1136, %r1136, 7;
	add.s32 	%r1138, %r1137, %r1130;
	xor.b32  	%r1139, %r1130, %r1122;
	and.b32  	%r1140, %r1138, %r1139;
	xor.b32  	%r1141, %r1140, %r1122;
	add.s32 	%r1142, %r1011, %r1114;
	add.s32 	%r1143, %r1142, %r1141;
	add.s32 	%r1144, %r1143, -1958414417;
	shf.l.wrap.b32 	%r1145, %r1144, %r1144, 12;
	add.s32 	%r1146, %r1145, %r1138;
	xor.b32  	%r1147, %r1138, %r1130;
	and.b32  	%r1148, %r1146, %r1147;
	xor.b32  	%r1149, %r1148, %r1130;
	add.s32 	%r1150, %r1007, %r1122;
	add.s32 	%r1151, %r1150, %r1149;
	add.s32 	%r1152, %r1151, -42063;
	shf.l.wrap.b32 	%r1153, %r1152, %r1152, 17;
	add.s32 	%r1154, %r1153, %r1146;
	xor.b32  	%r1155, %r1146, %r1138;
	and.b32  	%r1156, %r1154, %r1155;
	xor.b32  	%r1157, %r1156, %r1138;
	add.s32 	%r1158, %r1003, %r1130;
	add.s32 	%r1159, %r1158, %r1157;
	add.s32 	%r1160, %r1159, -1990404162;
	shf.l.wrap.b32 	%r1161, %r1160, %r1160, 22;
	add.s32 	%r1162, %r1161, %r1154;
	xor.b32  	%r1163, %r1154, %r1146;
	and.b32  	%r1164, %r1162, %r1163;
	xor.b32  	%r1165, %r1164, %r1146;
	add.s32 	%r1166, %r999, %r1138;
	add.s32 	%r1167, %r1166, %r1165;
	add.s32 	%r1168, %r1167, 1804603682;
	shf.l.wrap.b32 	%r1169, %r1168, %r1168, 7;
	add.s32 	%r1170, %r1169, %r1162;
	xor.b32  	%r1171, %r1162, %r1154;
	and.b32  	%r1172, %r1170, %r1171;
	xor.b32  	%r1173, %r1172, %r1154;
	add.s32 	%r1174, %r995, %r1146;
	add.s32 	%r1175, %r1174, %r1173;
	add.s32 	%r1176, %r1175, -40341101;
	shf.l.wrap.b32 	%r1177, %r1176, %r1176, 12;
	add.s32 	%r1178, %r1177, %r1170;
	xor.b32  	%r1179, %r1170, %r1162;
	and.b32  	%r1180, %r1178, %r1179;
	xor.b32  	%r1181, %r1180, %r1162;
	add.s32 	%r1182, %r991, %r1154;
	add.s32 	%r1183, %r1182, %r1181;
	add.s32 	%r1184, %r1183, -1502002290;
	shf.l.wrap.b32 	%r1185, %r1184, %r1184, 17;
	add.s32 	%r1186, %r1185, %r1178;
	xor.b32  	%r1187, %r1178, %r1170;
	and.b32  	%r1188, %r1186, %r1187;
	xor.b32  	%r1189, %r1188, %r1170;
	add.s32 	%r1190, %r987, %r1162;
	add.s32 	%r1191, %r1190, %r1189;
	add.s32 	%r1192, %r1191, 1236535329;
	shf.l.wrap.b32 	%r1193, %r1192, %r1192, 22;
	add.s32 	%r1194, %r1193, %r1186;
	xor.b32  	%r1195, %r1194, %r1186;
	and.b32  	%r1196, %r1195, %r1178;
	xor.b32  	%r1197, %r1196, %r1186;
	add.s32 	%r1198, %r1043, %r1170;
	add.s32 	%r1199, %r1198, %r1197;
	add.s32 	%r1200, %r1199, -165796510;
	shf.l.wrap.b32 	%r1201, %r1200, %r1200, 5;
	add.s32 	%r1202, %r1201, %r1194;
	xor.b32  	%r1203, %r1202, %r1194;
	and.b32  	%r1204, %r1203, %r1186;
	xor.b32  	%r1205, %r1204, %r1194;
	add.s32 	%r1206, %r1023, %r1178;
	add.s32 	%r1207, %r1206, %r1205;
	add.s32 	%r1208, %r1207, -1069501632;
	shf.l.wrap.b32 	%r1209, %r1208, %r1208, 9;
	add.s32 	%r1210, %r1209, %r1202;
	xor.b32  	%r1211, %r1210, %r1202;
	and.b32  	%r1212, %r1211, %r1194;
	xor.b32  	%r1213, %r1212, %r1202;
	add.s32 	%r1214, %r1003, %r1186;
	add.s32 	%r1215, %r1214, %r1213;
	add.s32 	%r1216, %r1215, 643717713;
	shf.l.wrap.b32 	%r1217, %r1216, %r1216, 14;
	add.s32 	%r1218, %r1217, %r1210;
	xor.b32  	%r1219, %r1218, %r1210;
	and.b32  	%r1220, %r1219, %r1202;
	xor.b32  	%r1221, %r1220, %r1210;
	add.s32 	%r1222, %r1047, %r1194;
	add.s32 	%r1223, %r1222, %r1221;
	add.s32 	%r1224, %r1223, -373897302;
	shf.l.wrap.b32 	%r1225, %r1224, %r1224, 20;
	add.s32 	%r1226, %r1225, %r1218;
	xor.b32  	%r1227, %r1226, %r1218;
	and.b32  	%r1228, %r1227, %r1210;
	xor.b32  	%r1229, %r1228, %r1218;
	add.s32 	%r1230, %r1027, %r1202;
	add.s32 	%r1231, %r1230, %r1229;
	add.s32 	%r1232, %r1231, -701558691;
	shf.l.wrap.b32 	%r1233, %r1232, %r1232, 5;
	add.s32 	%r1234, %r1233, %r1226;
	xor.b32  	%r1235, %r1234, %r1226;
	and.b32  	%r1236, %r1235, %r1218;
	xor.b32  	%r1237, %r1236, %r1226;
	add.s32 	%r1238, %r1007, %r1210;
	add.s32 	%r1239, %r1238, %r1237;
	add.s32 	%r1240, %r1239, 38016083;
	shf.l.wrap.b32 	%r1241, %r1240, %r1240, 9;
	add.s32 	%r1242, %r1241, %r1234;
	xor.b32  	%r1243, %r1242, %r1234;
	and.b32  	%r1244, %r1243, %r1226;
	xor.b32  	%r1245, %r1244, %r1234;
	add.s32 	%r1246, %r987, %r1218;
	add.s32 	%r1247, %r1246, %r1245;
	add.s32 	%r1248, %r1247, -660478335;
	shf.l.wrap.b32 	%r1249, %r1248, %r1248, 14;
	add.s32 	%r1250, %r1249, %r1242;
	xor.b32  	%r1251, %r1250, %r1242;
	and.b32  	%r1252, %r1251, %r1234;
	xor.b32  	%r1253, %r1252, %r1242;
	add.s32 	%r1254, %r1031, %r1226;
	add.s32 	%r1255, %r1254, %r1253;
	add.s32 	%r1256, %r1255, -405537848;
	shf.l.wrap.b32 	%r1257, %r1256, %r1256, 20;
	add.s32 	%r1258, %r1257, %r1250;
	xor.b32  	%r1259, %r1258, %r1250;
	and.b32  	%r1260, %r1259, %r1242;
	xor.b32  	%r1261, %r1260, %r1250;
	add.s32 	%r1262, %r1011, %r1234;
	add.s32 	%r1263, %r1262, %r1261;
	add.s32 	%r1264, %r1263, 568446438;
	shf.l.wrap.b32 	%r1265, %r1264, %r1264, 5;
	add.s32 	%r1266, %r1265, %r1258;
	xor.b32  	%r1267, %r1266, %r1258;
	and.b32  	%r1268, %r1267, %r1250;
	xor.b32  	%r1269, %r1268, %r1258;
	add.s32 	%r1270, %r991, %r1242;
	add.s32 	%r1271, %r1270, %r1269;
	add.s32 	%r1272, %r1271, -1019803690;
	shf.l.wrap.b32 	%r1273, %r1272, %r1272, 9;
	add.s32 	%r1274, %r1273, %r1266;
	xor.b32  	%r1275, %r1274, %r1266;
	and.b32  	%r1276, %r1275, %r1258;
	xor.b32  	%r1277, %r1276, %r1266;
	add.s32 	%r1278, %r1035, %r1250;
	add.s32 	%r1279, %r1278, %r1277;
	add.s32 	%r1280, %r1279, -187363961;
	shf.l.wrap.b32 	%r1281, %r1280, %r1280, 14;
	add.s32 	%r1282, %r1281, %r1274;
	xor.b32  	%r1283, %r1282, %r1274;
	and.b32  	%r1284, %r1283, %r1266;
	xor.b32  	%r1285, %r1284, %r1274;
	add.s32 	%r1286, %r1015, %r1258;
	add.s32 	%r1287, %r1286, %r1285;
	add.s32 	%r1288, %r1287, 1163531501;
	shf.l.wrap.b32 	%r1289, %r1288, %r1288, 20;
	add.s32 	%r1290, %r1289, %r1282;
	xor.b32  	%r1291, %r1290, %r1282;
	and.b32  	%r1292, %r1291, %r1274;
	xor.b32  	%r1293, %r1292, %r1282;
	add.s32 	%r1294, %r995, %r1266;
	add.s32 	%r1295, %r1294, %r1293;
	add.s32 	%r1296, %r1295, -1444681467;
	shf.l.wrap.b32 	%r1297, %r1296, %r1296, 5;
	add.s32 	%r1298, %r1297, %r1290;
	xor.b32  	%r1299, %r1298, %r1290;
	and.b32  	%r1300, %r1299, %r1282;
	xor.b32  	%r1301, %r1300, %r1290;
	add.s32 	%r1302, %r1039, %r1274;
	add.s32 	%r1303, %r1302, %r1301;
	add.s32 	%r1304, %r1303, -51403784;
	shf.l.wrap.b32 	%r1305, %r1304, %r1304, 9;
	add.s32 	%r1306, %r1305, %r1298;
	xor.b32  	%r1307, %r1306, %r1298;
	and.b32  	%r1308, %r1307, %r1290;
	xor.b32  	%r1309, %r1308, %r1298;
	add.s32 	%r1310, %r1019, %r1282;
	add.s32 	%r1311, %r1310, %r1309;
	add.s32 	%r1312, %r1311, 1735328473;
	shf.l.wrap.b32 	%r1313, %r1312, %r1312, 14;
	add.s32 	%r1314, %r1313, %r1306;
	xor.b32  	%r1315, %r1314, %r1306;
	and.b32  	%r1316, %r1315, %r1298;
	xor.b32  	%r1317, %r1316, %r1306;
	add.s32 	%r1318, %r999, %r1290;
	add.s32 	%r1319, %r1318, %r1317;
	add.s32 	%r1320, %r1319, -1926607734;
	shf.l.wrap.b32 	%r1321, %r1320, %r1320, 20;
	add.s32 	%r1322, %r1321, %r1314;
	xor.b32  	%r1323, %r1322, %r1314;
	xor.b32  	%r1324, %r1323, %r1306;
	add.s32 	%r1325, %r1027, %r1298;
	add.s32 	%r1326, %r1325, %r1324;
	add.s32 	%r1327, %r1326, -378558;
	shf.l.wrap.b32 	%r1328, %r1327, %r1327, 4;
	add.s32 	%r1329, %r1328, %r1322;
	xor.b32  	%r1330, %r1329, %r1323;
	add.s32 	%r1331, %r1015, %r1306;
	add.s32 	%r1332, %r1331, %r1330;
	add.s32 	%r1333, %r1332, -2022574463;
	shf.l.wrap.b32 	%r1334, %r1333, %r1333, 11;
	add.s32 	%r1335, %r1334, %r1329;
	xor.b32  	%r1336, %r1335, %r1329;
	xor.b32  	%r1337, %r1336, %r1322;
	add.s32 	%r1338, %r1003, %r1314;
	add.s32 	%r1339, %r1338, %r1337;
	add.s32 	%r1340, %r1339, 1839030562;
	shf.l.wrap.b32 	%r1341, %r1340, %r1340, 16;
	add.s32 	%r1342, %r1341, %r1335;
	xor.b32  	%r1343, %r1342, %r1336;
	add.s32 	%r1344, %r991, %r1322;
	add.s32 	%r1345, %r1344, %r1343;
	add.s32 	%r1346, %r1345, -35309556;
	shf.l.wrap.b32 	%r1347, %r1346, %r1346, 23;
	add.s32 	%r1348, %r1347, %r1342;
	xor.b32  	%r1349, %r1348, %r1342;
	xor.b32  	%r1350, %r1349, %r1335;
	add.s32 	%r1351, %r1043, %r1329;
	add.s32 	%r1352, %r1351, %r1350;
	add.s32 	%r1353, %r1352, -1530992060;
	shf.l.wrap.b32 	%r1354, %r1353, %r1353, 4;
	add.s32 	%r1355, %r1354, %r1348;
	xor.b32  	%r1356, %r1355, %r1349;
	add.s32 	%r1357, %r1031, %r1335;
	add.s32 	%r1358, %r1357, %r1356;
	add.s32 	%r1359, %r1358, 1272893353;
	shf.l.wrap.b32 	%r1360, %r1359, %r1359, 11;
	add.s32 	%r1361, %r1360, %r1355;
	xor.b32  	%r1362, %r1361, %r1355;
	xor.b32  	%r1363, %r1362, %r1348;
	add.s32 	%r1364, %r1019, %r1342;
	add.s32 	%r1365, %r1364, %r1363;
	add.s32 	%r1366, %r1365, -155497632;
	shf.l.wrap.b32 	%r1367, %r1366, %r1366, 16;
	add.s32 	%r1368, %r1367, %r1361;
	xor.b32  	%r1369, %r1368, %r1362;
	add.s32 	%r1370, %r1007, %r1348;
	add.s32 	%r1371, %r1370, %r1369;
	add.s32 	%r1372, %r1371, -1094730640;
	shf.l.wrap.b32 	%r1373, %r1372, %r1372, 23;
	add.s32 	%r1374, %r1373, %r1368;
	xor.b32  	%r1375, %r1374, %r1368;
	xor.b32  	%r1376, %r1375, %r1361;
	add.s32 	%r1377, %r995, %r1355;
	add.s32 	%r1378, %r1377, %r1376;
	add.s32 	%r1379, %r1378, 681279174;
	shf.l.wrap.b32 	%r1380, %r1379, %r1379, 4;
	add.s32 	%r1381, %r1380, %r1374;
	xor.b32  	%r1382, %r1381, %r1375;
	add.s32 	%r1383, %r1047, %r1361;
	add.s32 	%r1384, %r1383, %r1382;
	add.s32 	%r1385, %r1384, -358537222;
	shf.l.wrap.b32 	%r1386, %r1385, %r1385, 11;
	add.s32 	%r1387, %r1386, %r1381;
	xor.b32  	%r1388, %r1387, %r1381;
	xor.b32  	%r1389, %r1388, %r1374;
	add.s32 	%r1390, %r1035, %r1368;
	add.s32 	%r1391, %r1390, %r1389;
	add.s32 	%r1392, %r1391, -722521979;
	shf.l.wrap.b32 	%r1393, %r1392, %r1392, 16;
	add.s32 	%r1394, %r1393, %r1387;
	xor.b32  	%r1395, %r1394, %r1388;
	add.s32 	%r1396, %r1023, %r1374;
	add.s32 	%r1397, %r1396, %r1395;
	add.s32 	%r1398, %r1397, 76029189;
	shf.l.wrap.b32 	%r1399, %r1398, %r1398, 23;
	add.s32 	%r1400, %r1399, %r1394;
	xor.b32  	%r1401, %r1400, %r1394;
	xor.b32  	%r1402, %r1401, %r1387;
	add.s32 	%r1403, %r1011, %r1381;
	add.s32 	%r1404, %r1403, %r1402;
	add.s32 	%r1405, %r1404, -640364487;
	shf.l.wrap.b32 	%r1406, %r1405, %r1405, 4;
	add.s32 	%r1407, %r1406, %r1400;
	xor.b32  	%r1408, %r1407, %r1401;
	add.s32 	%r1409, %r999, %r1387;
	add.s32 	%r1410, %r1409, %r1408;
	add.s32 	%r1411, %r1410, -421815835;
	shf.l.wrap.b32 	%r1412, %r1411, %r1411, 11;
	add.s32 	%r1413, %r1412, %r1407;
	xor.b32  	%r1414, %r1413, %r1407;
	xor.b32  	%r1415, %r1414, %r1400;
	add.s32 	%r1416, %r987, %r1394;
	add.s32 	%r1417, %r1416, %r1415;
	add.s32 	%r1418, %r1417, 530742520;
	shf.l.wrap.b32 	%r1419, %r1418, %r1418, 16;
	add.s32 	%r1420, %r1419, %r1413;
	xor.b32  	%r1421, %r1420, %r1414;
	add.s32 	%r1422, %r1039, %r1400;
	add.s32 	%r1423, %r1422, %r1421;
	add.s32 	%r1424, %r1423, -995338651;
	shf.l.wrap.b32 	%r1425, %r1424, %r1424, 23;
	add.s32 	%r1426, %r1425, %r1420;
	not.b32 	%r1427, %r1413;
	or.b32  	%r1428, %r1426, %r1427;
	xor.b32  	%r1429, %r1428, %r1420;
	add.s32 	%r1430, %r1047, %r1407;
	add.s32 	%r1431, %r1430, %r1429;
	add.s32 	%r1432, %r1431, -198630844;
	shf.l.wrap.b32 	%r1433, %r1432, %r1432, 6;
	add.s32 	%r1434, %r1433, %r1426;
	not.b32 	%r1435, %r1420;
	or.b32  	%r1436, %r1434, %r1435;
	xor.b32  	%r1437, %r1436, %r1426;
	add.s32 	%r1438, %r1019, %r1413;
	add.s32 	%r1439, %r1438, %r1437;
	add.s32 	%r1440, %r1439, 1126891415;
	shf.l.wrap.b32 	%r1441, %r1440, %r1440, 10;
	add.s32 	%r1442, %r1441, %r1434;
	not.b32 	%r1443, %r1426;
	or.b32  	%r1444, %r1442, %r1443;
	xor.b32  	%r1445, %r1444, %r1434;
	add.s32 	%r1446, %r991, %r1420;
	add.s32 	%r1447, %r1446, %r1445;
	add.s32 	%r1448, %r1447, -1416354905;
	shf.l.wrap.b32 	%r1449, %r1448, %r1448, 15;
	add.s32 	%r1450, %r1449, %r1442;
	not.b32 	%r1451, %r1434;
	or.b32  	%r1452, %r1450, %r1451;
	xor.b32  	%r1453, %r1452, %r1442;
	add.s32 	%r1454, %r1027, %r1426;
	add.s32 	%r1455, %r1454, %r1453;
	add.s32 	%r1456, %r1455, -57434055;
	shf.l.wrap.b32 	%r1457, %r1456, %r1456, 21;
	add.s32 	%r1458, %r1457, %r1450;
	not.b32 	%r1459, %r1442;
	or.b32  	%r1460, %r1458, %r1459;
	xor.b32  	%r1461, %r1460, %r1450;
	add.s32 	%r1462, %r999, %r1434;
	add.s32 	%r1463, %r1462, %r1461;
	add.s32 	%r1464, %r1463, 1700485571;
	shf.l.wrap.b32 	%r1465, %r1464, %r1464, 6;
	add.s32 	%r1466, %r1465, %r1458;
	not.b32 	%r1467, %r1450;
	or.b32  	%r1468, %r1466, %r1467;
	xor.b32  	%r1469, %r1468, %r1458;
	add.s32 	%r1470, %r1035, %r1442;
	add.s32 	%r1471, %r1470, %r1469;
	add.s32 	%r1472, %r1471, -1894986606;
	shf.l.wrap.b32 	%r1473, %r1472, %r1472, 10;
	add.s32 	%r1474, %r1473, %r1466;
	not.b32 	%r1475, %r1458;
	or.b32  	%r1476, %r1474, %r1475;
	xor.b32  	%r1477, %r1476, %r1466;
	add.s32 	%r1478, %r1007, %r1450;
	add.s32 	%r1479, %r1478, %r1477;
	add.s32 	%r1480, %r1479, -1051523;
	shf.l.wrap.b32 	%r1481, %r1480, %r1480, 15;
	add.s32 	%r1482, %r1481, %r1474;
	not.b32 	%r1483, %r1466;
	or.b32  	%r1484, %r1482, %r1483;
	xor.b32  	%r1485, %r1484, %r1474;
	add.s32 	%r1486, %r1043, %r1458;
	add.s32 	%r1487, %r1486, %r1485;
	add.s32 	%r1488, %r1487, -2054922799;
	shf.l.wrap.b32 	%r1489, %r1488, %r1488, 21;
	add.s32 	%r1490, %r1489, %r1482;
	not.b32 	%r1491, %r1474;
	or.b32  	%r1492, %r1490, %r1491;
	xor.b32  	%r1493, %r1492, %r1482;
	add.s32 	%r1494, %r1015, %r1466;
	add.s32 	%r1495, %r1494, %r1493;
	add.s32 	%r1496, %r1495, 1873313359;
	shf.l.wrap.b32 	%r1497, %r1496, %r1496, 6;
	add.s32 	%r1498, %r1497, %r1490;
	not.b32 	%r1499, %r1482;
	or.b32  	%r1500, %r1498, %r1499;
	xor.b32  	%r1501, %r1500, %r1490;
	add.s32 	%r1502, %r987, %r1474;
	add.s32 	%r1503, %r1502, %r1501;
	add.s32 	%r1504, %r1503, -30611744;
	shf.l.wrap.b32 	%r1505, %r1504, %r1504, 10;
	add.s32 	%r1506, %r1505, %r1498;
	not.b32 	%r1507, %r1490;
	or.b32  	%r1508, %r1506, %r1507;
	xor.b32  	%r1509, %r1508, %r1498;
	add.s32 	%r1510, %r1023, %r1482;
	add.s32 	%r1511, %r1510, %r1509;
	add.s32 	%r1512, %r1511, -1560198380;
	shf.l.wrap.b32 	%r1513, %r1512, %r1512, 15;
	add.s32 	%r1514, %r1513, %r1506;
	not.b32 	%r1515, %r1498;
	or.b32  	%r1516, %r1514, %r1515;
	xor.b32  	%r1517, %r1516, %r1506;
	add.s32 	%r1518, %r995, %r1490;
	add.s32 	%r1519, %r1518, %r1517;
	add.s32 	%r1520, %r1519, 1309151649;
	shf.l.wrap.b32 	%r1521, %r1520, %r1520, 21;
	add.s32 	%r1522, %r1521, %r1514;
	not.b32 	%r1523, %r1506;
	or.b32  	%r1524, %r1522, %r1523;
	xor.b32  	%r1525, %r1524, %r1514;
	add.s32 	%r1526, %r1031, %r1498;
	add.s32 	%r1527, %r1526, %r1525;
	add.s32 	%r1528, %r1527, -145523070;
	shf.l.wrap.b32 	%r1529, %r1528, %r1528, 6;
	add.s32 	%r1530, %r1529, %r1522;
	not.b32 	%r1531, %r1514;
	or.b32  	%r1532, %r1530, %r1531;
	xor.b32  	%r1533, %r1532, %r1522;
	add.s32 	%r1534, %r1003, %r1506;
	add.s32 	%r1535, %r1534, %r1533;
	add.s32 	%r1536, %r1535, -1120210379;
	shf.l.wrap.b32 	%r1537, %r1536, %r1536, 10;
	add.s32 	%r1538, %r1537, %r1530;
	not.b32 	%r1539, %r1522;
	or.b32  	%r1540, %r1538, %r1539;
	xor.b32  	%r1541, %r1540, %r1530;
	add.s32 	%r1542, %r1039, %r1514;
	add.s32 	%r1543, %r1542, %r1541;
	add.s32 	%r1544, %r1543, 718787259;
	shf.l.wrap.b32 	%r1545, %r1544, %r1544, 15;
	add.s32 	%r1546, %r1545, %r1538;
	not.b32 	%r1547, %r1530;
	or.b32  	%r1548, %r1546, %r1547;
	xor.b32  	%r1549, %r1548, %r1538;
	add.s32 	%r1550, %r1011, %r1522;
	add.s32 	%r1551, %r1550, %r1549;
	add.s32 	%r1552, %r1551, -343485551;
	shf.l.wrap.b32 	%r1553, %r1552, %r1552, 21;
	add.s32 	%r11, %r1530, %r11;
	add.s32 	%r1554, %r1546, %r10;
	add.s32 	%r10, %r1554, %r1553;
	add.s32 	%r9, %r1546, %r9;
	add.s32 	%r8, %r1538, %r8;
	mov.u32 	%r7614, %r7613;
	mov.u32 	%r7615, %r7613;
	mov.u32 	%r7616, %r7613;
	mov.u32 	%r7617, %r7613;
	mov.u32 	%r7618, %r7613;
	mov.u32 	%r7619, %r7613;
	mov.u32 	%r7620, %r7613;
	mov.u32 	%r7621, %r7613;
	mov.u32 	%r7622, %r7613;
	mov.u32 	%r7623, %r7613;
	mov.u32 	%r7624, %r7613;
	mov.u32 	%r7625, %r7613;
	mov.u32 	%r7626, %r7613;
	mov.u32 	%r7627, %r7613;
	mov.u32 	%r7628, %r7613;

BB4_6:
	ld.param.u32 	%r7606, [m00000_sxx_param_30];
	setp.eq.s32	%p4, %r7606, 0;
	@%p4 bra 	BB4_119;

	ld.param.u64 	%rd31, [m00000_sxx_param_16];
	shl.b64 	%rd20, %rd2, 2;
	add.s64 	%rd3, %rd31, %rd20;
	mov.u32 	%r7633, 0;

BB4_8:
	mov.u32 	%r7655, 0;
	mul.wide.u32 	%rd21, %r7633, 260;
	add.s64 	%rd22, %rd6, %rd21;
	ld.global.nc.u32 	%r1622, [%rd22+256];
	and.b32  	%r71, %r1622, 255;
	mov.u32 	%r7634, %r6;
	mov.u32 	%r7747, %r7613;
	mov.u32 	%r7748, %r7614;
	mov.u32 	%r7749, %r7615;
	mov.u32 	%r7750, %r7616;
	mov.u32 	%r7743, %r7617;
	mov.u32 	%r7744, %r7618;
	mov.u32 	%r7745, %r7619;
	mov.u32 	%r7746, %r7620;
	mov.u32 	%r7774, %r7621;
	mov.u32 	%r7773, %r7622;
	mov.u32 	%r7772, %r7623;
	mov.u32 	%r7771, %r7624;
	mov.u32 	%r7767, %r7625;
	mov.u32 	%r7768, %r7626;
	mov.u32 	%r7769, %r7627;
	mov.u32 	%r7770, %r7628;
	mov.u32 	%r89, %r8;
	mov.u32 	%r90, %r9;
	mov.u32 	%r91, %r10;
	mov.u32 	%r92, %r11;
	mov.u32 	%r7656, %r7655;
	bra.uni 	BB4_9;

BB4_166:
	xor.b32  	%r6545, %r90, %r89;
	and.b32  	%r6546, %r91, %r6545;
	xor.b32  	%r6547, %r6546, %r89;
	add.s32 	%r6548, %r92, %r6547;
	or.b32  	%r6549, %r95, %r88;
	add.s32 	%r6550, %r6548, %r6549;
	add.s32 	%r6551, %r6550, -680876936;
	shf.l.wrap.b32 	%r6552, %r6551, %r6551, 7;
	add.s32 	%r6553, %r6552, %r91;
	xor.b32  	%r6554, %r91, %r90;
	and.b32  	%r6555, %r6553, %r6554;
	xor.b32  	%r6556, %r6555, %r90;
	or.b32  	%r6557, %r96, %r87;
	add.s32 	%r6558, %r89, %r6557;
	add.s32 	%r6559, %r6558, %r6556;
	add.s32 	%r6560, %r6559, -389564586;
	shf.l.wrap.b32 	%r6561, %r6560, %r6560, 12;
	add.s32 	%r6562, %r6561, %r6553;
	xor.b32  	%r6563, %r6553, %r91;
	and.b32  	%r6564, %r6562, %r6563;
	xor.b32  	%r6565, %r6564, %r91;
	or.b32  	%r6566, %r97, %r86;
	add.s32 	%r6567, %r90, %r6566;
	add.s32 	%r6568, %r6567, %r6565;
	add.s32 	%r6569, %r6568, 606105819;
	shf.l.wrap.b32 	%r6570, %r6569, %r6569, 17;
	add.s32 	%r6571, %r6570, %r6562;
	xor.b32  	%r6572, %r6562, %r6553;
	and.b32  	%r6573, %r6571, %r6572;
	xor.b32  	%r6574, %r6573, %r6553;
	or.b32  	%r6575, %r7751, %r85;
	add.s32 	%r6576, %r91, %r6575;
	add.s32 	%r6577, %r6576, %r6574;
	add.s32 	%r6578, %r6577, -1044525330;
	shf.l.wrap.b32 	%r6579, %r6578, %r6578, 22;
	add.s32 	%r6580, %r6579, %r6571;
	xor.b32  	%r6581, %r6571, %r6562;
	and.b32  	%r6582, %r6580, %r6581;
	xor.b32  	%r6583, %r6582, %r6562;
	or.b32  	%r6584, %r99, %r84;
	add.s32 	%r6585, %r6584, %r6553;
	add.s32 	%r6586, %r6585, %r6583;
	add.s32 	%r6587, %r6586, -176418897;
	shf.l.wrap.b32 	%r6588, %r6587, %r6587, 7;
	add.s32 	%r6589, %r6588, %r6580;
	xor.b32  	%r6590, %r6580, %r6571;
	and.b32  	%r6591, %r6589, %r6590;
	xor.b32  	%r6592, %r6591, %r6571;
	or.b32  	%r6593, %r100, %r83;
	add.s32 	%r6594, %r6593, %r6562;
	add.s32 	%r6595, %r6594, %r6592;
	add.s32 	%r6596, %r6595, 1200080426;
	shf.l.wrap.b32 	%r6597, %r6596, %r6596, 12;
	add.s32 	%r6598, %r6597, %r6589;
	xor.b32  	%r6599, %r6589, %r6580;
	and.b32  	%r6600, %r6598, %r6599;
	xor.b32  	%r6601, %r6600, %r6580;
	or.b32  	%r6602, %r101, %r82;
	add.s32 	%r6603, %r6602, %r6571;
	add.s32 	%r6604, %r6603, %r6601;
	add.s32 	%r6605, %r6604, -1473231341;
	shf.l.wrap.b32 	%r6606, %r6605, %r6605, 17;
	add.s32 	%r6607, %r6606, %r6598;
	xor.b32  	%r6608, %r6598, %r6589;
	and.b32  	%r6609, %r6607, %r6608;
	xor.b32  	%r6610, %r6609, %r6589;
	or.b32  	%r6611, %r102, %r81;
	add.s32 	%r6612, %r6611, %r6580;
	add.s32 	%r6613, %r6612, %r6610;
	add.s32 	%r6614, %r6613, -45705983;
	shf.l.wrap.b32 	%r6615, %r6614, %r6614, 22;
	add.s32 	%r6616, %r6615, %r6607;
	xor.b32  	%r6617, %r6607, %r6598;
	and.b32  	%r6618, %r6616, %r6617;
	xor.b32  	%r6619, %r6618, %r6598;
	or.b32  	%r6620, %r103, %r80;
	add.s32 	%r6621, %r6620, %r6589;
	add.s32 	%r6622, %r6621, %r6619;
	add.s32 	%r6623, %r6622, 1770035416;
	shf.l.wrap.b32 	%r6624, %r6623, %r6623, 7;
	add.s32 	%r6625, %r6624, %r6616;
	xor.b32  	%r6626, %r6616, %r6607;
	and.b32  	%r6627, %r6625, %r6626;
	xor.b32  	%r6628, %r6627, %r6607;
	or.b32  	%r6629, %r104, %r79;
	add.s32 	%r6630, %r6629, %r6598;
	add.s32 	%r6631, %r6630, %r6628;
	add.s32 	%r6632, %r6631, -1958414417;
	shf.l.wrap.b32 	%r6633, %r6632, %r6632, 12;
	add.s32 	%r6634, %r6633, %r6625;
	xor.b32  	%r6635, %r6625, %r6616;
	and.b32  	%r6636, %r6634, %r6635;
	xor.b32  	%r6637, %r6636, %r6616;
	or.b32  	%r6638, %r105, %r78;
	add.s32 	%r6639, %r6638, %r6607;
	add.s32 	%r6640, %r6639, %r6637;
	add.s32 	%r6641, %r6640, -42063;
	shf.l.wrap.b32 	%r6642, %r6641, %r6641, 17;
	add.s32 	%r6643, %r6642, %r6634;
	xor.b32  	%r6644, %r6634, %r6625;
	and.b32  	%r6645, %r6643, %r6644;
	xor.b32  	%r6646, %r6645, %r6625;
	or.b32  	%r6647, %r106, %r77;
	add.s32 	%r6648, %r6647, %r6616;
	add.s32 	%r6649, %r6648, %r6646;
	add.s32 	%r6650, %r6649, -1990404162;
	shf.l.wrap.b32 	%r6651, %r6650, %r6650, 22;
	add.s32 	%r6652, %r6651, %r6643;
	xor.b32  	%r6653, %r6643, %r6634;
	and.b32  	%r6654, %r6652, %r6653;
	xor.b32  	%r6655, %r6654, %r6634;
	or.b32  	%r6656, %r107, %r76;
	add.s32 	%r6657, %r6656, %r6625;
	add.s32 	%r6658, %r6657, %r6655;
	add.s32 	%r6659, %r6658, 1804603682;
	shf.l.wrap.b32 	%r6660, %r6659, %r6659, 7;
	add.s32 	%r6661, %r6660, %r6652;
	xor.b32  	%r6662, %r6652, %r6643;
	and.b32  	%r6663, %r6661, %r6662;
	xor.b32  	%r6664, %r6663, %r6643;
	or.b32  	%r6665, %r108, %r75;
	add.s32 	%r6666, %r6665, %r6634;
	add.s32 	%r6667, %r6666, %r6664;
	add.s32 	%r6668, %r6667, -40341101;
	shf.l.wrap.b32 	%r6669, %r6668, %r6668, 12;
	add.s32 	%r6670, %r6669, %r6661;
	xor.b32  	%r6671, %r6661, %r6652;
	and.b32  	%r6672, %r6670, %r6671;
	xor.b32  	%r6673, %r6672, %r6652;
	or.b32  	%r6674, %r109, %r74;
	add.s32 	%r6675, %r6674, %r6643;
	add.s32 	%r6676, %r6675, %r6673;
	add.s32 	%r6677, %r6676, -1502002290;
	shf.l.wrap.b32 	%r6678, %r6677, %r6677, 17;
	add.s32 	%r6679, %r6678, %r6670;
	xor.b32  	%r6680, %r6670, %r6661;
	and.b32  	%r6681, %r6679, %r6680;
	xor.b32  	%r6682, %r6681, %r6661;
	or.b32  	%r6683, %r110, %r73;
	add.s32 	%r6684, %r6683, %r6652;
	add.s32 	%r6685, %r6684, %r6682;
	add.s32 	%r6686, %r6685, 1236535329;
	shf.l.wrap.b32 	%r6687, %r6686, %r6686, 22;
	add.s32 	%r6688, %r6687, %r6679;
	xor.b32  	%r6689, %r6688, %r6679;
	and.b32  	%r6690, %r6689, %r6670;
	xor.b32  	%r6691, %r6690, %r6679;
	add.s32 	%r6692, %r6557, %r6661;
	add.s32 	%r6693, %r6692, %r6691;
	add.s32 	%r6694, %r6693, -165796510;
	shf.l.wrap.b32 	%r6695, %r6694, %r6694, 5;
	add.s32 	%r6696, %r6695, %r6688;
	xor.b32  	%r6697, %r6696, %r6688;
	and.b32  	%r6698, %r6697, %r6679;
	xor.b32  	%r6699, %r6698, %r6688;
	add.s32 	%r6700, %r6602, %r6670;
	add.s32 	%r6701, %r6700, %r6699;
	add.s32 	%r6702, %r6701, -1069501632;
	shf.l.wrap.b32 	%r6703, %r6702, %r6702, 9;
	add.s32 	%r6704, %r6703, %r6696;
	xor.b32  	%r6705, %r6704, %r6696;
	and.b32  	%r6706, %r6705, %r6688;
	xor.b32  	%r6707, %r6706, %r6696;
	add.s32 	%r6708, %r6647, %r6679;
	add.s32 	%r6709, %r6708, %r6707;
	add.s32 	%r6710, %r6709, 643717713;
	shf.l.wrap.b32 	%r6711, %r6710, %r6710, 14;
	add.s32 	%r6712, %r6711, %r6704;
	xor.b32  	%r6713, %r6712, %r6704;
	and.b32  	%r6714, %r6713, %r6696;
	xor.b32  	%r6715, %r6714, %r6704;
	add.s32 	%r6716, %r6549, %r6688;
	add.s32 	%r6717, %r6716, %r6715;
	add.s32 	%r6718, %r6717, -373897302;
	shf.l.wrap.b32 	%r6719, %r6718, %r6718, 20;
	add.s32 	%r6720, %r6719, %r6712;
	xor.b32  	%r6721, %r6720, %r6712;
	and.b32  	%r6722, %r6721, %r6704;
	xor.b32  	%r6723, %r6722, %r6712;
	add.s32 	%r6724, %r6593, %r6696;
	add.s32 	%r6725, %r6724, %r6723;
	add.s32 	%r6726, %r6725, -701558691;
	shf.l.wrap.b32 	%r6727, %r6726, %r6726, 5;
	add.s32 	%r6728, %r6727, %r6720;
	xor.b32  	%r6729, %r6728, %r6720;
	and.b32  	%r6730, %r6729, %r6712;
	xor.b32  	%r6731, %r6730, %r6720;
	add.s32 	%r6732, %r6638, %r6704;
	add.s32 	%r6733, %r6732, %r6731;
	add.s32 	%r6734, %r6733, 38016083;
	shf.l.wrap.b32 	%r6735, %r6734, %r6734, 9;
	add.s32 	%r6736, %r6735, %r6728;
	xor.b32  	%r6737, %r6736, %r6728;
	and.b32  	%r6738, %r6737, %r6720;
	xor.b32  	%r6739, %r6738, %r6728;
	add.s32 	%r6740, %r6683, %r6712;
	add.s32 	%r6741, %r6740, %r6739;
	add.s32 	%r6742, %r6741, -660478335;
	shf.l.wrap.b32 	%r6743, %r6742, %r6742, 14;
	add.s32 	%r6744, %r6743, %r6736;
	xor.b32  	%r6745, %r6744, %r6736;
	and.b32  	%r6746, %r6745, %r6728;
	xor.b32  	%r6747, %r6746, %r6736;
	add.s32 	%r6748, %r6584, %r6720;
	add.s32 	%r6749, %r6748, %r6747;
	add.s32 	%r6750, %r6749, -405537848;
	shf.l.wrap.b32 	%r6751, %r6750, %r6750, 20;
	add.s32 	%r6752, %r6751, %r6744;
	xor.b32  	%r6753, %r6752, %r6744;
	and.b32  	%r6754, %r6753, %r6736;
	xor.b32  	%r6755, %r6754, %r6744;
	add.s32 	%r6756, %r6629, %r6728;
	add.s32 	%r6757, %r6756, %r6755;
	add.s32 	%r6758, %r6757, 568446438;
	shf.l.wrap.b32 	%r6759, %r6758, %r6758, 5;
	add.s32 	%r6760, %r6759, %r6752;
	xor.b32  	%r6761, %r6760, %r6752;
	and.b32  	%r6762, %r6761, %r6744;
	xor.b32  	%r6763, %r6762, %r6752;
	add.s32 	%r6764, %r6674, %r6736;
	add.s32 	%r6765, %r6764, %r6763;
	add.s32 	%r6766, %r6765, -1019803690;
	shf.l.wrap.b32 	%r6767, %r6766, %r6766, 9;
	add.s32 	%r6768, %r6767, %r6760;
	xor.b32  	%r6769, %r6768, %r6760;
	and.b32  	%r6770, %r6769, %r6752;
	xor.b32  	%r6771, %r6770, %r6760;
	add.s32 	%r6772, %r6575, %r6744;
	add.s32 	%r6773, %r6772, %r6771;
	add.s32 	%r6774, %r6773, -187363961;
	shf.l.wrap.b32 	%r6775, %r6774, %r6774, 14;
	add.s32 	%r6776, %r6775, %r6768;
	xor.b32  	%r6777, %r6776, %r6768;
	and.b32  	%r6778, %r6777, %r6760;
	xor.b32  	%r6779, %r6778, %r6768;
	add.s32 	%r6780, %r6620, %r6752;
	add.s32 	%r6781, %r6780, %r6779;
	add.s32 	%r6782, %r6781, 1163531501;
	shf.l.wrap.b32 	%r6783, %r6782, %r6782, 20;
	add.s32 	%r6784, %r6783, %r6776;
	xor.b32  	%r6785, %r6784, %r6776;
	and.b32  	%r6786, %r6785, %r6768;
	xor.b32  	%r6787, %r6786, %r6776;
	add.s32 	%r6788, %r6665, %r6760;
	add.s32 	%r6789, %r6788, %r6787;
	add.s32 	%r6790, %r6789, -1444681467;
	shf.l.wrap.b32 	%r6791, %r6790, %r6790, 5;
	add.s32 	%r6792, %r6791, %r6784;
	xor.b32  	%r6793, %r6792, %r6784;
	and.b32  	%r6794, %r6793, %r6776;
	xor.b32  	%r6795, %r6794, %r6784;
	add.s32 	%r6796, %r6566, %r6768;
	add.s32 	%r6797, %r6796, %r6795;
	add.s32 	%r6798, %r6797, -51403784;
	shf.l.wrap.b32 	%r6799, %r6798, %r6798, 9;
	add.s32 	%r6800, %r6799, %r6792;
	xor.b32  	%r6801, %r6800, %r6792;
	and.b32  	%r6802, %r6801, %r6784;
	xor.b32  	%r6803, %r6802, %r6792;
	add.s32 	%r6804, %r6611, %r6776;
	add.s32 	%r6805, %r6804, %r6803;
	add.s32 	%r6806, %r6805, 1735328473;
	shf.l.wrap.b32 	%r6807, %r6806, %r6806, 14;
	add.s32 	%r6808, %r6807, %r6800;
	xor.b32  	%r6809, %r6808, %r6800;
	and.b32  	%r6810, %r6809, %r6792;
	xor.b32  	%r6811, %r6810, %r6800;
	add.s32 	%r6812, %r6656, %r6784;
	add.s32 	%r6813, %r6812, %r6811;
	add.s32 	%r6814, %r6813, -1926607734;
	shf.l.wrap.b32 	%r6815, %r6814, %r6814, 20;
	add.s32 	%r6816, %r6815, %r6808;
	xor.b32  	%r6817, %r6816, %r6808;
	xor.b32  	%r6818, %r6817, %r6800;
	add.s32 	%r6819, %r6593, %r6792;
	add.s32 	%r6820, %r6819, %r6818;
	add.s32 	%r6821, %r6820, -378558;
	shf.l.wrap.b32 	%r6822, %r6821, %r6821, 4;
	add.s32 	%r6823, %r6822, %r6816;
	xor.b32  	%r6824, %r6823, %r6817;
	add.s32 	%r6825, %r6620, %r6800;
	add.s32 	%r6826, %r6825, %r6824;
	add.s32 	%r6827, %r6826, -2022574463;
	shf.l.wrap.b32 	%r6828, %r6827, %r6827, 11;
	add.s32 	%r6829, %r6828, %r6823;
	xor.b32  	%r6830, %r6829, %r6823;
	xor.b32  	%r6831, %r6830, %r6816;
	add.s32 	%r6832, %r6647, %r6808;
	add.s32 	%r6833, %r6832, %r6831;
	add.s32 	%r6834, %r6833, 1839030562;
	shf.l.wrap.b32 	%r6835, %r6834, %r6834, 16;
	add.s32 	%r6836, %r6835, %r6829;
	xor.b32  	%r6837, %r6836, %r6830;
	add.s32 	%r6838, %r6674, %r6816;
	add.s32 	%r6839, %r6838, %r6837;
	add.s32 	%r6840, %r6839, -35309556;
	shf.l.wrap.b32 	%r6841, %r6840, %r6840, 23;
	add.s32 	%r6842, %r6841, %r6836;
	xor.b32  	%r6843, %r6842, %r6836;
	xor.b32  	%r6844, %r6843, %r6829;
	add.s32 	%r6845, %r6557, %r6823;
	add.s32 	%r6846, %r6845, %r6844;
	add.s32 	%r6847, %r6846, -1530992060;
	shf.l.wrap.b32 	%r6848, %r6847, %r6847, 4;
	add.s32 	%r6849, %r6848, %r6842;
	xor.b32  	%r6850, %r6849, %r6843;
	add.s32 	%r6851, %r6584, %r6829;
	add.s32 	%r6852, %r6851, %r6850;
	add.s32 	%r6853, %r6852, 1272893353;
	shf.l.wrap.b32 	%r6854, %r6853, %r6853, 11;
	add.s32 	%r6855, %r6854, %r6849;
	xor.b32  	%r6856, %r6855, %r6849;
	xor.b32  	%r6857, %r6856, %r6842;
	add.s32 	%r6858, %r6611, %r6836;
	add.s32 	%r6859, %r6858, %r6857;
	add.s32 	%r6860, %r6859, -155497632;
	shf.l.wrap.b32 	%r6861, %r6860, %r6860, 16;
	add.s32 	%r6862, %r6861, %r6855;
	xor.b32  	%r6863, %r6862, %r6856;
	add.s32 	%r6864, %r6638, %r6842;
	add.s32 	%r6865, %r6864, %r6863;
	add.s32 	%r6866, %r6865, -1094730640;
	shf.l.wrap.b32 	%r6867, %r6866, %r6866, 23;
	add.s32 	%r6868, %r6867, %r6862;
	xor.b32  	%r6869, %r6868, %r6862;
	xor.b32  	%r6870, %r6869, %r6855;
	add.s32 	%r6871, %r6665, %r6849;
	add.s32 	%r6872, %r6871, %r6870;
	add.s32 	%r6873, %r6872, 681279174;
	shf.l.wrap.b32 	%r6874, %r6873, %r6873, 4;
	add.s32 	%r6875, %r6874, %r6868;
	xor.b32  	%r6876, %r6875, %r6869;
	add.s32 	%r6877, %r6549, %r6855;
	add.s32 	%r6878, %r6877, %r6876;
	add.s32 	%r6879, %r6878, -358537222;
	shf.l.wrap.b32 	%r6880, %r6879, %r6879, 11;
	add.s32 	%r6881, %r6880, %r6875;
	xor.b32  	%r6882, %r6881, %r6875;
	xor.b32  	%r6883, %r6882, %r6868;
	add.s32 	%r6884, %r6575, %r6862;
	add.s32 	%r6885, %r6884, %r6883;
	add.s32 	%r6886, %r6885, -722521979;
	shf.l.wrap.b32 	%r6887, %r6886, %r6886, 16;
	add.s32 	%r6888, %r6887, %r6881;
	xor.b32  	%r6889, %r6888, %r6882;
	add.s32 	%r6890, %r6602, %r6868;
	add.s32 	%r6891, %r6890, %r6889;
	add.s32 	%r6892, %r6891, 76029189;
	shf.l.wrap.b32 	%r6893, %r6892, %r6892, 23;
	add.s32 	%r6894, %r6893, %r6888;
	xor.b32  	%r6895, %r6894, %r6888;
	xor.b32  	%r6896, %r6895, %r6881;
	add.s32 	%r6897, %r6629, %r6875;
	add.s32 	%r6898, %r6897, %r6896;
	add.s32 	%r6899, %r6898, -640364487;
	shf.l.wrap.b32 	%r6900, %r6899, %r6899, 4;
	add.s32 	%r6901, %r6900, %r6894;
	xor.b32  	%r6902, %r6901, %r6895;
	add.s32 	%r6903, %r6656, %r6881;
	add.s32 	%r6904, %r6903, %r6902;
	add.s32 	%r6905, %r6904, -421815835;
	shf.l.wrap.b32 	%r6906, %r6905, %r6905, 11;
	add.s32 	%r6907, %r6906, %r6901;
	xor.b32  	%r6908, %r6907, %r6901;
	xor.b32  	%r6909, %r6908, %r6894;
	add.s32 	%r6910, %r6683, %r6888;
	add.s32 	%r6911, %r6910, %r6909;
	add.s32 	%r6912, %r6911, 530742520;
	shf.l.wrap.b32 	%r6913, %r6912, %r6912, 16;
	add.s32 	%r6914, %r6913, %r6907;
	xor.b32  	%r6915, %r6914, %r6908;
	add.s32 	%r6916, %r6566, %r6894;
	add.s32 	%r6917, %r6916, %r6915;
	add.s32 	%r6918, %r6917, -995338651;
	shf.l.wrap.b32 	%r6919, %r6918, %r6918, 23;
	add.s32 	%r6920, %r6919, %r6914;
	not.b32 	%r6921, %r6907;
	or.b32  	%r6922, %r6920, %r6921;
	xor.b32  	%r6923, %r6922, %r6914;
	add.s32 	%r6924, %r6549, %r6901;
	add.s32 	%r6925, %r6924, %r6923;
	add.s32 	%r6926, %r6925, -198630844;
	shf.l.wrap.b32 	%r6927, %r6926, %r6926, 6;
	add.s32 	%r6928, %r6927, %r6920;
	not.b32 	%r6929, %r6914;
	or.b32  	%r6930, %r6928, %r6929;
	xor.b32  	%r6931, %r6930, %r6920;
	add.s32 	%r6932, %r6611, %r6907;
	add.s32 	%r6933, %r6932, %r6931;
	add.s32 	%r6934, %r6933, 1126891415;
	shf.l.wrap.b32 	%r6935, %r6934, %r6934, 10;
	add.s32 	%r6936, %r6935, %r6928;
	not.b32 	%r6937, %r6920;
	or.b32  	%r6938, %r6936, %r6937;
	xor.b32  	%r6939, %r6938, %r6928;
	add.s32 	%r6940, %r6674, %r6914;
	add.s32 	%r6941, %r6940, %r6939;
	add.s32 	%r6942, %r6941, -1416354905;
	shf.l.wrap.b32 	%r6943, %r6942, %r6942, 15;
	add.s32 	%r6944, %r6943, %r6936;
	not.b32 	%r6945, %r6928;
	or.b32  	%r6946, %r6944, %r6945;
	xor.b32  	%r6947, %r6946, %r6936;
	add.s32 	%r6948, %r6593, %r6920;
	add.s32 	%r6949, %r6948, %r6947;
	add.s32 	%r6950, %r6949, -57434055;
	shf.l.wrap.b32 	%r6951, %r6950, %r6950, 21;
	add.s32 	%r6952, %r6951, %r6944;
	not.b32 	%r6953, %r6936;
	or.b32  	%r6954, %r6952, %r6953;
	xor.b32  	%r6955, %r6954, %r6944;
	add.s32 	%r6956, %r6656, %r6928;
	add.s32 	%r6957, %r6956, %r6955;
	add.s32 	%r6958, %r6957, 1700485571;
	shf.l.wrap.b32 	%r6959, %r6958, %r6958, 6;
	add.s32 	%r6960, %r6959, %r6952;
	not.b32 	%r6961, %r6944;
	or.b32  	%r6962, %r6960, %r6961;
	xor.b32  	%r6963, %r6962, %r6952;
	add.s32 	%r6964, %r6575, %r6936;
	add.s32 	%r6965, %r6964, %r6963;
	add.s32 	%r6966, %r6965, -1894986606;
	shf.l.wrap.b32 	%r6967, %r6966, %r6966, 10;
	add.s32 	%r6968, %r6967, %r6960;
	not.b32 	%r6969, %r6952;
	or.b32  	%r6970, %r6968, %r6969;
	xor.b32  	%r6971, %r6970, %r6960;
	add.s32 	%r6972, %r6638, %r6944;
	add.s32 	%r6973, %r6972, %r6971;
	add.s32 	%r6974, %r6973, -1051523;
	shf.l.wrap.b32 	%r6975, %r6974, %r6974, 15;
	add.s32 	%r6976, %r6975, %r6968;
	not.b32 	%r6977, %r6960;
	or.b32  	%r6978, %r6976, %r6977;
	xor.b32  	%r6979, %r6978, %r6968;
	add.s32 	%r6980, %r6557, %r6952;
	add.s32 	%r6981, %r6980, %r6979;
	add.s32 	%r6982, %r6981, -2054922799;
	shf.l.wrap.b32 	%r6983, %r6982, %r6982, 21;
	add.s32 	%r6984, %r6983, %r6976;
	not.b32 	%r6985, %r6968;
	or.b32  	%r6986, %r6984, %r6985;
	xor.b32  	%r6987, %r6986, %r6976;
	add.s32 	%r6988, %r6620, %r6960;
	add.s32 	%r6989, %r6988, %r6987;
	add.s32 	%r6990, %r6989, 1873313359;
	shf.l.wrap.b32 	%r6991, %r6990, %r6990, 6;
	add.s32 	%r6992, %r6991, %r6984;
	not.b32 	%r6993, %r6976;
	or.b32  	%r6994, %r6992, %r6993;
	xor.b32  	%r6995, %r6994, %r6984;
	add.s32 	%r6996, %r6683, %r6968;
	add.s32 	%r6997, %r6996, %r6995;
	add.s32 	%r6998, %r6997, -30611744;
	shf.l.wrap.b32 	%r6999, %r6998, %r6998, 10;
	add.s32 	%r7000, %r6999, %r6992;
	not.b32 	%r7001, %r6984;
	or.b32  	%r7002, %r7000, %r7001;
	xor.b32  	%r7003, %r7002, %r6992;
	add.s32 	%r7004, %r6602, %r6976;
	add.s32 	%r7005, %r7004, %r7003;
	add.s32 	%r7006, %r7005, -1560198380;
	shf.l.wrap.b32 	%r7007, %r7006, %r7006, 15;
	add.s32 	%r7008, %r7007, %r7000;
	not.b32 	%r7009, %r6992;
	or.b32  	%r7010, %r7008, %r7009;
	xor.b32  	%r7011, %r7010, %r7000;
	add.s32 	%r7012, %r6665, %r6984;
	add.s32 	%r7013, %r7012, %r7011;
	add.s32 	%r7014, %r7013, 1309151649;
	shf.l.wrap.b32 	%r7015, %r7014, %r7014, 21;
	add.s32 	%r7016, %r7015, %r7008;
	not.b32 	%r7017, %r7000;
	or.b32  	%r7018, %r7016, %r7017;
	xor.b32  	%r7019, %r7018, %r7008;
	add.s32 	%r7020, %r6584, %r6992;
	add.s32 	%r7021, %r7020, %r7019;
	add.s32 	%r7022, %r7021, -145523070;
	shf.l.wrap.b32 	%r7023, %r7022, %r7022, 6;
	add.s32 	%r7024, %r7023, %r7016;
	not.b32 	%r7025, %r7008;
	or.b32  	%r7026, %r7024, %r7025;
	xor.b32  	%r7027, %r7026, %r7016;
	add.s32 	%r7028, %r6647, %r7000;
	add.s32 	%r7029, %r7028, %r7027;
	add.s32 	%r7030, %r7029, -1120210379;
	shf.l.wrap.b32 	%r7031, %r7030, %r7030, 10;
	add.s32 	%r7032, %r7031, %r7024;
	not.b32 	%r7033, %r7016;
	or.b32  	%r7034, %r7032, %r7033;
	xor.b32  	%r7035, %r7034, %r7024;
	add.s32 	%r7036, %r6566, %r7008;
	add.s32 	%r7037, %r7036, %r7035;
	add.s32 	%r7038, %r7037, 718787259;
	shf.l.wrap.b32 	%r7039, %r7038, %r7038, 15;
	add.s32 	%r7040, %r7039, %r7032;
	not.b32 	%r7041, %r7024;
	or.b32  	%r7042, %r7040, %r7041;
	xor.b32  	%r7043, %r7042, %r7032;
	add.s32 	%r7044, %r6629, %r7016;
	add.s32 	%r7045, %r7044, %r7043;
	add.s32 	%r7046, %r7045, -343485551;
	shf.l.wrap.b32 	%r7047, %r7046, %r7046, 21;
	add.s32 	%r92, %r7024, %r92;
	add.s32 	%r7048, %r7040, %r91;
	add.s32 	%r91, %r7048, %r7047;
	add.s32 	%r90, %r7040, %r90;
	add.s32 	%r89, %r7032, %r89;
	add.s32 	%r7655, %r7655, 64;
	add.s32 	%r7656, %r7656, 16;
	add.s32 	%r7634, %r7634, 64;

BB4_9:
	mov.u32 	%r88, %r7770;
	mov.u32 	%r87, %r7769;
	mov.u32 	%r86, %r7768;
	mov.u32 	%r85, %r7767;
	mov.u32 	%r84, %r7771;
	mov.u32 	%r83, %r7772;
	mov.u32 	%r82, %r7773;
	mov.u32 	%r81, %r7774;
	mov.u32 	%r80, %r7746;
	mov.u32 	%r79, %r7745;
	mov.u32 	%r78, %r7744;
	mov.u32 	%r77, %r7743;
	mov.u32 	%r76, %r7750;
	mov.u32 	%r75, %r7749;
	mov.u32 	%r74, %r7748;
	mov.u32 	%r73, %r7747;
	cvt.u64.u32	%rd29, %r7633;
	add.s32 	%r1623, %r71, -64;
	setp.lt.s32	%p5, %r7655, %r1623;
	mul.lo.s64 	%rd23, %rd29, 260;
	add.s64 	%rd24, %rd6, %rd23;
	mul.wide.s32 	%rd25, %r7656, 4;
	add.s64 	%rd26, %rd24, %rd25;
	ld.global.nc.u32 	%r95, [%rd26];
	mov.u32 	%r1624, 4;
	ld.global.nc.u32 	%r96, [%rd26+4];
	ld.global.nc.u32 	%r97, [%rd26+8];
	ld.global.nc.u32 	%r98, [%rd26+12];
	ld.global.nc.u32 	%r99, [%rd26+16];
	ld.global.nc.u32 	%r100, [%rd26+20];
	ld.global.nc.u32 	%r101, [%rd26+24];
	ld.global.nc.u32 	%r102, [%rd26+28];
	ld.global.nc.u32 	%r103, [%rd26+32];
	ld.global.nc.u32 	%r104, [%rd26+36];
	ld.global.nc.u32 	%r105, [%rd26+40];
	ld.global.nc.u32 	%r106, [%rd26+44];
	ld.global.nc.u32 	%r107, [%rd26+48];
	ld.global.nc.u32 	%r108, [%rd26+52];
	ld.global.nc.u32 	%r109, [%rd26+56];
	ld.global.nc.u32 	%r110, [%rd26+60];
	and.b32  	%r111, %r7634, 3;
	sub.s32 	%r112, %r1624, %r111;
	@%p5 bra 	BB4_120;
	bra.uni 	BB4_10;

BB4_120:
	bfe.u32 	%r5200, %r7634, 2, 4;
	mov.u32 	%r7743, 0;
	setp.gt.s32	%p88, %r5200, 7;
	@%p88 bra 	BB4_136;

	setp.gt.s32	%p100, %r5200, 3;
	@%p100 bra 	BB4_129;

	setp.gt.s32	%p106, %r5200, 1;
	@%p106 bra 	BB4_126;

	setp.eq.s32	%p109, %r5200, 0;
	@%p109 bra 	BB4_161;
	bra.uni 	BB4_124;

BB4_161:
	and.b32  	%r6544, %r112, 3;
	shl.b32 	%r6528, %r6544, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6461, %r110, %r7743, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6465, %r109, %r110, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6469, %r108, %r109, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6473, %r107, %r108, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6477, %r106, %r107, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6481, %r105, %r106, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6485, %r104, %r105, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6489, %r103, %r104, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6493, %r102, %r103, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6497, %r101, %r102, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6501, %r100, %r101, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6505, %r99, %r100, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6509, %r98, %r99, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6513, %r97, %r98, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6517, %r96, %r97, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6521, %r95, %r96, %r6528;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6525, %r7743, %r95, %r6528;
	// inline asm
	setp.eq.s32	%p126, %r111, 0;
	selp.b32	%r7751, %r6509, %r6513, %p126;
	selp.b32	%r97, %r6513, %r6517, %p126;
	selp.b32	%r96, %r6517, %r6521, %p126;
	selp.b32	%r95, %r6521, %r6525, %p126;
	selp.b32	%r102, %r6493, %r6497, %p126;
	selp.b32	%r101, %r6497, %r6501, %p126;
	selp.b32	%r100, %r6501, %r6505, %p126;
	selp.b32	%r99, %r6505, %r6509, %p126;
	selp.b32	%r106, %r6477, %r6481, %p126;
	selp.b32	%r105, %r6481, %r6485, %p126;
	selp.b32	%r104, %r6485, %r6489, %p126;
	selp.b32	%r103, %r6489, %r6493, %p126;
	selp.b32	%r110, %r6461, %r6465, %p126;
	selp.b32	%r109, %r6465, %r6469, %p126;
	selp.b32	%r108, %r6469, %r6473, %p126;
	selp.b32	%r107, %r6473, %r6477, %p126;
	selp.b32	%r7770, 0, %r6461, %p126;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7767, %r7743;
	mov.u32 	%r7768, %r7743;
	mov.u32 	%r7769, %r7743;
	bra.uni 	BB4_162;

BB4_136:
	setp.gt.s32	%p89, %r5200, 11;
	@%p89 bra 	BB4_144;

	setp.gt.s32	%p95, %r5200, 9;
	@%p95 bra 	BB4_141;

	setp.eq.s32	%p98, %r5200, 8;
	@%p98 bra 	BB4_156;
	bra.uni 	BB4_139;

BB4_156:
	and.b32  	%r5872, %r112, 3;
	shl.b32 	%r5856, %r5872, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r5789, %r110, %r7743, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5793, %r109, %r110, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5797, %r108, %r109, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5801, %r107, %r108, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5805, %r106, %r107, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5809, %r105, %r106, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5813, %r104, %r105, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5817, %r103, %r104, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5821, %r102, %r103, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5825, %r101, %r102, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5829, %r100, %r101, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5833, %r99, %r100, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5837, %r98, %r99, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5841, %r97, %r98, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5845, %r96, %r97, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5849, %r95, %r96, %r5856;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5853, %r7743, %r95, %r5856;
	// inline asm
	setp.eq.s32	%p118, %r111, 0;
	selp.b32	%r7746, 0, %r5789, %p118;
	selp.b32	%r106, %r5837, %r5841, %p118;
	selp.b32	%r105, %r5841, %r5845, %p118;
	selp.b32	%r104, %r5845, %r5849, %p118;
	selp.b32	%r103, %r5849, %r5853, %p118;
	selp.b32	%r110, %r5821, %r5825, %p118;
	selp.b32	%r109, %r5825, %r5829, %p118;
	selp.b32	%r108, %r5829, %r5833, %p118;
	selp.b32	%r107, %r5833, %r5837, %p118;
	selp.b32	%r7767, %r5805, %r5809, %p118;
	selp.b32	%r7768, %r5809, %r5813, %p118;
	selp.b32	%r7769, %r5813, %r5817, %p118;
	selp.b32	%r7770, %r5817, %r5821, %p118;
	selp.b32	%r7771, %r5801, %r5805, %p118;
	selp.b32	%r7772, %r5797, %r5801, %p118;
	selp.b32	%r7773, %r5793, %r5797, %p118;
	selp.b32	%r7774, %r5789, %r5793, %p118;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r102, %r7743;
	bra.uni 	BB4_157;

BB4_129:
	setp.gt.s32	%p101, %r5200, 5;
	@%p101 bra 	BB4_133;

	setp.eq.s32	%p104, %r5200, 4;
	@%p104 bra 	BB4_159;
	bra.uni 	BB4_131;

BB4_159:
	and.b32  	%r6208, %r112, 3;
	shl.b32 	%r6192, %r6208, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6125, %r110, %r7743, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6129, %r109, %r110, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6133, %r108, %r109, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6137, %r107, %r108, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6141, %r106, %r107, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6145, %r105, %r106, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6149, %r104, %r105, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6153, %r103, %r104, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6157, %r102, %r103, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6161, %r101, %r102, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6165, %r100, %r101, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6169, %r99, %r100, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6173, %r98, %r99, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6177, %r97, %r98, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6181, %r96, %r97, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6185, %r95, %r96, %r6192;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6189, %r7743, %r95, %r6192;
	// inline asm
	setp.eq.s32	%p122, %r111, 0;
	selp.b32	%r102, %r6173, %r6177, %p122;
	selp.b32	%r101, %r6177, %r6181, %p122;
	selp.b32	%r100, %r6181, %r6185, %p122;
	selp.b32	%r99, %r6185, %r6189, %p122;
	selp.b32	%r106, %r6157, %r6161, %p122;
	selp.b32	%r105, %r6161, %r6165, %p122;
	selp.b32	%r104, %r6165, %r6169, %p122;
	selp.b32	%r103, %r6169, %r6173, %p122;
	selp.b32	%r110, %r6141, %r6145, %p122;
	selp.b32	%r109, %r6145, %r6149, %p122;
	selp.b32	%r108, %r6149, %r6153, %p122;
	selp.b32	%r107, %r6153, %r6157, %p122;
	selp.b32	%r7767, %r6125, %r6129, %p122;
	selp.b32	%r7768, %r6129, %r6133, %p122;
	selp.b32	%r7769, %r6133, %r6137, %p122;
	selp.b32	%r7770, %r6137, %r6141, %p122;
	selp.b32	%r7771, 0, %r6125, %p122;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	bra.uni 	BB4_163;

BB4_144:
	setp.gt.s32	%p90, %r5200, 13;
	@%p90 bra 	BB4_148;

	setp.eq.s32	%p93, %r5200, 12;
	@%p93 bra 	BB4_153;
	bra.uni 	BB4_146;

BB4_153:
	and.b32  	%r5536, %r112, 3;
	shl.b32 	%r5520, %r5536, 3;
	mov.u32 	%r7747, 0;
	// inline asm
	shf.r.wrap.b32 %r5453, %r110, %r7747, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5457, %r109, %r110, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5461, %r108, %r109, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5465, %r107, %r108, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5469, %r106, %r107, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5473, %r105, %r106, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5477, %r104, %r105, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5481, %r103, %r104, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5485, %r102, %r103, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5489, %r101, %r102, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5493, %r100, %r101, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5497, %r99, %r100, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5501, %r98, %r99, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5505, %r97, %r98, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5509, %r96, %r97, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5513, %r95, %r96, %r5520;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5517, %r7747, %r95, %r5520;
	// inline asm
	setp.eq.s32	%p114, %r111, 0;
	selp.b32	%r7743, %r5453, %r5457, %p114;
	selp.b32	%r7744, %r5457, %r5461, %p114;
	selp.b32	%r7745, %r5461, %r5465, %p114;
	selp.b32	%r7746, %r5465, %r5469, %p114;
	selp.b32	%r7750, 0, %r5453, %p114;
	selp.b32	%r110, %r5501, %r5505, %p114;
	selp.b32	%r109, %r5505, %r5509, %p114;
	selp.b32	%r108, %r5509, %r5513, %p114;
	selp.b32	%r107, %r5513, %r5517, %p114;
	selp.b32	%r7767, %r5485, %r5489, %p114;
	selp.b32	%r7768, %r5489, %r5493, %p114;
	selp.b32	%r7769, %r5493, %r5497, %p114;
	selp.b32	%r7770, %r5497, %r5501, %p114;
	selp.b32	%r7771, %r5481, %r5485, %p114;
	selp.b32	%r7772, %r5477, %r5481, %p114;
	selp.b32	%r7773, %r5473, %r5477, %p114;
	selp.b32	%r7774, %r5469, %r5473, %p114;
	mov.u32 	%r7748, %r7747;
	mov.u32 	%r7749, %r7747;
	mov.u32 	%r7751, %r7747;
	mov.u32 	%r97, %r7747;
	mov.u32 	%r96, %r7747;
	mov.u32 	%r95, %r7747;
	mov.u32 	%r102, %r7747;
	mov.u32 	%r101, %r7747;
	mov.u32 	%r100, %r7747;
	mov.u32 	%r99, %r7747;
	mov.u32 	%r106, %r7747;
	bra.uni 	BB4_154;

BB4_126:
	setp.eq.s32	%p107, %r5200, 2;
	@%p107 bra 	BB4_160;
	bra.uni 	BB4_127;

BB4_160:
	and.b32  	%r6376, %r112, 3;
	shl.b32 	%r6360, %r6376, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6293, %r110, %r7743, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6297, %r109, %r110, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6301, %r108, %r109, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6305, %r107, %r108, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6309, %r106, %r107, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6313, %r105, %r106, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6317, %r104, %r105, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6321, %r103, %r104, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6325, %r102, %r103, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6329, %r101, %r102, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6333, %r100, %r101, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6337, %r99, %r100, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6341, %r98, %r99, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6345, %r97, %r98, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6349, %r96, %r97, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6353, %r95, %r96, %r6360;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6357, %r7743, %r95, %r6360;
	// inline asm
	setp.eq.s32	%p124, %r111, 0;
	selp.b32	%r7751, %r6349, %r6353, %p124;
	selp.b32	%r97, %r6353, %r6357, %p124;
	selp.b32	%r102, %r6333, %r6337, %p124;
	selp.b32	%r101, %r6337, %r6341, %p124;
	selp.b32	%r100, %r6341, %r6345, %p124;
	selp.b32	%r99, %r6345, %r6349, %p124;
	selp.b32	%r106, %r6317, %r6321, %p124;
	selp.b32	%r105, %r6321, %r6325, %p124;
	selp.b32	%r104, %r6325, %r6329, %p124;
	selp.b32	%r103, %r6329, %r6333, %p124;
	selp.b32	%r110, %r6301, %r6305, %p124;
	selp.b32	%r109, %r6305, %r6309, %p124;
	selp.b32	%r108, %r6309, %r6313, %p124;
	selp.b32	%r107, %r6313, %r6317, %p124;
	selp.b32	%r7768, 0, %r6293, %p124;
	selp.b32	%r7769, %r6293, %r6297, %p124;
	selp.b32	%r7770, %r6297, %r6301, %p124;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r7767, %r7743;
	bra.uni 	BB4_162;

BB4_141:
	setp.eq.s32	%p96, %r5200, 10;
	@%p96 bra 	BB4_155;
	bra.uni 	BB4_142;

BB4_155:
	and.b32  	%r5704, %r112, 3;
	shl.b32 	%r5688, %r5704, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r5621, %r110, %r7743, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5625, %r109, %r110, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5629, %r108, %r109, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5633, %r107, %r108, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5637, %r106, %r107, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5641, %r105, %r106, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5645, %r104, %r105, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5649, %r103, %r104, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5653, %r102, %r103, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5657, %r101, %r102, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5661, %r100, %r101, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5665, %r99, %r100, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5669, %r98, %r99, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5673, %r97, %r98, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5677, %r96, %r97, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5681, %r95, %r96, %r5688;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5685, %r7743, %r95, %r5688;
	// inline asm
	setp.eq.s32	%p116, %r111, 0;
	selp.b32	%r7744, 0, %r5621, %p116;
	selp.b32	%r7745, %r5621, %r5625, %p116;
	selp.b32	%r7746, %r5625, %r5629, %p116;
	selp.b32	%r106, %r5677, %r5681, %p116;
	selp.b32	%r105, %r5681, %r5685, %p116;
	selp.b32	%r110, %r5661, %r5665, %p116;
	selp.b32	%r109, %r5665, %r5669, %p116;
	selp.b32	%r108, %r5669, %r5673, %p116;
	selp.b32	%r107, %r5673, %r5677, %p116;
	selp.b32	%r7767, %r5645, %r5649, %p116;
	selp.b32	%r7768, %r5649, %r5653, %p116;
	selp.b32	%r7769, %r5653, %r5657, %p116;
	selp.b32	%r7770, %r5657, %r5661, %p116;
	selp.b32	%r7771, %r5641, %r5645, %p116;
	selp.b32	%r7772, %r5637, %r5641, %p116;
	selp.b32	%r7773, %r5633, %r5637, %p116;
	selp.b32	%r7774, %r5629, %r5633, %p116;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r102, %r7743;
	mov.u32 	%r101, %r7743;
	mov.u32 	%r100, %r7743;
	mov.u32 	%r99, %r7743;
	mov.u32 	%r104, %r7743;
	mov.u32 	%r103, %r7743;
	bra.uni 	BB4_166;

BB4_133:
	setp.eq.s32	%p102, %r5200, 6;
	@%p102 bra 	BB4_158;
	bra.uni 	BB4_134;

BB4_158:
	and.b32  	%r6040, %r112, 3;
	shl.b32 	%r6024, %r6040, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r5957, %r110, %r7743, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5961, %r109, %r110, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5965, %r108, %r109, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5969, %r107, %r108, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5973, %r106, %r107, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5977, %r105, %r106, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5981, %r104, %r105, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5985, %r103, %r104, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5989, %r102, %r103, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5993, %r101, %r102, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5997, %r100, %r101, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6001, %r99, %r100, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6005, %r98, %r99, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6009, %r97, %r98, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6013, %r96, %r97, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6017, %r95, %r96, %r6024;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6021, %r7743, %r95, %r6024;
	// inline asm
	setp.eq.s32	%p120, %r111, 0;
	selp.b32	%r102, %r6013, %r6017, %p120;
	selp.b32	%r101, %r6017, %r6021, %p120;
	selp.b32	%r106, %r5997, %r6001, %p120;
	selp.b32	%r105, %r6001, %r6005, %p120;
	selp.b32	%r104, %r6005, %r6009, %p120;
	selp.b32	%r103, %r6009, %r6013, %p120;
	selp.b32	%r110, %r5981, %r5985, %p120;
	selp.b32	%r109, %r5985, %r5989, %p120;
	selp.b32	%r108, %r5989, %r5993, %p120;
	selp.b32	%r107, %r5993, %r5997, %p120;
	selp.b32	%r7767, %r5965, %r5969, %p120;
	selp.b32	%r7768, %r5969, %r5973, %p120;
	selp.b32	%r7769, %r5973, %r5977, %p120;
	selp.b32	%r7770, %r5977, %r5981, %p120;
	selp.b32	%r7771, %r5961, %r5965, %p120;
	selp.b32	%r7772, %r5957, %r5961, %p120;
	selp.b32	%r7773, 0, %r5957, %p120;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r100, %r7743;
	mov.u32 	%r99, %r7743;
	bra.uni 	BB4_165;

BB4_148:
	setp.eq.s32	%p91, %r5200, 14;
	@%p91 bra 	BB4_152;
	bra.uni 	BB4_149;

BB4_152:
	and.b32  	%r5368, %r112, 3;
	shl.b32 	%r5352, %r5368, 3;
	mov.u32 	%r7747, 0;
	// inline asm
	shf.r.wrap.b32 %r5285, %r110, %r7747, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5289, %r109, %r110, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5293, %r108, %r109, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5297, %r107, %r108, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5301, %r106, %r107, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5305, %r105, %r106, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5309, %r104, %r105, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5313, %r103, %r104, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5317, %r102, %r103, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5321, %r101, %r102, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5325, %r100, %r101, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5329, %r99, %r100, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5333, %r98, %r99, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5337, %r97, %r98, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5341, %r96, %r97, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5345, %r95, %r96, %r5352;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5349, %r7747, %r95, %r5352;
	// inline asm
	setp.eq.s32	%p112, %r111, 0;
	selp.b32	%r7743, %r5293, %r5297, %p112;
	selp.b32	%r7744, %r5297, %r5301, %p112;
	selp.b32	%r7745, %r5301, %r5305, %p112;
	selp.b32	%r7746, %r5305, %r5309, %p112;
	selp.b32	%r7748, 0, %r5285, %p112;
	selp.b32	%r7749, %r5285, %r5289, %p112;
	selp.b32	%r7750, %r5289, %r5293, %p112;
	selp.b32	%r110, %r5341, %r5345, %p112;
	selp.b32	%r109, %r5345, %r5349, %p112;
	selp.b32	%r7767, %r5325, %r5329, %p112;
	selp.b32	%r7768, %r5329, %r5333, %p112;
	selp.b32	%r7769, %r5333, %r5337, %p112;
	selp.b32	%r7770, %r5337, %r5341, %p112;
	selp.b32	%r7771, %r5321, %r5325, %p112;
	selp.b32	%r7772, %r5317, %r5321, %p112;
	selp.b32	%r7773, %r5313, %r5317, %p112;
	selp.b32	%r7774, %r5309, %r5313, %p112;
	mov.u32 	%r7751, %r7747;
	mov.u32 	%r97, %r7747;
	mov.u32 	%r96, %r7747;
	mov.u32 	%r95, %r7747;
	mov.u32 	%r102, %r7747;
	mov.u32 	%r101, %r7747;
	mov.u32 	%r100, %r7747;
	mov.u32 	%r99, %r7747;
	mov.u32 	%r106, %r7747;
	mov.u32 	%r105, %r7747;
	mov.u32 	%r104, %r7747;
	mov.u32 	%r103, %r7747;
	mov.u32 	%r108, %r7747;
	mov.u32 	%r107, %r7747;
	bra.uni 	BB4_166;

BB4_124:
	setp.eq.s32	%p110, %r5200, 1;
	@%p110 bra 	BB4_125;
	bra.uni 	BB4_150;

BB4_125:
	and.b32  	%r6460, %r112, 3;
	shl.b32 	%r6444, %r6460, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6377, %r110, %r7743, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6381, %r109, %r110, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6385, %r108, %r109, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6389, %r107, %r108, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6393, %r106, %r107, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6397, %r105, %r106, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6401, %r104, %r105, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6405, %r103, %r104, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6409, %r102, %r103, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6413, %r101, %r102, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6417, %r100, %r101, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6421, %r99, %r100, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6425, %r98, %r99, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6429, %r97, %r98, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6433, %r96, %r97, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6437, %r95, %r96, %r6444;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6441, %r7743, %r95, %r6444;
	// inline asm
	setp.eq.s32	%p125, %r111, 0;
	selp.b32	%r7751, %r6429, %r6433, %p125;
	selp.b32	%r97, %r6433, %r6437, %p125;
	selp.b32	%r96, %r6437, %r6441, %p125;
	selp.b32	%r102, %r6413, %r6417, %p125;
	selp.b32	%r101, %r6417, %r6421, %p125;
	selp.b32	%r100, %r6421, %r6425, %p125;
	selp.b32	%r99, %r6425, %r6429, %p125;
	selp.b32	%r106, %r6397, %r6401, %p125;
	selp.b32	%r105, %r6401, %r6405, %p125;
	selp.b32	%r104, %r6405, %r6409, %p125;
	selp.b32	%r103, %r6409, %r6413, %p125;
	selp.b32	%r110, %r6381, %r6385, %p125;
	selp.b32	%r109, %r6385, %r6389, %p125;
	selp.b32	%r108, %r6389, %r6393, %p125;
	selp.b32	%r107, %r6393, %r6397, %p125;
	selp.b32	%r7769, 0, %r6377, %p125;
	selp.b32	%r7770, %r6377, %r6381, %p125;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r7767, %r7743;
	mov.u32 	%r7768, %r7743;
	bra.uni 	BB4_162;

BB4_139:
	setp.eq.s32	%p99, %r5200, 9;
	@%p99 bra 	BB4_140;
	bra.uni 	BB4_150;

BB4_140:
	and.b32  	%r5788, %r112, 3;
	shl.b32 	%r5772, %r5788, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r5705, %r110, %r7743, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5709, %r109, %r110, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5713, %r108, %r109, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5717, %r107, %r108, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5721, %r106, %r107, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5725, %r105, %r106, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5729, %r104, %r105, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5733, %r103, %r104, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5737, %r102, %r103, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5741, %r101, %r102, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5745, %r100, %r101, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5749, %r99, %r100, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5753, %r98, %r99, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5757, %r97, %r98, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5761, %r96, %r97, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5765, %r95, %r96, %r5772;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5769, %r7743, %r95, %r5772;
	// inline asm
	setp.eq.s32	%p117, %r111, 0;
	selp.b32	%r7745, 0, %r5705, %p117;
	selp.b32	%r7746, %r5705, %r5709, %p117;
	selp.b32	%r106, %r5757, %r5761, %p117;
	selp.b32	%r105, %r5761, %r5765, %p117;
	selp.b32	%r104, %r5765, %r5769, %p117;
	selp.b32	%r110, %r5741, %r5745, %p117;
	selp.b32	%r109, %r5745, %r5749, %p117;
	selp.b32	%r108, %r5749, %r5753, %p117;
	selp.b32	%r107, %r5753, %r5757, %p117;
	selp.b32	%r7767, %r5725, %r5729, %p117;
	selp.b32	%r7768, %r5729, %r5733, %p117;
	selp.b32	%r7769, %r5733, %r5737, %p117;
	selp.b32	%r7770, %r5737, %r5741, %p117;
	selp.b32	%r7771, %r5721, %r5725, %p117;
	selp.b32	%r7772, %r5717, %r5721, %p117;
	selp.b32	%r7773, %r5713, %r5717, %p117;
	selp.b32	%r7774, %r5709, %r5713, %p117;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r102, %r7743;
	mov.u32 	%r101, %r7743;
	mov.u32 	%r100, %r7743;
	mov.u32 	%r99, %r7743;
	mov.u32 	%r103, %r7743;
	bra.uni 	BB4_166;

BB4_131:
	setp.eq.s32	%p105, %r5200, 5;
	@%p105 bra 	BB4_132;
	bra.uni 	BB4_150;

BB4_132:
	and.b32  	%r6124, %r112, 3;
	shl.b32 	%r6108, %r6124, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6041, %r110, %r7743, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6045, %r109, %r110, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6049, %r108, %r109, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6053, %r107, %r108, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6057, %r106, %r107, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6061, %r105, %r106, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6065, %r104, %r105, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6069, %r103, %r104, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6073, %r102, %r103, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6077, %r101, %r102, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6081, %r100, %r101, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6085, %r99, %r100, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6089, %r98, %r99, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6093, %r97, %r98, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6097, %r96, %r97, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6101, %r95, %r96, %r6108;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6105, %r7743, %r95, %r6108;
	// inline asm
	setp.eq.s32	%p121, %r111, 0;
	selp.b32	%r102, %r6093, %r6097, %p121;
	selp.b32	%r101, %r6097, %r6101, %p121;
	selp.b32	%r100, %r6101, %r6105, %p121;
	selp.b32	%r106, %r6077, %r6081, %p121;
	selp.b32	%r105, %r6081, %r6085, %p121;
	selp.b32	%r104, %r6085, %r6089, %p121;
	selp.b32	%r103, %r6089, %r6093, %p121;
	selp.b32	%r110, %r6061, %r6065, %p121;
	selp.b32	%r109, %r6065, %r6069, %p121;
	selp.b32	%r108, %r6069, %r6073, %p121;
	selp.b32	%r107, %r6073, %r6077, %p121;
	selp.b32	%r7767, %r6045, %r6049, %p121;
	selp.b32	%r7768, %r6049, %r6053, %p121;
	selp.b32	%r7769, %r6053, %r6057, %p121;
	selp.b32	%r7770, %r6057, %r6061, %p121;
	selp.b32	%r7771, %r6041, %r6045, %p121;
	selp.b32	%r7772, 0, %r6041, %p121;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	mov.u32 	%r99, %r7743;
	bra.uni 	BB4_164;

BB4_146:
	setp.eq.s32	%p94, %r5200, 13;
	@%p94 bra 	BB4_147;
	bra.uni 	BB4_150;

BB4_147:
	and.b32  	%r5452, %r112, 3;
	shl.b32 	%r5436, %r5452, 3;
	mov.u32 	%r7747, 0;
	// inline asm
	shf.r.wrap.b32 %r5369, %r110, %r7747, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5373, %r109, %r110, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5377, %r108, %r109, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5381, %r107, %r108, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5385, %r106, %r107, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5389, %r105, %r106, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5393, %r104, %r105, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5397, %r103, %r104, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5401, %r102, %r103, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5405, %r101, %r102, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5409, %r100, %r101, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5413, %r99, %r100, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5417, %r98, %r99, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5421, %r97, %r98, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5425, %r96, %r97, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5429, %r95, %r96, %r5436;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5433, %r7747, %r95, %r5436;
	// inline asm
	setp.eq.s32	%p113, %r111, 0;
	selp.b32	%r7743, %r5373, %r5377, %p113;
	selp.b32	%r7744, %r5377, %r5381, %p113;
	selp.b32	%r7745, %r5381, %r5385, %p113;
	selp.b32	%r7746, %r5385, %r5389, %p113;
	selp.b32	%r7749, 0, %r5369, %p113;
	selp.b32	%r7750, %r5369, %r5373, %p113;
	selp.b32	%r110, %r5421, %r5425, %p113;
	selp.b32	%r109, %r5425, %r5429, %p113;
	selp.b32	%r108, %r5429, %r5433, %p113;
	selp.b32	%r7767, %r5405, %r5409, %p113;
	selp.b32	%r7768, %r5409, %r5413, %p113;
	selp.b32	%r7769, %r5413, %r5417, %p113;
	selp.b32	%r7770, %r5417, %r5421, %p113;
	selp.b32	%r7771, %r5401, %r5405, %p113;
	selp.b32	%r7772, %r5397, %r5401, %p113;
	selp.b32	%r7773, %r5393, %r5397, %p113;
	selp.b32	%r7774, %r5389, %r5393, %p113;
	mov.u32 	%r7748, %r7747;
	mov.u32 	%r7751, %r7747;
	mov.u32 	%r97, %r7747;
	mov.u32 	%r96, %r7747;
	mov.u32 	%r95, %r7747;
	mov.u32 	%r102, %r7747;
	mov.u32 	%r101, %r7747;
	mov.u32 	%r100, %r7747;
	mov.u32 	%r99, %r7747;
	mov.u32 	%r106, %r7747;
	mov.u32 	%r105, %r7747;
	mov.u32 	%r104, %r7747;
	mov.u32 	%r103, %r7747;
	mov.u32 	%r107, %r7747;
	bra.uni 	BB4_166;

BB4_127:
	setp.eq.s32	%p108, %r5200, 3;
	@%p108 bra 	BB4_128;
	bra.uni 	BB4_150;

BB4_128:
	and.b32  	%r6292, %r112, 3;
	shl.b32 	%r6276, %r6292, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r6209, %r110, %r7743, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6213, %r109, %r110, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6217, %r108, %r109, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6221, %r107, %r108, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6225, %r106, %r107, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6229, %r105, %r106, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6233, %r104, %r105, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6237, %r103, %r104, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6241, %r102, %r103, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6245, %r101, %r102, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6249, %r100, %r101, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6253, %r99, %r100, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6257, %r98, %r99, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6261, %r97, %r98, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6265, %r96, %r97, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6269, %r95, %r96, %r6276;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r6273, %r7743, %r95, %r6276;
	// inline asm
	setp.eq.s32	%p123, %r111, 0;
	selp.b32	%r7751, %r6269, %r6273, %p123;
	selp.b32	%r102, %r6253, %r6257, %p123;
	selp.b32	%r101, %r6257, %r6261, %p123;
	selp.b32	%r100, %r6261, %r6265, %p123;
	selp.b32	%r99, %r6265, %r6269, %p123;
	selp.b32	%r106, %r6237, %r6241, %p123;
	selp.b32	%r105, %r6241, %r6245, %p123;
	selp.b32	%r104, %r6245, %r6249, %p123;
	selp.b32	%r103, %r6249, %r6253, %p123;
	selp.b32	%r110, %r6221, %r6225, %p123;
	selp.b32	%r109, %r6225, %r6229, %p123;
	selp.b32	%r108, %r6229, %r6233, %p123;
	selp.b32	%r107, %r6233, %r6237, %p123;
	selp.b32	%r7767, 0, %r6209, %p123;
	selp.b32	%r7768, %r6209, %r6213, %p123;
	selp.b32	%r7769, %r6213, %r6217, %p123;
	selp.b32	%r7770, %r6217, %r6221, %p123;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;
	bra.uni 	BB4_162;

BB4_142:
	setp.eq.s32	%p97, %r5200, 11;
	@%p97 bra 	BB4_143;
	bra.uni 	BB4_150;

BB4_143:
	and.b32  	%r5620, %r112, 3;
	shl.b32 	%r5604, %r5620, 3;
	mov.u32 	%r7747, 0;
	// inline asm
	shf.r.wrap.b32 %r5537, %r110, %r7747, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5541, %r109, %r110, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5545, %r108, %r109, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5549, %r107, %r108, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5553, %r106, %r107, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5557, %r105, %r106, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5561, %r104, %r105, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5565, %r103, %r104, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5569, %r102, %r103, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5573, %r101, %r102, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5577, %r100, %r101, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5581, %r99, %r100, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5585, %r98, %r99, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5589, %r97, %r98, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5593, %r96, %r97, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5597, %r95, %r96, %r5604;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5601, %r7747, %r95, %r5604;
	// inline asm
	setp.eq.s32	%p115, %r111, 0;
	selp.b32	%r7743, 0, %r5537, %p115;
	selp.b32	%r7744, %r5537, %r5541, %p115;
	selp.b32	%r7745, %r5541, %r5545, %p115;
	selp.b32	%r7746, %r5545, %r5549, %p115;
	selp.b32	%r106, %r5597, %r5601, %p115;
	selp.b32	%r110, %r5581, %r5585, %p115;
	selp.b32	%r109, %r5585, %r5589, %p115;
	selp.b32	%r108, %r5589, %r5593, %p115;
	selp.b32	%r107, %r5593, %r5597, %p115;
	selp.b32	%r7767, %r5565, %r5569, %p115;
	selp.b32	%r7768, %r5569, %r5573, %p115;
	selp.b32	%r7769, %r5573, %r5577, %p115;
	selp.b32	%r7770, %r5577, %r5581, %p115;
	selp.b32	%r7771, %r5561, %r5565, %p115;
	selp.b32	%r7772, %r5557, %r5561, %p115;
	selp.b32	%r7773, %r5553, %r5557, %p115;
	selp.b32	%r7774, %r5549, %r5553, %p115;
	mov.u32 	%r7748, %r7747;
	mov.u32 	%r7749, %r7747;
	mov.u32 	%r7750, %r7747;
	mov.u32 	%r7751, %r7747;
	mov.u32 	%r97, %r7747;
	mov.u32 	%r96, %r7747;
	mov.u32 	%r95, %r7747;
	mov.u32 	%r102, %r7747;
	mov.u32 	%r101, %r7747;
	mov.u32 	%r100, %r7747;
	mov.u32 	%r99, %r7747;

BB4_154:
	mov.u32 	%r105, %r7747;
	mov.u32 	%r104, %r7747;
	mov.u32 	%r103, %r7747;
	bra.uni 	BB4_166;

BB4_134:
	setp.eq.s32	%p103, %r5200, 7;
	@%p103 bra 	BB4_135;
	bra.uni 	BB4_150;

BB4_135:
	and.b32  	%r5956, %r112, 3;
	shl.b32 	%r5940, %r5956, 3;
	mov.u32 	%r7743, 0;
	// inline asm
	shf.r.wrap.b32 %r5873, %r110, %r7743, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5877, %r109, %r110, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5881, %r108, %r109, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5885, %r107, %r108, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5889, %r106, %r107, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5893, %r105, %r106, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5897, %r104, %r105, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5901, %r103, %r104, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5905, %r102, %r103, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5909, %r101, %r102, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5913, %r100, %r101, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5917, %r99, %r100, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5921, %r98, %r99, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5925, %r97, %r98, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5929, %r96, %r97, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5933, %r95, %r96, %r5940;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5937, %r7743, %r95, %r5940;
	// inline asm
	setp.eq.s32	%p119, %r111, 0;
	selp.b32	%r102, %r5933, %r5937, %p119;
	selp.b32	%r106, %r5917, %r5921, %p119;
	selp.b32	%r105, %r5921, %r5925, %p119;
	selp.b32	%r104, %r5925, %r5929, %p119;
	selp.b32	%r103, %r5929, %r5933, %p119;
	selp.b32	%r110, %r5901, %r5905, %p119;
	selp.b32	%r109, %r5905, %r5909, %p119;
	selp.b32	%r108, %r5909, %r5913, %p119;
	selp.b32	%r107, %r5913, %r5917, %p119;
	selp.b32	%r7767, %r5885, %r5889, %p119;
	selp.b32	%r7768, %r5889, %r5893, %p119;
	selp.b32	%r7769, %r5893, %r5897, %p119;
	selp.b32	%r7770, %r5897, %r5901, %p119;
	selp.b32	%r7771, %r5881, %r5885, %p119;
	selp.b32	%r7772, %r5877, %r5881, %p119;
	selp.b32	%r7773, %r5873, %r5877, %p119;
	selp.b32	%r7774, 0, %r5873, %p119;
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r7743;
	mov.u32 	%r97, %r7743;
	mov.u32 	%r96, %r7743;
	mov.u32 	%r95, %r7743;

BB4_157:
	mov.u32 	%r101, %r7743;
	mov.u32 	%r100, %r7743;
	mov.u32 	%r99, %r7743;
	bra.uni 	BB4_166;

BB4_149:
	setp.ne.s32	%p92, %r5200, 15;
	@%p92 bra 	BB4_150;

	and.b32  	%r5284, %r112, 3;
	shl.b32 	%r5268, %r5284, 3;
	mov.u32 	%r7751, 0;
	// inline asm
	shf.r.wrap.b32 %r5201, %r110, %r7751, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5205, %r109, %r110, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5209, %r108, %r109, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5213, %r107, %r108, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5217, %r106, %r107, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5221, %r105, %r106, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5225, %r104, %r105, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5229, %r103, %r104, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5233, %r102, %r103, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5237, %r101, %r102, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5241, %r100, %r101, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5245, %r99, %r100, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5249, %r98, %r99, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5253, %r97, %r98, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5257, %r96, %r97, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5261, %r95, %r96, %r5268;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r5265, %r7751, %r95, %r5268;
	// inline asm
	setp.eq.s32	%p111, %r111, 0;
	selp.b32	%r7743, %r5213, %r5217, %p111;
	selp.b32	%r7744, %r5217, %r5221, %p111;
	selp.b32	%r7745, %r5221, %r5225, %p111;
	selp.b32	%r7746, %r5225, %r5229, %p111;
	selp.b32	%r7747, 0, %r5201, %p111;
	selp.b32	%r7748, %r5201, %r5205, %p111;
	selp.b32	%r7749, %r5205, %r5209, %p111;
	selp.b32	%r7750, %r5209, %r5213, %p111;
	selp.b32	%r110, %r5261, %r5265, %p111;
	selp.b32	%r7767, %r5245, %r5249, %p111;
	selp.b32	%r7768, %r5249, %r5253, %p111;
	selp.b32	%r7769, %r5253, %r5257, %p111;
	selp.b32	%r7770, %r5257, %r5261, %p111;
	selp.b32	%r7771, %r5241, %r5245, %p111;
	selp.b32	%r7772, %r5237, %r5241, %p111;
	selp.b32	%r7773, %r5233, %r5237, %p111;
	selp.b32	%r7774, %r5229, %r5233, %p111;
	mov.u32 	%r97, %r7751;
	mov.u32 	%r96, %r7751;
	mov.u32 	%r95, %r7751;
	mov.u32 	%r102, %r7751;
	mov.u32 	%r101, %r7751;
	mov.u32 	%r100, %r7751;
	mov.u32 	%r99, %r7751;
	mov.u32 	%r106, %r7751;
	mov.u32 	%r105, %r7751;
	mov.u32 	%r104, %r7751;
	mov.u32 	%r103, %r7751;
	mov.u32 	%r109, %r7751;
	mov.u32 	%r108, %r7751;
	mov.u32 	%r107, %r7751;
	bra.uni 	BB4_166;

BB4_150:
	mov.u32 	%r7744, %r7743;
	mov.u32 	%r7745, %r7743;
	mov.u32 	%r7746, %r7743;
	mov.u32 	%r7747, %r7743;
	mov.u32 	%r7748, %r7743;
	mov.u32 	%r7749, %r7743;
	mov.u32 	%r7750, %r7743;
	mov.u32 	%r7751, %r98;
	mov.u32 	%r7767, %r7743;
	mov.u32 	%r7768, %r7743;
	mov.u32 	%r7769, %r7743;
	mov.u32 	%r7770, %r7743;

BB4_162:
	mov.u32 	%r7771, %r7743;

BB4_163:
	mov.u32 	%r7772, %r7743;

BB4_164:
	mov.u32 	%r7773, %r7743;

BB4_165:
	mov.u32 	%r7774, %r7743;
	bra.uni 	BB4_166;

BB4_10:
	sub.s32 	%r1625, %r71, %r7655;
	add.s32 	%r113, %r1625, %r7634;
	and.b32  	%r1626, %r7634, 63;
	add.s32 	%r1627, %r1625, %r1626;
	setp.lt.s32	%p6, %r1627, 64;
	bfe.u32 	%r114, %r7634, 2, 4;
	@%p6 bra 	BB4_58;
	bra.uni 	BB4_11;

BB4_58:
	shl.b32 	%r3492, %r112, 2;
	mov.u32 	%r3493, 1985229328;
	shr.u32 	%r3494, %r3493, %r3492;
	and.b32  	%r423, %r3494, 65535;
	setp.gt.s32	%p46, %r114, 7;
	@%p46 bra 	BB4_74;

	setp.gt.s32	%p58, %r114, 3;
	@%p58 bra 	BB4_67;

	setp.gt.s32	%p64, %r114, 1;
	@%p64 bra 	BB4_64;

	setp.eq.s32	%p67, %r114, 0;
	@%p67 bra 	BB4_109;
	bra.uni 	BB4_62;

BB4_109:
	// inline asm
	prmt.b32 %r110, %r109, %r110, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r108, %r109, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r107, %r108, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r106, %r107, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r105, %r106, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r96, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r4156, 0;
	// inline asm
	prmt.b32 %r7692, %r4156, %r95, %r423;
	// inline asm
	bra.uni 	BB4_110;

BB4_11:
	mov.u32 	%r7657, 0;
	setp.gt.s32	%p7, %r114, 7;
	@%p7 bra 	BB4_27;

	setp.gt.s32	%p19, %r114, 3;
	@%p19 bra 	BB4_20;

	setp.gt.s32	%p25, %r114, 1;
	@%p25 bra 	BB4_17;

	setp.eq.s32	%p28, %r114, 0;
	@%p28 bra 	BB4_52;
	bra.uni 	BB4_15;

BB4_52:
	and.b32  	%r2987, %r112, 3;
	shl.b32 	%r2971, %r2987, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2904, %r110, %r7657, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2908, %r109, %r110, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2912, %r108, %r109, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2916, %r107, %r108, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2920, %r106, %r107, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2924, %r105, %r106, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2928, %r104, %r105, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2932, %r103, %r104, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2936, %r102, %r103, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2940, %r101, %r102, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2944, %r100, %r101, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2948, %r99, %r100, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2952, %r98, %r99, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2956, %r97, %r98, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2960, %r96, %r97, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2964, %r95, %r96, %r2971;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2968, %r7657, %r95, %r2971;
	// inline asm
	setp.eq.s32	%p45, %r111, 0;
	selp.b32	%r7665, %r2952, %r2956, %p45;
	selp.b32	%r97, %r2956, %r2960, %p45;
	selp.b32	%r96, %r2960, %r2964, %p45;
	selp.b32	%r95, %r2964, %r2968, %p45;
	selp.b32	%r102, %r2936, %r2940, %p45;
	selp.b32	%r101, %r2940, %r2944, %p45;
	selp.b32	%r100, %r2944, %r2948, %p45;
	selp.b32	%r99, %r2948, %r2952, %p45;
	selp.b32	%r106, %r2920, %r2924, %p45;
	selp.b32	%r105, %r2924, %r2928, %p45;
	selp.b32	%r104, %r2928, %r2932, %p45;
	selp.b32	%r103, %r2932, %r2936, %p45;
	selp.b32	%r110, %r2904, %r2908, %p45;
	selp.b32	%r109, %r2908, %r2912, %p45;
	selp.b32	%r108, %r2912, %r2916, %p45;
	selp.b32	%r107, %r2916, %r2920, %p45;
	selp.b32	%r7684, 0, %r2904, %p45;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7681, %r7657;
	mov.u32 	%r7682, %r7657;
	mov.u32 	%r7683, %r7657;
	bra.uni 	BB4_53;

BB4_74:
	setp.gt.s32	%p47, %r114, 11;
	@%p47 bra 	BB4_82;

	setp.gt.s32	%p53, %r114, 9;
	@%p53 bra 	BB4_79;

	setp.eq.s32	%p56, %r114, 8;
	@%p56 bra 	BB4_99;
	bra.uni 	BB4_77;

BB4_99:
	// inline asm
	prmt.b32 %r110, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r103, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	bra.uni 	BB4_100;

BB4_27:
	setp.gt.s32	%p8, %r114, 11;
	@%p8 bra 	BB4_35;

	setp.gt.s32	%p14, %r114, 9;
	@%p14 bra 	BB4_32;

	setp.eq.s32	%p17, %r114, 8;
	@%p17 bra 	BB4_47;
	bra.uni 	BB4_30;

BB4_47:
	and.b32  	%r2315, %r112, 3;
	shl.b32 	%r2299, %r2315, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2232, %r110, %r7657, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2236, %r109, %r110, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2240, %r108, %r109, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2244, %r107, %r108, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2248, %r106, %r107, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2252, %r105, %r106, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2256, %r104, %r105, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2260, %r103, %r104, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2264, %r102, %r103, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2268, %r101, %r102, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2272, %r100, %r101, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2276, %r99, %r100, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2280, %r98, %r99, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2284, %r97, %r98, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2288, %r96, %r97, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2292, %r95, %r96, %r2299;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2296, %r7657, %r95, %r2299;
	// inline asm
	setp.eq.s32	%p37, %r111, 0;
	selp.b32	%r7660, 0, %r2232, %p37;
	selp.b32	%r106, %r2280, %r2284, %p37;
	selp.b32	%r105, %r2284, %r2288, %p37;
	selp.b32	%r104, %r2288, %r2292, %p37;
	selp.b32	%r103, %r2292, %r2296, %p37;
	selp.b32	%r110, %r2264, %r2268, %p37;
	selp.b32	%r109, %r2268, %r2272, %p37;
	selp.b32	%r108, %r2272, %r2276, %p37;
	selp.b32	%r107, %r2276, %r2280, %p37;
	selp.b32	%r7681, %r2248, %r2252, %p37;
	selp.b32	%r7682, %r2252, %r2256, %p37;
	selp.b32	%r7683, %r2256, %r2260, %p37;
	selp.b32	%r7684, %r2260, %r2264, %p37;
	selp.b32	%r7685, %r2244, %r2248, %p37;
	selp.b32	%r7686, %r2240, %r2244, %p37;
	selp.b32	%r7687, %r2236, %r2240, %p37;
	selp.b32	%r7688, %r2232, %r2236, %p37;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r102, %r7657;
	bra.uni 	BB4_48;

BB4_67:
	setp.gt.s32	%p59, %r114, 5;
	@%p59 bra 	BB4_71;

	setp.eq.s32	%p62, %r114, 4;
	@%p62 bra 	BB4_105;
	bra.uni 	BB4_69;

BB4_105:
	// inline asm
	prmt.b32 %r110, %r105, %r106, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r99, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	bra.uni 	BB4_110;

BB4_20:
	setp.gt.s32	%p20, %r114, 5;
	@%p20 bra 	BB4_24;

	setp.eq.s32	%p23, %r114, 4;
	@%p23 bra 	BB4_50;
	bra.uni 	BB4_22;

BB4_50:
	and.b32  	%r2651, %r112, 3;
	shl.b32 	%r2635, %r2651, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2568, %r110, %r7657, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2572, %r109, %r110, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2576, %r108, %r109, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2580, %r107, %r108, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2584, %r106, %r107, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2588, %r105, %r106, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2592, %r104, %r105, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2596, %r103, %r104, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2600, %r102, %r103, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2604, %r101, %r102, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2608, %r100, %r101, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2612, %r99, %r100, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2616, %r98, %r99, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2620, %r97, %r98, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2624, %r96, %r97, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2628, %r95, %r96, %r2635;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2632, %r7657, %r95, %r2635;
	// inline asm
	setp.eq.s32	%p41, %r111, 0;
	selp.b32	%r102, %r2616, %r2620, %p41;
	selp.b32	%r101, %r2620, %r2624, %p41;
	selp.b32	%r100, %r2624, %r2628, %p41;
	selp.b32	%r99, %r2628, %r2632, %p41;
	selp.b32	%r106, %r2600, %r2604, %p41;
	selp.b32	%r105, %r2604, %r2608, %p41;
	selp.b32	%r104, %r2608, %r2612, %p41;
	selp.b32	%r103, %r2612, %r2616, %p41;
	selp.b32	%r110, %r2584, %r2588, %p41;
	selp.b32	%r109, %r2588, %r2592, %p41;
	selp.b32	%r108, %r2592, %r2596, %p41;
	selp.b32	%r107, %r2596, %r2600, %p41;
	selp.b32	%r7681, %r2568, %r2572, %p41;
	selp.b32	%r7682, %r2572, %r2576, %p41;
	selp.b32	%r7683, %r2576, %r2580, %p41;
	selp.b32	%r7684, %r2580, %r2584, %p41;
	selp.b32	%r7685, 0, %r2568, %p41;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	bra.uni 	BB4_54;

BB4_82:
	setp.gt.s32	%p48, %r114, 13;
	@%p48 bra 	BB4_86;

	setp.eq.s32	%p51, %r114, 12;
	@%p51 bra 	BB4_93;
	bra.uni 	BB4_84;

BB4_93:
	// inline asm
	prmt.b32 %r110, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r107, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	mov.u32 	%r106, %r98;
	bra.uni 	BB4_94;

BB4_35:
	setp.gt.s32	%p9, %r114, 13;
	@%p9 bra 	BB4_39;

	setp.eq.s32	%p12, %r114, 12;
	@%p12 bra 	BB4_44;
	bra.uni 	BB4_37;

BB4_44:
	and.b32  	%r1979, %r112, 3;
	shl.b32 	%r1963, %r1979, 3;
	mov.u32 	%r7661, 0;
	// inline asm
	shf.r.wrap.b32 %r1896, %r110, %r7661, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1900, %r109, %r110, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1904, %r108, %r109, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1908, %r107, %r108, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1912, %r106, %r107, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1916, %r105, %r106, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1920, %r104, %r105, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1924, %r103, %r104, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1928, %r102, %r103, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1932, %r101, %r102, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1936, %r100, %r101, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1940, %r99, %r100, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1944, %r98, %r99, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1948, %r97, %r98, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1952, %r96, %r97, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1956, %r95, %r96, %r1963;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1960, %r7661, %r95, %r1963;
	// inline asm
	setp.eq.s32	%p33, %r111, 0;
	selp.b32	%r7657, %r1896, %r1900, %p33;
	selp.b32	%r7658, %r1900, %r1904, %p33;
	selp.b32	%r7659, %r1904, %r1908, %p33;
	selp.b32	%r7660, %r1908, %r1912, %p33;
	selp.b32	%r7664, 0, %r1896, %p33;
	selp.b32	%r110, %r1944, %r1948, %p33;
	selp.b32	%r109, %r1948, %r1952, %p33;
	selp.b32	%r108, %r1952, %r1956, %p33;
	selp.b32	%r107, %r1956, %r1960, %p33;
	selp.b32	%r7681, %r1928, %r1932, %p33;
	selp.b32	%r7682, %r1932, %r1936, %p33;
	selp.b32	%r7683, %r1936, %r1940, %p33;
	selp.b32	%r7684, %r1940, %r1944, %p33;
	selp.b32	%r7685, %r1924, %r1928, %p33;
	selp.b32	%r7686, %r1920, %r1924, %p33;
	selp.b32	%r7687, %r1916, %r1920, %p33;
	selp.b32	%r7688, %r1912, %r1916, %p33;
	mov.u32 	%r7662, %r7661;
	mov.u32 	%r7663, %r7661;
	mov.u32 	%r7665, %r7661;
	mov.u32 	%r97, %r7661;
	mov.u32 	%r96, %r7661;
	mov.u32 	%r95, %r7661;
	mov.u32 	%r102, %r7661;
	mov.u32 	%r101, %r7661;
	mov.u32 	%r100, %r7661;
	mov.u32 	%r99, %r7661;
	mov.u32 	%r106, %r7661;
	bra.uni 	BB4_45;

BB4_64:
	setp.eq.s32	%p65, %r114, 2;
	@%p65 bra 	BB4_107;
	bra.uni 	BB4_65;

BB4_107:
	// inline asm
	prmt.b32 %r110, %r107, %r108, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r106, %r107, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r105, %r106, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r96, 0;
	// inline asm
	prmt.b32 %r97, %r96, %r95, %r423;
	// inline asm
	mov.u32 	%r7692, %r96;
	bra.uni 	BB4_110;

BB4_17:
	setp.eq.s32	%p26, %r114, 2;
	@%p26 bra 	BB4_51;
	bra.uni 	BB4_18;

BB4_51:
	and.b32  	%r2819, %r112, 3;
	shl.b32 	%r2803, %r2819, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2736, %r110, %r7657, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2740, %r109, %r110, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2744, %r108, %r109, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2748, %r107, %r108, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2752, %r106, %r107, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2756, %r105, %r106, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2760, %r104, %r105, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2764, %r103, %r104, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2768, %r102, %r103, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2772, %r101, %r102, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2776, %r100, %r101, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2780, %r99, %r100, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2784, %r98, %r99, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2788, %r97, %r98, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2792, %r96, %r97, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2796, %r95, %r96, %r2803;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2800, %r7657, %r95, %r2803;
	// inline asm
	setp.eq.s32	%p43, %r111, 0;
	selp.b32	%r7665, %r2792, %r2796, %p43;
	selp.b32	%r97, %r2796, %r2800, %p43;
	selp.b32	%r102, %r2776, %r2780, %p43;
	selp.b32	%r101, %r2780, %r2784, %p43;
	selp.b32	%r100, %r2784, %r2788, %p43;
	selp.b32	%r99, %r2788, %r2792, %p43;
	selp.b32	%r106, %r2760, %r2764, %p43;
	selp.b32	%r105, %r2764, %r2768, %p43;
	selp.b32	%r104, %r2768, %r2772, %p43;
	selp.b32	%r103, %r2772, %r2776, %p43;
	selp.b32	%r110, %r2744, %r2748, %p43;
	selp.b32	%r109, %r2748, %r2752, %p43;
	selp.b32	%r108, %r2752, %r2756, %p43;
	selp.b32	%r107, %r2756, %r2760, %p43;
	selp.b32	%r7682, 0, %r2736, %p43;
	selp.b32	%r7683, %r2736, %r2740, %p43;
	selp.b32	%r7684, %r2740, %r2744, %p43;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r7681, %r7657;
	bra.uni 	BB4_53;

BB4_79:
	setp.eq.s32	%p54, %r114, 10;
	@%p54 bra 	BB4_97;
	bra.uni 	BB4_80;

BB4_97:
	// inline asm
	prmt.b32 %r110, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r105, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	bra.uni 	BB4_95;

BB4_32:
	setp.eq.s32	%p15, %r114, 10;
	@%p15 bra 	BB4_46;
	bra.uni 	BB4_33;

BB4_46:
	and.b32  	%r2147, %r112, 3;
	shl.b32 	%r2131, %r2147, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2064, %r110, %r7657, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2068, %r109, %r110, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2072, %r108, %r109, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2076, %r107, %r108, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2080, %r106, %r107, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2084, %r105, %r106, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2088, %r104, %r105, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2092, %r103, %r104, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2096, %r102, %r103, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2100, %r101, %r102, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2104, %r100, %r101, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2108, %r99, %r100, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2112, %r98, %r99, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2116, %r97, %r98, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2120, %r96, %r97, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2124, %r95, %r96, %r2131;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2128, %r7657, %r95, %r2131;
	// inline asm
	setp.eq.s32	%p35, %r111, 0;
	selp.b32	%r7658, 0, %r2064, %p35;
	selp.b32	%r7659, %r2064, %r2068, %p35;
	selp.b32	%r7660, %r2068, %r2072, %p35;
	selp.b32	%r106, %r2120, %r2124, %p35;
	selp.b32	%r105, %r2124, %r2128, %p35;
	selp.b32	%r110, %r2104, %r2108, %p35;
	selp.b32	%r109, %r2108, %r2112, %p35;
	selp.b32	%r108, %r2112, %r2116, %p35;
	selp.b32	%r107, %r2116, %r2120, %p35;
	selp.b32	%r7681, %r2088, %r2092, %p35;
	selp.b32	%r7682, %r2092, %r2096, %p35;
	selp.b32	%r7683, %r2096, %r2100, %p35;
	selp.b32	%r7684, %r2100, %r2104, %p35;
	selp.b32	%r7685, %r2084, %r2088, %p35;
	selp.b32	%r7686, %r2080, %r2084, %p35;
	selp.b32	%r7687, %r2076, %r2080, %p35;
	selp.b32	%r7688, %r2072, %r2076, %p35;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r102, %r7657;
	mov.u32 	%r101, %r7657;
	mov.u32 	%r100, %r7657;
	mov.u32 	%r99, %r7657;
	mov.u32 	%r104, %r7657;
	mov.u32 	%r103, %r7657;
	bra.uni 	BB4_57;

BB4_71:
	setp.eq.s32	%p60, %r114, 6;
	@%p60 bra 	BB4_103;
	bra.uni 	BB4_72;

BB4_103:
	// inline asm
	prmt.b32 %r110, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r101, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	bra.uni 	BB4_101;

BB4_24:
	setp.eq.s32	%p21, %r114, 6;
	@%p21 bra 	BB4_49;
	bra.uni 	BB4_25;

BB4_49:
	and.b32  	%r2483, %r112, 3;
	shl.b32 	%r2467, %r2483, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2400, %r110, %r7657, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2404, %r109, %r110, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2408, %r108, %r109, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2412, %r107, %r108, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2416, %r106, %r107, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2420, %r105, %r106, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2424, %r104, %r105, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2428, %r103, %r104, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2432, %r102, %r103, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2436, %r101, %r102, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2440, %r100, %r101, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2444, %r99, %r100, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2448, %r98, %r99, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2452, %r97, %r98, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2456, %r96, %r97, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2460, %r95, %r96, %r2467;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2464, %r7657, %r95, %r2467;
	// inline asm
	setp.eq.s32	%p39, %r111, 0;
	selp.b32	%r102, %r2456, %r2460, %p39;
	selp.b32	%r101, %r2460, %r2464, %p39;
	selp.b32	%r106, %r2440, %r2444, %p39;
	selp.b32	%r105, %r2444, %r2448, %p39;
	selp.b32	%r104, %r2448, %r2452, %p39;
	selp.b32	%r103, %r2452, %r2456, %p39;
	selp.b32	%r110, %r2424, %r2428, %p39;
	selp.b32	%r109, %r2428, %r2432, %p39;
	selp.b32	%r108, %r2432, %r2436, %p39;
	selp.b32	%r107, %r2436, %r2440, %p39;
	selp.b32	%r7681, %r2408, %r2412, %p39;
	selp.b32	%r7682, %r2412, %r2416, %p39;
	selp.b32	%r7683, %r2416, %r2420, %p39;
	selp.b32	%r7684, %r2420, %r2424, %p39;
	selp.b32	%r7685, %r2404, %r2408, %p39;
	selp.b32	%r7686, %r2400, %r2404, %p39;
	selp.b32	%r7687, 0, %r2400, %p39;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r100, %r7657;
	mov.u32 	%r99, %r7657;
	bra.uni 	BB4_56;

BB4_86:
	setp.eq.s32	%p49, %r114, 14;
	@%p49 bra 	BB4_91;
	bra.uni 	BB4_87;

BB4_91:
	// inline asm
	prmt.b32 %r110, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r109, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	mov.u32 	%r106, %r98;
	mov.u32 	%r105, %r98;
	mov.u32 	%r104, %r98;
	mov.u32 	%r103, %r98;
	bra.uni 	BB4_90;

BB4_39:
	setp.eq.s32	%p10, %r114, 14;
	@%p10 bra 	BB4_43;
	bra.uni 	BB4_40;

BB4_43:
	and.b32  	%r1811, %r112, 3;
	shl.b32 	%r1795, %r1811, 3;
	mov.u32 	%r7661, 0;
	// inline asm
	shf.r.wrap.b32 %r1728, %r110, %r7661, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1732, %r109, %r110, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1736, %r108, %r109, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1740, %r107, %r108, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1744, %r106, %r107, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1748, %r105, %r106, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1752, %r104, %r105, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1756, %r103, %r104, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1760, %r102, %r103, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1764, %r101, %r102, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1768, %r100, %r101, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1772, %r99, %r100, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1776, %r98, %r99, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1780, %r97, %r98, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1784, %r96, %r97, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1788, %r95, %r96, %r1795;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1792, %r7661, %r95, %r1795;
	// inline asm
	setp.eq.s32	%p31, %r111, 0;
	selp.b32	%r7657, %r1736, %r1740, %p31;
	selp.b32	%r7658, %r1740, %r1744, %p31;
	selp.b32	%r7659, %r1744, %r1748, %p31;
	selp.b32	%r7660, %r1748, %r1752, %p31;
	selp.b32	%r7662, 0, %r1728, %p31;
	selp.b32	%r7663, %r1728, %r1732, %p31;
	selp.b32	%r7664, %r1732, %r1736, %p31;
	selp.b32	%r110, %r1784, %r1788, %p31;
	selp.b32	%r109, %r1788, %r1792, %p31;
	selp.b32	%r7681, %r1768, %r1772, %p31;
	selp.b32	%r7682, %r1772, %r1776, %p31;
	selp.b32	%r7683, %r1776, %r1780, %p31;
	selp.b32	%r7684, %r1780, %r1784, %p31;
	selp.b32	%r7685, %r1764, %r1768, %p31;
	selp.b32	%r7686, %r1760, %r1764, %p31;
	selp.b32	%r7687, %r1756, %r1760, %p31;
	selp.b32	%r7688, %r1752, %r1756, %p31;
	mov.u32 	%r7665, %r7661;
	mov.u32 	%r97, %r7661;
	mov.u32 	%r96, %r7661;
	mov.u32 	%r95, %r7661;
	mov.u32 	%r102, %r7661;
	mov.u32 	%r101, %r7661;
	mov.u32 	%r100, %r7661;
	mov.u32 	%r99, %r7661;
	mov.u32 	%r106, %r7661;
	mov.u32 	%r105, %r7661;
	mov.u32 	%r104, %r7661;
	mov.u32 	%r103, %r7661;
	mov.u32 	%r108, %r7661;
	mov.u32 	%r107, %r7661;
	bra.uni 	BB4_57;

BB4_62:
	setp.eq.s32	%p68, %r114, 1;
	@%p68 bra 	BB4_108;
	bra.uni 	BB4_63;

BB4_108:
	// inline asm
	prmt.b32 %r110, %r108, %r109, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r107, %r108, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r106, %r107, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r105, %r106, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r98, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r97, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r7692, 0;
	// inline asm
	prmt.b32 %r96, %r7692, %r95, %r423;
	// inline asm
	bra.uni 	BB4_110;

BB4_15:
	setp.eq.s32	%p29, %r114, 1;
	@%p29 bra 	BB4_16;
	bra.uni 	BB4_41;

BB4_16:
	and.b32  	%r2903, %r112, 3;
	shl.b32 	%r2887, %r2903, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2820, %r110, %r7657, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2824, %r109, %r110, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2828, %r108, %r109, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2832, %r107, %r108, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2836, %r106, %r107, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2840, %r105, %r106, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2844, %r104, %r105, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2848, %r103, %r104, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2852, %r102, %r103, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2856, %r101, %r102, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2860, %r100, %r101, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2864, %r99, %r100, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2868, %r98, %r99, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2872, %r97, %r98, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2876, %r96, %r97, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2880, %r95, %r96, %r2887;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2884, %r7657, %r95, %r2887;
	// inline asm
	setp.eq.s32	%p44, %r111, 0;
	selp.b32	%r7665, %r2872, %r2876, %p44;
	selp.b32	%r97, %r2876, %r2880, %p44;
	selp.b32	%r96, %r2880, %r2884, %p44;
	selp.b32	%r102, %r2856, %r2860, %p44;
	selp.b32	%r101, %r2860, %r2864, %p44;
	selp.b32	%r100, %r2864, %r2868, %p44;
	selp.b32	%r99, %r2868, %r2872, %p44;
	selp.b32	%r106, %r2840, %r2844, %p44;
	selp.b32	%r105, %r2844, %r2848, %p44;
	selp.b32	%r104, %r2848, %r2852, %p44;
	selp.b32	%r103, %r2852, %r2856, %p44;
	selp.b32	%r110, %r2824, %r2828, %p44;
	selp.b32	%r109, %r2828, %r2832, %p44;
	selp.b32	%r108, %r2832, %r2836, %p44;
	selp.b32	%r107, %r2836, %r2840, %p44;
	selp.b32	%r7683, 0, %r2820, %p44;
	selp.b32	%r7684, %r2820, %r2824, %p44;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r7681, %r7657;
	mov.u32 	%r7682, %r7657;
	bra.uni 	BB4_53;

BB4_77:
	setp.eq.s32	%p57, %r114, 9;
	@%p57 bra 	BB4_98;
	bra.uni 	BB4_78;

BB4_98:
	// inline asm
	prmt.b32 %r110, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r104, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	mov.u32 	%r103, %r98;
	bra.uni 	BB4_110;

BB4_30:
	setp.eq.s32	%p18, %r114, 9;
	@%p18 bra 	BB4_31;
	bra.uni 	BB4_41;

BB4_31:
	and.b32  	%r2231, %r112, 3;
	shl.b32 	%r2215, %r2231, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2148, %r110, %r7657, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2152, %r109, %r110, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2156, %r108, %r109, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2160, %r107, %r108, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2164, %r106, %r107, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2168, %r105, %r106, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2172, %r104, %r105, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2176, %r103, %r104, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2180, %r102, %r103, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2184, %r101, %r102, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2188, %r100, %r101, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2192, %r99, %r100, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2196, %r98, %r99, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2200, %r97, %r98, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2204, %r96, %r97, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2208, %r95, %r96, %r2215;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2212, %r7657, %r95, %r2215;
	// inline asm
	setp.eq.s32	%p36, %r111, 0;
	selp.b32	%r7659, 0, %r2148, %p36;
	selp.b32	%r7660, %r2148, %r2152, %p36;
	selp.b32	%r106, %r2200, %r2204, %p36;
	selp.b32	%r105, %r2204, %r2208, %p36;
	selp.b32	%r104, %r2208, %r2212, %p36;
	selp.b32	%r110, %r2184, %r2188, %p36;
	selp.b32	%r109, %r2188, %r2192, %p36;
	selp.b32	%r108, %r2192, %r2196, %p36;
	selp.b32	%r107, %r2196, %r2200, %p36;
	selp.b32	%r7681, %r2168, %r2172, %p36;
	selp.b32	%r7682, %r2172, %r2176, %p36;
	selp.b32	%r7683, %r2176, %r2180, %p36;
	selp.b32	%r7684, %r2180, %r2184, %p36;
	selp.b32	%r7685, %r2164, %r2168, %p36;
	selp.b32	%r7686, %r2160, %r2164, %p36;
	selp.b32	%r7687, %r2156, %r2160, %p36;
	selp.b32	%r7688, %r2152, %r2156, %p36;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r102, %r7657;
	mov.u32 	%r101, %r7657;
	mov.u32 	%r100, %r7657;
	mov.u32 	%r99, %r7657;
	mov.u32 	%r103, %r7657;
	bra.uni 	BB4_57;

BB4_69:
	setp.eq.s32	%p63, %r114, 5;
	@%p63 bra 	BB4_104;
	bra.uni 	BB4_70;

BB4_104:
	// inline asm
	prmt.b32 %r110, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r100, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r99, %r98;
	bra.uni 	BB4_110;

BB4_22:
	setp.eq.s32	%p24, %r114, 5;
	@%p24 bra 	BB4_23;
	bra.uni 	BB4_41;

BB4_23:
	and.b32  	%r2567, %r112, 3;
	shl.b32 	%r2551, %r2567, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2484, %r110, %r7657, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2488, %r109, %r110, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2492, %r108, %r109, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2496, %r107, %r108, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2500, %r106, %r107, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2504, %r105, %r106, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2508, %r104, %r105, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2512, %r103, %r104, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2516, %r102, %r103, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2520, %r101, %r102, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2524, %r100, %r101, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2528, %r99, %r100, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2532, %r98, %r99, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2536, %r97, %r98, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2540, %r96, %r97, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2544, %r95, %r96, %r2551;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2548, %r7657, %r95, %r2551;
	// inline asm
	setp.eq.s32	%p40, %r111, 0;
	selp.b32	%r102, %r2536, %r2540, %p40;
	selp.b32	%r101, %r2540, %r2544, %p40;
	selp.b32	%r100, %r2544, %r2548, %p40;
	selp.b32	%r106, %r2520, %r2524, %p40;
	selp.b32	%r105, %r2524, %r2528, %p40;
	selp.b32	%r104, %r2528, %r2532, %p40;
	selp.b32	%r103, %r2532, %r2536, %p40;
	selp.b32	%r110, %r2504, %r2508, %p40;
	selp.b32	%r109, %r2508, %r2512, %p40;
	selp.b32	%r108, %r2512, %r2516, %p40;
	selp.b32	%r107, %r2516, %r2520, %p40;
	selp.b32	%r7681, %r2488, %r2492, %p40;
	selp.b32	%r7682, %r2492, %r2496, %p40;
	selp.b32	%r7683, %r2496, %r2500, %p40;
	selp.b32	%r7684, %r2500, %r2504, %p40;
	selp.b32	%r7685, %r2484, %r2488, %p40;
	selp.b32	%r7686, 0, %r2484, %p40;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	mov.u32 	%r99, %r7657;
	bra.uni 	BB4_55;

BB4_84:
	setp.eq.s32	%p52, %r114, 13;
	@%p52 bra 	BB4_92;
	bra.uni 	BB4_85;

BB4_92:
	// inline asm
	prmt.b32 %r110, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r108, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	mov.u32 	%r106, %r98;
	mov.u32 	%r105, %r98;
	mov.u32 	%r104, %r98;
	mov.u32 	%r103, %r98;
	mov.u32 	%r107, %r98;
	bra.uni 	BB4_110;

BB4_37:
	setp.eq.s32	%p13, %r114, 13;
	@%p13 bra 	BB4_38;
	bra.uni 	BB4_41;

BB4_38:
	and.b32  	%r1895, %r112, 3;
	shl.b32 	%r1879, %r1895, 3;
	mov.u32 	%r7661, 0;
	// inline asm
	shf.r.wrap.b32 %r1812, %r110, %r7661, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1816, %r109, %r110, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1820, %r108, %r109, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1824, %r107, %r108, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1828, %r106, %r107, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1832, %r105, %r106, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1836, %r104, %r105, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1840, %r103, %r104, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1844, %r102, %r103, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1848, %r101, %r102, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1852, %r100, %r101, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1856, %r99, %r100, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1860, %r98, %r99, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1864, %r97, %r98, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1868, %r96, %r97, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1872, %r95, %r96, %r1879;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1876, %r7661, %r95, %r1879;
	// inline asm
	setp.eq.s32	%p32, %r111, 0;
	selp.b32	%r7657, %r1816, %r1820, %p32;
	selp.b32	%r7658, %r1820, %r1824, %p32;
	selp.b32	%r7659, %r1824, %r1828, %p32;
	selp.b32	%r7660, %r1828, %r1832, %p32;
	selp.b32	%r7663, 0, %r1812, %p32;
	selp.b32	%r7664, %r1812, %r1816, %p32;
	selp.b32	%r110, %r1864, %r1868, %p32;
	selp.b32	%r109, %r1868, %r1872, %p32;
	selp.b32	%r108, %r1872, %r1876, %p32;
	selp.b32	%r7681, %r1848, %r1852, %p32;
	selp.b32	%r7682, %r1852, %r1856, %p32;
	selp.b32	%r7683, %r1856, %r1860, %p32;
	selp.b32	%r7684, %r1860, %r1864, %p32;
	selp.b32	%r7685, %r1844, %r1848, %p32;
	selp.b32	%r7686, %r1840, %r1844, %p32;
	selp.b32	%r7687, %r1836, %r1840, %p32;
	selp.b32	%r7688, %r1832, %r1836, %p32;
	mov.u32 	%r7662, %r7661;
	mov.u32 	%r7665, %r7661;
	mov.u32 	%r97, %r7661;
	mov.u32 	%r96, %r7661;
	mov.u32 	%r95, %r7661;
	mov.u32 	%r102, %r7661;
	mov.u32 	%r101, %r7661;
	mov.u32 	%r100, %r7661;
	mov.u32 	%r99, %r7661;
	mov.u32 	%r106, %r7661;
	mov.u32 	%r105, %r7661;
	mov.u32 	%r104, %r7661;
	mov.u32 	%r103, %r7661;
	mov.u32 	%r107, %r7661;
	bra.uni 	BB4_57;

BB4_65:
	setp.eq.s32	%p66, %r114, 3;
	@%p66 bra 	BB4_106;
	bra.uni 	BB4_66;

BB4_106:
	// inline asm
	prmt.b32 %r110, %r106, %r107, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r105, %r106, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r104, %r105, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r103, %r104, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r102, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r101, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r100, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r99, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r97, 0;
	// inline asm
	prmt.b32 %r98, %r97, %r95, %r423;
	// inline asm
	mov.u32 	%r96, %r97;
	mov.u32 	%r7692, %r97;
	bra.uni 	BB4_110;

BB4_18:
	setp.eq.s32	%p27, %r114, 3;
	@%p27 bra 	BB4_19;
	bra.uni 	BB4_41;

BB4_19:
	and.b32  	%r2735, %r112, 3;
	shl.b32 	%r2719, %r2735, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2652, %r110, %r7657, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2656, %r109, %r110, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2660, %r108, %r109, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2664, %r107, %r108, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2668, %r106, %r107, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2672, %r105, %r106, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2676, %r104, %r105, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2680, %r103, %r104, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2684, %r102, %r103, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2688, %r101, %r102, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2692, %r100, %r101, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2696, %r99, %r100, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2700, %r98, %r99, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2704, %r97, %r98, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2708, %r96, %r97, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2712, %r95, %r96, %r2719;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2716, %r7657, %r95, %r2719;
	// inline asm
	setp.eq.s32	%p42, %r111, 0;
	selp.b32	%r7665, %r2712, %r2716, %p42;
	selp.b32	%r102, %r2696, %r2700, %p42;
	selp.b32	%r101, %r2700, %r2704, %p42;
	selp.b32	%r100, %r2704, %r2708, %p42;
	selp.b32	%r99, %r2708, %r2712, %p42;
	selp.b32	%r106, %r2680, %r2684, %p42;
	selp.b32	%r105, %r2684, %r2688, %p42;
	selp.b32	%r104, %r2688, %r2692, %p42;
	selp.b32	%r103, %r2692, %r2696, %p42;
	selp.b32	%r110, %r2664, %r2668, %p42;
	selp.b32	%r109, %r2668, %r2672, %p42;
	selp.b32	%r108, %r2672, %r2676, %p42;
	selp.b32	%r107, %r2676, %r2680, %p42;
	selp.b32	%r7681, 0, %r2652, %p42;
	selp.b32	%r7682, %r2652, %r2656, %p42;
	selp.b32	%r7683, %r2656, %r2660, %p42;
	selp.b32	%r7684, %r2660, %r2664, %p42;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;
	bra.uni 	BB4_53;

BB4_80:
	setp.eq.s32	%p55, %r114, 11;
	@%p55 bra 	BB4_96;
	bra.uni 	BB4_81;

BB4_96:
	// inline asm
	prmt.b32 %r110, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r106, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;

BB4_94:
	mov.u32 	%r105, %r98;

BB4_95:
	mov.u32 	%r104, %r98;
	mov.u32 	%r103, %r98;
	bra.uni 	BB4_110;

BB4_33:
	setp.eq.s32	%p16, %r114, 11;
	@%p16 bra 	BB4_34;
	bra.uni 	BB4_41;

BB4_34:
	and.b32  	%r2063, %r112, 3;
	shl.b32 	%r2047, %r2063, 3;
	mov.u32 	%r7661, 0;
	// inline asm
	shf.r.wrap.b32 %r1980, %r110, %r7661, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1984, %r109, %r110, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1988, %r108, %r109, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1992, %r107, %r108, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1996, %r106, %r107, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2000, %r105, %r106, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2004, %r104, %r105, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2008, %r103, %r104, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2012, %r102, %r103, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2016, %r101, %r102, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2020, %r100, %r101, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2024, %r99, %r100, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2028, %r98, %r99, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2032, %r97, %r98, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2036, %r96, %r97, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2040, %r95, %r96, %r2047;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2044, %r7661, %r95, %r2047;
	// inline asm
	setp.eq.s32	%p34, %r111, 0;
	selp.b32	%r7657, 0, %r1980, %p34;
	selp.b32	%r7658, %r1980, %r1984, %p34;
	selp.b32	%r7659, %r1984, %r1988, %p34;
	selp.b32	%r7660, %r1988, %r1992, %p34;
	selp.b32	%r106, %r2040, %r2044, %p34;
	selp.b32	%r110, %r2024, %r2028, %p34;
	selp.b32	%r109, %r2028, %r2032, %p34;
	selp.b32	%r108, %r2032, %r2036, %p34;
	selp.b32	%r107, %r2036, %r2040, %p34;
	selp.b32	%r7681, %r2008, %r2012, %p34;
	selp.b32	%r7682, %r2012, %r2016, %p34;
	selp.b32	%r7683, %r2016, %r2020, %p34;
	selp.b32	%r7684, %r2020, %r2024, %p34;
	selp.b32	%r7685, %r2004, %r2008, %p34;
	selp.b32	%r7686, %r2000, %r2004, %p34;
	selp.b32	%r7687, %r1996, %r2000, %p34;
	selp.b32	%r7688, %r1992, %r1996, %p34;
	mov.u32 	%r7662, %r7661;
	mov.u32 	%r7663, %r7661;
	mov.u32 	%r7664, %r7661;
	mov.u32 	%r7665, %r7661;
	mov.u32 	%r97, %r7661;
	mov.u32 	%r96, %r7661;
	mov.u32 	%r95, %r7661;
	mov.u32 	%r102, %r7661;
	mov.u32 	%r101, %r7661;
	mov.u32 	%r100, %r7661;
	mov.u32 	%r99, %r7661;

BB4_45:
	mov.u32 	%r105, %r7661;
	mov.u32 	%r104, %r7661;
	mov.u32 	%r103, %r7661;
	bra.uni 	BB4_57;

BB4_72:
	setp.eq.s32	%p61, %r114, 7;
	@%p61 bra 	BB4_102;
	bra.uni 	BB4_73;

BB4_102:
	// inline asm
	prmt.b32 %r110, %r102, %r103, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r109, %r101, %r102, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r108, %r100, %r101, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r107, %r99, %r100, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r106, %r98, %r99, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r105, %r97, %r98, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r104, %r96, %r97, %r423;
	// inline asm
	// inline asm
	prmt.b32 %r103, %r95, %r96, %r423;
	// inline asm
	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r102, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;

BB4_100:
	mov.u32 	%r101, %r98;

BB4_101:
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	bra.uni 	BB4_110;

BB4_25:
	setp.eq.s32	%p22, %r114, 7;
	@%p22 bra 	BB4_26;
	bra.uni 	BB4_41;

BB4_26:
	and.b32  	%r2399, %r112, 3;
	shl.b32 	%r2383, %r2399, 3;
	mov.u32 	%r7657, 0;
	// inline asm
	shf.r.wrap.b32 %r2316, %r110, %r7657, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2320, %r109, %r110, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2324, %r108, %r109, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2328, %r107, %r108, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2332, %r106, %r107, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2336, %r105, %r106, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2340, %r104, %r105, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2344, %r103, %r104, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2348, %r102, %r103, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2352, %r101, %r102, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2356, %r100, %r101, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2360, %r99, %r100, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2364, %r98, %r99, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2368, %r97, %r98, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2372, %r96, %r97, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2376, %r95, %r96, %r2383;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r2380, %r7657, %r95, %r2383;
	// inline asm
	setp.eq.s32	%p38, %r111, 0;
	selp.b32	%r102, %r2376, %r2380, %p38;
	selp.b32	%r106, %r2360, %r2364, %p38;
	selp.b32	%r105, %r2364, %r2368, %p38;
	selp.b32	%r104, %r2368, %r2372, %p38;
	selp.b32	%r103, %r2372, %r2376, %p38;
	selp.b32	%r110, %r2344, %r2348, %p38;
	selp.b32	%r109, %r2348, %r2352, %p38;
	selp.b32	%r108, %r2352, %r2356, %p38;
	selp.b32	%r107, %r2356, %r2360, %p38;
	selp.b32	%r7681, %r2328, %r2332, %p38;
	selp.b32	%r7682, %r2332, %r2336, %p38;
	selp.b32	%r7683, %r2336, %r2340, %p38;
	selp.b32	%r7684, %r2340, %r2344, %p38;
	selp.b32	%r7685, %r2324, %r2328, %p38;
	selp.b32	%r7686, %r2320, %r2324, %p38;
	selp.b32	%r7687, %r2316, %r2320, %p38;
	selp.b32	%r7688, 0, %r2316, %p38;
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r7657;
	mov.u32 	%r97, %r7657;
	mov.u32 	%r96, %r7657;
	mov.u32 	%r95, %r7657;

BB4_48:
	mov.u32 	%r101, %r7657;
	mov.u32 	%r100, %r7657;
	mov.u32 	%r99, %r7657;
	bra.uni 	BB4_57;

BB4_87:
	setp.ne.s32	%p50, %r114, 15;
	@%p50 bra 	BB4_88;

	mov.u32 	%r98, 0;
	// inline asm
	prmt.b32 %r110, %r98, %r95, %r423;
	// inline asm
	mov.u32 	%r97, %r98;
	mov.u32 	%r96, %r98;
	mov.u32 	%r7692, %r98;
	mov.u32 	%r102, %r98;
	mov.u32 	%r101, %r98;
	mov.u32 	%r100, %r98;
	mov.u32 	%r99, %r98;
	mov.u32 	%r106, %r98;
	mov.u32 	%r105, %r98;
	mov.u32 	%r104, %r98;
	mov.u32 	%r103, %r98;
	mov.u32 	%r109, %r98;

BB4_90:
	mov.u32 	%r108, %r98;
	mov.u32 	%r107, %r98;
	bra.uni 	BB4_110;

BB4_40:
	setp.ne.s32	%p11, %r114, 15;
	@%p11 bra 	BB4_41;

	and.b32  	%r1727, %r112, 3;
	shl.b32 	%r1711, %r1727, 3;
	mov.u32 	%r7665, 0;
	// inline asm
	shf.r.wrap.b32 %r1644, %r110, %r7665, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1648, %r109, %r110, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1652, %r108, %r109, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1656, %r107, %r108, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1660, %r106, %r107, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1664, %r105, %r106, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1668, %r104, %r105, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1672, %r103, %r104, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1676, %r102, %r103, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1680, %r101, %r102, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1684, %r100, %r101, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1688, %r99, %r100, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1692, %r98, %r99, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1696, %r97, %r98, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1700, %r96, %r97, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1704, %r95, %r96, %r1711;
	// inline asm
	// inline asm
	shf.r.wrap.b32 %r1708, %r7665, %r95, %r1711;
	// inline asm
	setp.eq.s32	%p30, %r111, 0;
	selp.b32	%r7657, %r1656, %r1660, %p30;
	selp.b32	%r7658, %r1660, %r1664, %p30;
	selp.b32	%r7659, %r1664, %r1668, %p30;
	selp.b32	%r7660, %r1668, %r1672, %p30;
	selp.b32	%r7661, 0, %r1644, %p30;
	selp.b32	%r7662, %r1644, %r1648, %p30;
	selp.b32	%r7663, %r1648, %r1652, %p30;
	selp.b32	%r7664, %r1652, %r1656, %p30;
	selp.b32	%r110, %r1704, %r1708, %p30;
	selp.b32	%r7681, %r1688, %r1692, %p30;
	selp.b32	%r7682, %r1692, %r1696, %p30;
	selp.b32	%r7683, %r1696, %r1700, %p30;
	selp.b32	%r7684, %r1700, %r1704, %p30;
	selp.b32	%r7685, %r1684, %r1688, %p30;
	selp.b32	%r7686, %r1680, %r1684, %p30;
	selp.b32	%r7687, %r1676, %r1680, %p30;
	selp.b32	%r7688, %r1672, %r1676, %p30;
	mov.u32 	%r97, %r7665;
	mov.u32 	%r96, %r7665;
	mov.u32 	%r95, %r7665;
	mov.u32 	%r102, %r7665;
	mov.u32 	%r101, %r7665;
	mov.u32 	%r100, %r7665;
	mov.u32 	%r99, %r7665;
	mov.u32 	%r106, %r7665;
	mov.u32 	%r105, %r7665;
	mov.u32 	%r104, %r7665;
	mov.u32 	%r103, %r7665;
	mov.u32 	%r109, %r7665;
	mov.u32 	%r108, %r7665;
	mov.u32 	%r107, %r7665;
	bra.uni 	BB4_57;

BB4_41:
	mov.u32 	%r7658, %r7657;
	mov.u32 	%r7659, %r7657;
	mov.u32 	%r7660, %r7657;
	mov.u32 	%r7661, %r7657;
	mov.u32 	%r7662, %r7657;
	mov.u32 	%r7663, %r7657;
	mov.u32 	%r7664, %r7657;
	mov.u32 	%r7665, %r98;
	mov.u32 	%r7681, %r7657;
	mov.u32 	%r7682, %r7657;
	mov.u32 	%r7683, %r7657;
	mov.u32 	%r7684, %r7657;

BB4_53:
	mov.u32 	%r7685, %r7657;

BB4_54:
	mov.u32 	%r7686, %r7657;

BB4_55:
	mov.u32 	%r7687, %r7657;

BB4_56:
	mov.u32 	%r7688, %r7657;

BB4_57:
	xor.b32  	%r2988, %r90, %r89;
	and.b32  	%r2989, %r91, %r2988;
	xor.b32  	%r2990, %r2989, %r89;
	add.s32 	%r2991, %r92, %r2990;
	or.b32  	%r2992, %r95, %r88;
	add.s32 	%r2993, %r2991, %r2992;
	add.s32 	%r2994, %r2993, -680876936;
	shf.l.wrap.b32 	%r2995, %r2994, %r2994, 7;
	add.s32 	%r2996, %r2995, %r91;
	xor.b32  	%r2997, %r91, %r90;
	and.b32  	%r2998, %r2996, %r2997;
	xor.b32  	%r2999, %r2998, %r90;
	or.b32  	%r3000, %r96, %r87;
	add.s32 	%r3001, %r89, %r3000;
	add.s32 	%r3002, %r3001, %r2999;
	add.s32 	%r3003, %r3002, -389564586;
	shf.l.wrap.b32 	%r3004, %r3003, %r3003, 12;
	add.s32 	%r3005, %r3004, %r2996;
	xor.b32  	%r3006, %r2996, %r91;
	and.b32  	%r3007, %r3005, %r3006;
	xor.b32  	%r3008, %r3007, %r91;
	or.b32  	%r3009, %r97, %r86;
	add.s32 	%r3010, %r90, %r3009;
	add.s32 	%r3011, %r3010, %r3008;
	add.s32 	%r3012, %r3011, 606105819;
	shf.l.wrap.b32 	%r3013, %r3012, %r3012, 17;
	add.s32 	%r3014, %r3013, %r3005;
	xor.b32  	%r3015, %r3005, %r2996;
	and.b32  	%r3016, %r3014, %r3015;
	xor.b32  	%r3017, %r3016, %r2996;
	or.b32  	%r3018, %r7665, %r85;
	add.s32 	%r3019, %r91, %r3018;
	add.s32 	%r3020, %r3019, %r3017;
	add.s32 	%r3021, %r3020, -1044525330;
	shf.l.wrap.b32 	%r3022, %r3021, %r3021, 22;
	add.s32 	%r3023, %r3022, %r3014;
	xor.b32  	%r3024, %r3014, %r3005;
	and.b32  	%r3025, %r3023, %r3024;
	xor.b32  	%r3026, %r3025, %r3005;
	or.b32  	%r3027, %r99, %r84;
	add.s32 	%r3028, %r3027, %r2996;
	add.s32 	%r3029, %r3028, %r3026;
	add.s32 	%r3030, %r3029, -176418897;
	shf.l.wrap.b32 	%r3031, %r3030, %r3030, 7;
	add.s32 	%r3032, %r3031, %r3023;
	xor.b32  	%r3033, %r3023, %r3014;
	and.b32  	%r3034, %r3032, %r3033;
	xor.b32  	%r3035, %r3034, %r3014;
	or.b32  	%r3036, %r100, %r83;
	add.s32 	%r3037, %r3036, %r3005;
	add.s32 	%r3038, %r3037, %r3035;
	add.s32 	%r3039, %r3038, 1200080426;
	shf.l.wrap.b32 	%r3040, %r3039, %r3039, 12;
	add.s32 	%r3041, %r3040, %r3032;
	xor.b32  	%r3042, %r3032, %r3023;
	and.b32  	%r3043, %r3041, %r3042;
	xor.b32  	%r3044, %r3043, %r3023;
	or.b32  	%r3045, %r101, %r82;
	add.s32 	%r3046, %r3045, %r3014;
	add.s32 	%r3047, %r3046, %r3044;
	add.s32 	%r3048, %r3047, -1473231341;
	shf.l.wrap.b32 	%r3049, %r3048, %r3048, 17;
	add.s32 	%r3050, %r3049, %r3041;
	xor.b32  	%r3051, %r3041, %r3032;
	and.b32  	%r3052, %r3050, %r3051;
	xor.b32  	%r3053, %r3052, %r3032;
	or.b32  	%r3054, %r102, %r81;
	add.s32 	%r3055, %r3054, %r3023;
	add.s32 	%r3056, %r3055, %r3053;
	add.s32 	%r3057, %r3056, -45705983;
	shf.l.wrap.b32 	%r3058, %r3057, %r3057, 22;
	add.s32 	%r3059, %r3058, %r3050;
	xor.b32  	%r3060, %r3050, %r3041;
	and.b32  	%r3061, %r3059, %r3060;
	xor.b32  	%r3062, %r3061, %r3041;
	or.b32  	%r3063, %r103, %r80;
	add.s32 	%r3064, %r3063, %r3032;
	add.s32 	%r3065, %r3064, %r3062;
	add.s32 	%r3066, %r3065, 1770035416;
	shf.l.wrap.b32 	%r3067, %r3066, %r3066, 7;
	add.s32 	%r3068, %r3067, %r3059;
	xor.b32  	%r3069, %r3059, %r3050;
	and.b32  	%r3070, %r3068, %r3069;
	xor.b32  	%r3071, %r3070, %r3050;
	or.b32  	%r3072, %r104, %r79;
	add.s32 	%r3073, %r3072, %r3041;
	add.s32 	%r3074, %r3073, %r3071;
	add.s32 	%r3075, %r3074, -1958414417;
	shf.l.wrap.b32 	%r3076, %r3075, %r3075, 12;
	add.s32 	%r3077, %r3076, %r3068;
	xor.b32  	%r3078, %r3068, %r3059;
	and.b32  	%r3079, %r3077, %r3078;
	xor.b32  	%r3080, %r3079, %r3059;
	or.b32  	%r3081, %r105, %r78;
	add.s32 	%r3082, %r3081, %r3050;
	add.s32 	%r3083, %r3082, %r3080;
	add.s32 	%r3084, %r3083, -42063;
	shf.l.wrap.b32 	%r3085, %r3084, %r3084, 17;
	add.s32 	%r3086, %r3085, %r3077;
	xor.b32  	%r3087, %r3077, %r3068;
	and.b32  	%r3088, %r3086, %r3087;
	xor.b32  	%r3089, %r3088, %r3068;
	or.b32  	%r3090, %r106, %r77;
	add.s32 	%r3091, %r3090, %r3059;
	add.s32 	%r3092, %r3091, %r3089;
	add.s32 	%r3093, %r3092, -1990404162;
	shf.l.wrap.b32 	%r3094, %r3093, %r3093, 22;
	add.s32 	%r3095, %r3094, %r3086;
	xor.b32  	%r3096, %r3086, %r3077;
	and.b32  	%r3097, %r3095, %r3096;
	xor.b32  	%r3098, %r3097, %r3077;
	or.b32  	%r3099, %r107, %r76;
	add.s32 	%r3100, %r3099, %r3068;
	add.s32 	%r3101, %r3100, %r3098;
	add.s32 	%r3102, %r3101, 1804603682;
	shf.l.wrap.b32 	%r3103, %r3102, %r3102, 7;
	add.s32 	%r3104, %r3103, %r3095;
	xor.b32  	%r3105, %r3095, %r3086;
	and.b32  	%r3106, %r3104, %r3105;
	xor.b32  	%r3107, %r3106, %r3086;
	or.b32  	%r3108, %r108, %r75;
	add.s32 	%r3109, %r3108, %r3077;
	add.s32 	%r3110, %r3109, %r3107;
	add.s32 	%r3111, %r3110, -40341101;
	shf.l.wrap.b32 	%r3112, %r3111, %r3111, 12;
	add.s32 	%r3113, %r3112, %r3104;
	xor.b32  	%r3114, %r3104, %r3095;
	and.b32  	%r3115, %r3113, %r3114;
	xor.b32  	%r3116, %r3115, %r3095;
	or.b32  	%r3117, %r109, %r74;
	add.s32 	%r3118, %r3117, %r3086;
	add.s32 	%r3119, %r3118, %r3116;
	add.s32 	%r3120, %r3119, -1502002290;
	shf.l.wrap.b32 	%r3121, %r3120, %r3120, 17;
	add.s32 	%r3122, %r3121, %r3113;
	xor.b32  	%r3123, %r3113, %r3104;
	and.b32  	%r3124, %r3122, %r3123;
	xor.b32  	%r3125, %r3124, %r3104;
	or.b32  	%r3126, %r110, %r73;
	add.s32 	%r3127, %r3126, %r3095;
	add.s32 	%r3128, %r3127, %r3125;
	add.s32 	%r3129, %r3128, 1236535329;
	shf.l.wrap.b32 	%r3130, %r3129, %r3129, 22;
	add.s32 	%r3131, %r3130, %r3122;
	xor.b32  	%r3132, %r3131, %r3122;
	and.b32  	%r3133, %r3132, %r3113;
	xor.b32  	%r3134, %r3133, %r3122;
	add.s32 	%r3135, %r3000, %r3104;
	add.s32 	%r3136, %r3135, %r3134;
	add.s32 	%r3137, %r3136, -165796510;
	shf.l.wrap.b32 	%r3138, %r3137, %r3137, 5;
	add.s32 	%r3139, %r3138, %r3131;
	xor.b32  	%r3140, %r3139, %r3131;
	and.b32  	%r3141, %r3140, %r3122;
	xor.b32  	%r3142, %r3141, %r3131;
	add.s32 	%r3143, %r3045, %r3113;
	add.s32 	%r3144, %r3143, %r3142;
	add.s32 	%r3145, %r3144, -1069501632;
	shf.l.wrap.b32 	%r3146, %r3145, %r3145, 9;
	add.s32 	%r3147, %r3146, %r3139;
	xor.b32  	%r3148, %r3147, %r3139;
	and.b32  	%r3149, %r3148, %r3131;
	xor.b32  	%r3150, %r3149, %r3139;
	add.s32 	%r3151, %r3090, %r3122;
	add.s32 	%r3152, %r3151, %r3150;
	add.s32 	%r3153, %r3152, 643717713;
	shf.l.wrap.b32 	%r3154, %r3153, %r3153, 14;
	add.s32 	%r3155, %r3154, %r3147;
	xor.b32  	%r3156, %r3155, %r3147;
	and.b32  	%r3157, %r3156, %r3139;
	xor.b32  	%r3158, %r3157, %r3147;
	add.s32 	%r3159, %r2992, %r3131;
	add.s32 	%r3160, %r3159, %r3158;
	add.s32 	%r3161, %r3160, -373897302;
	shf.l.wrap.b32 	%r3162, %r3161, %r3161, 20;
	add.s32 	%r3163, %r3162, %r3155;
	xor.b32  	%r3164, %r3163, %r3155;
	and.b32  	%r3165, %r3164, %r3147;
	xor.b32  	%r3166, %r3165, %r3155;
	add.s32 	%r3167, %r3036, %r3139;
	add.s32 	%r3168, %r3167, %r3166;
	add.s32 	%r3169, %r3168, -701558691;
	shf.l.wrap.b32 	%r3170, %r3169, %r3169, 5;
	add.s32 	%r3171, %r3170, %r3163;
	xor.b32  	%r3172, %r3171, %r3163;
	and.b32  	%r3173, %r3172, %r3155;
	xor.b32  	%r3174, %r3173, %r3163;
	add.s32 	%r3175, %r3081, %r3147;
	add.s32 	%r3176, %r3175, %r3174;
	add.s32 	%r3177, %r3176, 38016083;
	shf.l.wrap.b32 	%r3178, %r3177, %r3177, 9;
	add.s32 	%r3179, %r3178, %r3171;
	xor.b32  	%r3180, %r3179, %r3171;
	and.b32  	%r3181, %r3180, %r3163;
	xor.b32  	%r3182, %r3181, %r3171;
	add.s32 	%r3183, %r3126, %r3155;
	add.s32 	%r3184, %r3183, %r3182;
	add.s32 	%r3185, %r3184, -660478335;
	shf.l.wrap.b32 	%r3186, %r3185, %r3185, 14;
	add.s32 	%r3187, %r3186, %r3179;
	xor.b32  	%r3188, %r3187, %r3179;
	and.b32  	%r3189, %r3188, %r3171;
	xor.b32  	%r3190, %r3189, %r3179;
	add.s32 	%r3191, %r3027, %r3163;
	add.s32 	%r3192, %r3191, %r3190;
	add.s32 	%r3193, %r3192, -405537848;
	shf.l.wrap.b32 	%r3194, %r3193, %r3193, 20;
	add.s32 	%r3195, %r3194, %r3187;
	xor.b32  	%r3196, %r3195, %r3187;
	and.b32  	%r3197, %r3196, %r3179;
	xor.b32  	%r3198, %r3197, %r3187;
	add.s32 	%r3199, %r3072, %r3171;
	add.s32 	%r3200, %r3199, %r3198;
	add.s32 	%r3201, %r3200, 568446438;
	shf.l.wrap.b32 	%r3202, %r3201, %r3201, 5;
	add.s32 	%r3203, %r3202, %r3195;
	xor.b32  	%r3204, %r3203, %r3195;
	and.b32  	%r3205, %r3204, %r3187;
	xor.b32  	%r3206, %r3205, %r3195;
	add.s32 	%r3207, %r3117, %r3179;
	add.s32 	%r3208, %r3207, %r3206;
	add.s32 	%r3209, %r3208, -1019803690;
	shf.l.wrap.b32 	%r3210, %r3209, %r3209, 9;
	add.s32 	%r3211, %r3210, %r3203;
	xor.b32  	%r3212, %r3211, %r3203;
	and.b32  	%r3213, %r3212, %r3195;
	xor.b32  	%r3214, %r3213, %r3203;
	add.s32 	%r3215, %r3018, %r3187;
	add.s32 	%r3216, %r3215, %r3214;
	add.s32 	%r3217, %r3216, -187363961;
	shf.l.wrap.b32 	%r3218, %r3217, %r3217, 14;
	add.s32 	%r3219, %r3218, %r3211;
	xor.b32  	%r3220, %r3219, %r3211;
	and.b32  	%r3221, %r3220, %r3203;
	xor.b32  	%r3222, %r3221, %r3211;
	add.s32 	%r3223, %r3063, %r3195;
	add.s32 	%r3224, %r3223, %r3222;
	add.s32 	%r3225, %r3224, 1163531501;
	shf.l.wrap.b32 	%r3226, %r3225, %r3225, 20;
	add.s32 	%r3227, %r3226, %r3219;
	xor.b32  	%r3228, %r3227, %r3219;
	and.b32  	%r3229, %r3228, %r3211;
	xor.b32  	%r3230, %r3229, %r3219;
	add.s32 	%r3231, %r3108, %r3203;
	add.s32 	%r3232, %r3231, %r3230;
	add.s32 	%r3233, %r3232, -1444681467;
	shf.l.wrap.b32 	%r3234, %r3233, %r3233, 5;
	add.s32 	%r3235, %r3234, %r3227;
	xor.b32  	%r3236, %r3235, %r3227;
	and.b32  	%r3237, %r3236, %r3219;
	xor.b32  	%r3238, %r3237, %r3227;
	add.s32 	%r3239, %r3009, %r3211;
	add.s32 	%r3240, %r3239, %r3238;
	add.s32 	%r3241, %r3240, -51403784;
	shf.l.wrap.b32 	%r3242, %r3241, %r3241, 9;
	add.s32 	%r3243, %r3242, %r3235;
	xor.b32  	%r3244, %r3243, %r3235;
	and.b32  	%r3245, %r3244, %r3227;
	xor.b32  	%r3246, %r3245, %r3235;
	add.s32 	%r3247, %r3054, %r3219;
	add.s32 	%r3248, %r3247, %r3246;
	add.s32 	%r3249, %r3248, 1735328473;
	shf.l.wrap.b32 	%r3250, %r3249, %r3249, 14;
	add.s32 	%r3251, %r3250, %r3243;
	xor.b32  	%r3252, %r3251, %r3243;
	and.b32  	%r3253, %r3252, %r3235;
	xor.b32  	%r3254, %r3253, %r3243;
	add.s32 	%r3255, %r3099, %r3227;
	add.s32 	%r3256, %r3255, %r3254;
	add.s32 	%r3257, %r3256, -1926607734;
	shf.l.wrap.b32 	%r3258, %r3257, %r3257, 20;
	add.s32 	%r3259, %r3258, %r3251;
	xor.b32  	%r3260, %r3259, %r3251;
	xor.b32  	%r3261, %r3260, %r3243;
	add.s32 	%r3262, %r3036, %r3235;
	add.s32 	%r3263, %r3262, %r3261;
	add.s32 	%r3264, %r3263, -378558;
	shf.l.wrap.b32 	%r3265, %r3264, %r3264, 4;
	add.s32 	%r3266, %r3265, %r3259;
	xor.b32  	%r3267, %r3266, %r3260;
	add.s32 	%r3268, %r3063, %r3243;
	add.s32 	%r3269, %r3268, %r3267;
	add.s32 	%r3270, %r3269, -2022574463;
	shf.l.wrap.b32 	%r3271, %r3270, %r3270, 11;
	add.s32 	%r3272, %r3271, %r3266;
	xor.b32  	%r3273, %r3272, %r3266;
	xor.b32  	%r3274, %r3273, %r3259;
	add.s32 	%r3275, %r3090, %r3251;
	add.s32 	%r3276, %r3275, %r3274;
	add.s32 	%r3277, %r3276, 1839030562;
	shf.l.wrap.b32 	%r3278, %r3277, %r3277, 16;
	add.s32 	%r3279, %r3278, %r3272;
	xor.b32  	%r3280, %r3279, %r3273;
	add.s32 	%r3281, %r3117, %r3259;
	add.s32 	%r3282, %r3281, %r3280;
	add.s32 	%r3283, %r3282, -35309556;
	shf.l.wrap.b32 	%r3284, %r3283, %r3283, 23;
	add.s32 	%r3285, %r3284, %r3279;
	xor.b32  	%r3286, %r3285, %r3279;
	xor.b32  	%r3287, %r3286, %r3272;
	add.s32 	%r3288, %r3000, %r3266;
	add.s32 	%r3289, %r3288, %r3287;
	add.s32 	%r3290, %r3289, -1530992060;
	shf.l.wrap.b32 	%r3291, %r3290, %r3290, 4;
	add.s32 	%r3292, %r3291, %r3285;
	xor.b32  	%r3293, %r3292, %r3286;
	add.s32 	%r3294, %r3027, %r3272;
	add.s32 	%r3295, %r3294, %r3293;
	add.s32 	%r3296, %r3295, 1272893353;
	shf.l.wrap.b32 	%r3297, %r3296, %r3296, 11;
	add.s32 	%r3298, %r3297, %r3292;
	xor.b32  	%r3299, %r3298, %r3292;
	xor.b32  	%r3300, %r3299, %r3285;
	add.s32 	%r3301, %r3054, %r3279;
	add.s32 	%r3302, %r3301, %r3300;
	add.s32 	%r3303, %r3302, -155497632;
	shf.l.wrap.b32 	%r3304, %r3303, %r3303, 16;
	add.s32 	%r3305, %r3304, %r3298;
	xor.b32  	%r3306, %r3305, %r3299;
	add.s32 	%r3307, %r3081, %r3285;
	add.s32 	%r3308, %r3307, %r3306;
	add.s32 	%r3309, %r3308, -1094730640;
	shf.l.wrap.b32 	%r3310, %r3309, %r3309, 23;
	add.s32 	%r3311, %r3310, %r3305;
	xor.b32  	%r3312, %r3311, %r3305;
	xor.b32  	%r3313, %r3312, %r3298;
	add.s32 	%r3314, %r3108, %r3292;
	add.s32 	%r3315, %r3314, %r3313;
	add.s32 	%r3316, %r3315, 681279174;
	shf.l.wrap.b32 	%r3317, %r3316, %r3316, 4;
	add.s32 	%r3318, %r3317, %r3311;
	xor.b32  	%r3319, %r3318, %r3312;
	add.s32 	%r3320, %r2992, %r3298;
	add.s32 	%r3321, %r3320, %r3319;
	add.s32 	%r3322, %r3321, -358537222;
	shf.l.wrap.b32 	%r3323, %r3322, %r3322, 11;
	add.s32 	%r3324, %r3323, %r3318;
	xor.b32  	%r3325, %r3324, %r3318;
	xor.b32  	%r3326, %r3325, %r3311;
	add.s32 	%r3327, %r3018, %r3305;
	add.s32 	%r3328, %r3327, %r3326;
	add.s32 	%r3329, %r3328, -722521979;
	shf.l.wrap.b32 	%r3330, %r3329, %r3329, 16;
	add.s32 	%r3331, %r3330, %r3324;
	xor.b32  	%r3332, %r3331, %r3325;
	add.s32 	%r3333, %r3045, %r3311;
	add.s32 	%r3334, %r3333, %r3332;
	add.s32 	%r3335, %r3334, 76029189;
	shf.l.wrap.b32 	%r3336, %r3335, %r3335, 23;
	add.s32 	%r3337, %r3336, %r3331;
	xor.b32  	%r3338, %r3337, %r3331;
	xor.b32  	%r3339, %r3338, %r3324;
	add.s32 	%r3340, %r3072, %r3318;
	add.s32 	%r3341, %r3340, %r3339;
	add.s32 	%r3342, %r3341, -640364487;
	shf.l.wrap.b32 	%r3343, %r3342, %r3342, 4;
	add.s32 	%r3344, %r3343, %r3337;
	xor.b32  	%r3345, %r3344, %r3338;
	add.s32 	%r3346, %r3099, %r3324;
	add.s32 	%r3347, %r3346, %r3345;
	add.s32 	%r3348, %r3347, -421815835;
	shf.l.wrap.b32 	%r3349, %r3348, %r3348, 11;
	add.s32 	%r3350, %r3349, %r3344;
	xor.b32  	%r3351, %r3350, %r3344;
	xor.b32  	%r3352, %r3351, %r3337;
	add.s32 	%r3353, %r3126, %r3331;
	add.s32 	%r3354, %r3353, %r3352;
	add.s32 	%r3355, %r3354, 530742520;
	shf.l.wrap.b32 	%r3356, %r3355, %r3355, 16;
	add.s32 	%r3357, %r3356, %r3350;
	xor.b32  	%r3358, %r3357, %r3351;
	add.s32 	%r3359, %r3009, %r3337;
	add.s32 	%r3360, %r3359, %r3358;
	add.s32 	%r3361, %r3360, -995338651;
	shf.l.wrap.b32 	%r3362, %r3361, %r3361, 23;
	add.s32 	%r3363, %r3362, %r3357;
	not.b32 	%r3364, %r3350;
	or.b32  	%r3365, %r3363, %r3364;
	xor.b32  	%r3366, %r3365, %r3357;
	add.s32 	%r3367, %r2992, %r3344;
	add.s32 	%r3368, %r3367, %r3366;
	add.s32 	%r3369, %r3368, -198630844;
	shf.l.wrap.b32 	%r3370, %r3369, %r3369, 6;
	add.s32 	%r3371, %r3370, %r3363;
	not.b32 	%r3372, %r3357;
	or.b32  	%r3373, %r3371, %r3372;
	xor.b32  	%r3374, %r3373, %r3363;
	add.s32 	%r3375, %r3054, %r3350;
	add.s32 	%r3376, %r3375, %r3374;
	add.s32 	%r3377, %r3376, 1126891415;
	shf.l.wrap.b32 	%r3378, %r3377, %r3377, 10;
	add.s32 	%r3379, %r3378, %r3371;
	not.b32 	%r3380, %r3363;
	or.b32  	%r3381, %r3379, %r3380;
	xor.b32  	%r3382, %r3381, %r3371;
	add.s32 	%r3383, %r3117, %r3357;
	add.s32 	%r3384, %r3383, %r3382;
	add.s32 	%r3385, %r3384, -1416354905;
	shf.l.wrap.b32 	%r3386, %r3385, %r3385, 15;
	add.s32 	%r3387, %r3386, %r3379;
	not.b32 	%r3388, %r3371;
	or.b32  	%r3389, %r3387, %r3388;
	xor.b32  	%r3390, %r3389, %r3379;
	add.s32 	%r3391, %r3036, %r3363;
	add.s32 	%r3392, %r3391, %r3390;
	add.s32 	%r3393, %r3392, -57434055;
	shf.l.wrap.b32 	%r3394, %r3393, %r3393, 21;
	add.s32 	%r3395, %r3394, %r3387;
	not.b32 	%r3396, %r3379;
	or.b32  	%r3397, %r3395, %r3396;
	xor.b32  	%r3398, %r3397, %r3387;
	add.s32 	%r3399, %r3099, %r3371;
	add.s32 	%r3400, %r3399, %r3398;
	add.s32 	%r3401, %r3400, 1700485571;
	shf.l.wrap.b32 	%r3402, %r3401, %r3401, 6;
	add.s32 	%r3403, %r3402, %r3395;
	not.b32 	%r3404, %r3387;
	or.b32  	%r3405, %r3403, %r3404;
	xor.b32  	%r3406, %r3405, %r3395;
	add.s32 	%r3407, %r3018, %r3379;
	add.s32 	%r3408, %r3407, %r3406;
	add.s32 	%r3409, %r3408, -1894986606;
	shf.l.wrap.b32 	%r3410, %r3409, %r3409, 10;
	add.s32 	%r3411, %r3410, %r3403;
	not.b32 	%r3412, %r3395;
	or.b32  	%r3413, %r3411, %r3412;
	xor.b32  	%r3414, %r3413, %r3403;
	add.s32 	%r3415, %r3081, %r3387;
	add.s32 	%r3416, %r3415, %r3414;
	add.s32 	%r3417, %r3416, -1051523;
	shf.l.wrap.b32 	%r3418, %r3417, %r3417, 15;
	add.s32 	%r3419, %r3418, %r3411;
	not.b32 	%r3420, %r3403;
	or.b32  	%r3421, %r3419, %r3420;
	xor.b32  	%r3422, %r3421, %r3411;
	add.s32 	%r3423, %r3000, %r3395;
	add.s32 	%r3424, %r3423, %r3422;
	add.s32 	%r3425, %r3424, -2054922799;
	shf.l.wrap.b32 	%r3426, %r3425, %r3425, 21;
	add.s32 	%r3427, %r3426, %r3419;
	not.b32 	%r3428, %r3411;
	or.b32  	%r3429, %r3427, %r3428;
	xor.b32  	%r3430, %r3429, %r3419;
	add.s32 	%r3431, %r3063, %r3403;
	add.s32 	%r3432, %r3431, %r3430;
	add.s32 	%r3433, %r3432, 1873313359;
	shf.l.wrap.b32 	%r3434, %r3433, %r3433, 6;
	add.s32 	%r3435, %r3434, %r3427;
	not.b32 	%r3436, %r3419;
	or.b32  	%r3437, %r3435, %r3436;
	xor.b32  	%r3438, %r3437, %r3427;
	add.s32 	%r3439, %r3126, %r3411;
	add.s32 	%r3440, %r3439, %r3438;
	add.s32 	%r3441, %r3440, -30611744;
	shf.l.wrap.b32 	%r3442, %r3441, %r3441, 10;
	add.s32 	%r3443, %r3442, %r3435;
	not.b32 	%r3444, %r3427;
	or.b32  	%r3445, %r3443, %r3444;
	xor.b32  	%r3446, %r3445, %r3435;
	add.s32 	%r3447, %r3045, %r3419;
	add.s32 	%r3448, %r3447, %r3446;
	add.s32 	%r3449, %r3448, -1560198380;
	shf.l.wrap.b32 	%r3450, %r3449, %r3449, 15;
	add.s32 	%r3451, %r3450, %r3443;
	not.b32 	%r3452, %r3435;
	or.b32  	%r3453, %r3451, %r3452;
	xor.b32  	%r3454, %r3453, %r3443;
	add.s32 	%r3455, %r3108, %r3427;
	add.s32 	%r3456, %r3455, %r3454;
	add.s32 	%r3457, %r3456, 1309151649;
	shf.l.wrap.b32 	%r3458, %r3457, %r3457, 21;
	add.s32 	%r3459, %r3458, %r3451;
	not.b32 	%r3460, %r3443;
	or.b32  	%r3461, %r3459, %r3460;
	xor.b32  	%r3462, %r3461, %r3451;
	add.s32 	%r3463, %r3027, %r3435;
	add.s32 	%r3464, %r3463, %r3462;
	add.s32 	%r3465, %r3464, -145523070;
	shf.l.wrap.b32 	%r3466, %r3465, %r3465, 6;
	add.s32 	%r3467, %r3466, %r3459;
	not.b32 	%r3468, %r3451;
	or.b32  	%r3469, %r3467, %r3468;
	xor.b32  	%r3470, %r3469, %r3459;
	add.s32 	%r3471, %r3090, %r3443;
	add.s32 	%r3472, %r3471, %r3470;
	add.s32 	%r3473, %r3472, -1120210379;
	shf.l.wrap.b32 	%r3474, %r3473, %r3473, 10;
	add.s32 	%r3475, %r3474, %r3467;
	not.b32 	%r3476, %r3459;
	or.b32  	%r3477, %r3475, %r3476;
	xor.b32  	%r3478, %r3477, %r3467;
	add.s32 	%r3479, %r3009, %r3451;
	add.s32 	%r3480, %r3479, %r3478;
	add.s32 	%r3481, %r3480, 718787259;
	shf.l.wrap.b32 	%r3482, %r3481, %r3481, 15;
	add.s32 	%r3483, %r3482, %r3475;
	not.b32 	%r3484, %r3467;
	or.b32  	%r3485, %r3483, %r3484;
	xor.b32  	%r3486, %r3485, %r3475;
	add.s32 	%r3487, %r3072, %r3459;
	add.s32 	%r3488, %r3487, %r3486;
	add.s32 	%r3489, %r3488, -343485551;
	shf.l.wrap.b32 	%r3490, %r3489, %r3489, 21;
	add.s32 	%r92, %r3467, %r92;
	add.s32 	%r3491, %r3483, %r91;
	add.s32 	%r91, %r3491, %r3490;
	add.s32 	%r90, %r3483, %r90;
	add.s32 	%r89, %r3475, %r89;
	bra.uni 	BB4_111;

BB4_63:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_78:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_70:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_85:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_66:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_81:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_73:
	mov.u32 	%r7692, %r95;
	bra.uni 	BB4_110;

BB4_88:
	mov.u32 	%r7692, %r95;

BB4_110:
	or.b32  	%r7684, %r7692, %r88;
	or.b32  	%r7683, %r96, %r87;
	or.b32  	%r7682, %r97, %r86;
	or.b32  	%r7681, %r98, %r85;
	or.b32  	%r7685, %r99, %r84;
	or.b32  	%r7686, %r100, %r83;
	or.b32  	%r7687, %r101, %r82;
	or.b32  	%r7688, %r102, %r81;
	or.b32  	%r7660, %r103, %r80;
	or.b32  	%r7659, %r104, %r79;
	or.b32  	%r7658, %r105, %r78;
	or.b32  	%r7657, %r106, %r77;
	or.b32  	%r7664, %r107, %r76;
	or.b32  	%r7663, %r108, %r75;
	or.b32  	%r7662, %r109, %r74;
	or.b32  	%r7661, %r110, %r73;

BB4_111:
	bfe.u32 	%r4159, %r113, 2, 2;
	and.b32  	%r4160, %r113, 3;
	shl.b32 	%r4161, %r4160, 3;
	mov.u32 	%r4162, 255;
	shl.b32 	%r4163, %r4162, %r4161;
	setp.eq.s32	%p69, %r4159, 0;
	selp.b32	%r4164, %r4163, 0, %p69;
	setp.eq.s32	%p70, %r4159, 1;
	selp.b32	%r4165, %r4163, 0, %p70;
	setp.eq.s32	%p71, %r4159, 2;
	selp.b32	%r4166, %r4163, 0, %p71;
	setp.eq.s32	%p72, %r4159, 3;
	selp.b32	%r4167, %r4163, 0, %p72;
	and.b32  	%r4168, %r113, 63;
	bfe.u32 	%r4169, %r113, 4, 2;
	setp.eq.s32	%p73, %r4169, 0;
	selp.b32	%r4170, -2139062144, 0, %p73;
	and.b32  	%r4171, %r4164, %r4170;
	or.b32  	%r7738, %r7684, %r4171;
	and.b32  	%r4172, %r4165, %r4170;
	or.b32  	%r7737, %r7683, %r4172;
	and.b32  	%r4173, %r4166, %r4170;
	or.b32  	%r7736, %r7682, %r4173;
	and.b32  	%r4174, %r4167, %r4170;
	or.b32  	%r7735, %r7681, %r4174;
	setp.eq.s32	%p74, %r4169, 1;
	selp.b32	%r4175, -2139062144, 0, %p74;
	and.b32  	%r4176, %r4164, %r4175;
	or.b32  	%r7734, %r7685, %r4176;
	and.b32  	%r4177, %r4165, %r4175;
	or.b32  	%r7733, %r7686, %r4177;
	and.b32  	%r4178, %r4166, %r4175;
	or.b32  	%r7732, %r7687, %r4178;
	and.b32  	%r4179, %r4167, %r4175;
	or.b32  	%r7731, %r7688, %r4179;
	setp.eq.s32	%p75, %r4169, 2;
	selp.b32	%r4180, -2139062144, 0, %p75;
	and.b32  	%r4181, %r4164, %r4180;
	or.b32  	%r7730, %r7660, %r4181;
	and.b32  	%r4182, %r4165, %r4180;
	or.b32  	%r7729, %r7659, %r4182;
	and.b32  	%r4183, %r4166, %r4180;
	or.b32  	%r7728, %r7658, %r4183;
	and.b32  	%r4184, %r4167, %r4180;
	or.b32  	%r7727, %r7657, %r4184;
	setp.eq.s32	%p76, %r4169, 3;
	selp.b32	%r4185, -2139062144, 0, %p76;
	and.b32  	%r4186, %r4164, %r4185;
	or.b32  	%r7726, %r7664, %r4186;
	and.b32  	%r4187, %r4165, %r4185;
	or.b32  	%r7725, %r7663, %r4187;
	and.b32  	%r4188, %r4166, %r4185;
	or.b32  	%r626, %r7662, %r4188;
	and.b32  	%r4189, %r4167, %r4185;
	or.b32  	%r627, %r7661, %r4189;
	setp.lt.u32	%p77, %r4168, 56;
	@%p77 bra 	BB4_113;

	xor.b32  	%r4204, %r90, %r89;
	and.b32  	%r4205, %r91, %r4204;
	xor.b32  	%r4206, %r4205, %r89;
	add.s32 	%r4207, %r7738, %r92;
	add.s32 	%r4208, %r4207, %r4206;
	add.s32 	%r4209, %r4208, -680876936;
	shf.l.wrap.b32 	%r4210, %r4209, %r4209, 7;
	add.s32 	%r4211, %r4210, %r91;
	xor.b32  	%r4212, %r91, %r90;
	and.b32  	%r4213, %r4211, %r4212;
	xor.b32  	%r4214, %r4213, %r90;
	add.s32 	%r4215, %r7737, %r89;
	add.s32 	%r4216, %r4215, %r4214;
	add.s32 	%r4217, %r4216, -389564586;
	shf.l.wrap.b32 	%r4218, %r4217, %r4217, 12;
	add.s32 	%r4219, %r4218, %r4211;
	xor.b32  	%r4220, %r4211, %r91;
	and.b32  	%r4221, %r4219, %r4220;
	xor.b32  	%r4222, %r4221, %r91;
	add.s32 	%r4223, %r7736, %r90;
	add.s32 	%r4224, %r4223, %r4222;
	add.s32 	%r4225, %r4224, 606105819;
	shf.l.wrap.b32 	%r4226, %r4225, %r4225, 17;
	add.s32 	%r4227, %r4226, %r4219;
	xor.b32  	%r4228, %r4219, %r4211;
	and.b32  	%r4229, %r4227, %r4228;
	xor.b32  	%r4230, %r4229, %r4211;
	add.s32 	%r4231, %r7735, %r91;
	add.s32 	%r4232, %r4231, %r4230;
	add.s32 	%r4233, %r4232, -1044525330;
	shf.l.wrap.b32 	%r4234, %r4233, %r4233, 22;
	add.s32 	%r4235, %r4234, %r4227;
	xor.b32  	%r4236, %r4227, %r4219;
	and.b32  	%r4237, %r4235, %r4236;
	xor.b32  	%r4238, %r4237, %r4219;
	add.s32 	%r4239, %r7734, %r4211;
	add.s32 	%r4240, %r4239, %r4238;
	add.s32 	%r4241, %r4240, -176418897;
	shf.l.wrap.b32 	%r4242, %r4241, %r4241, 7;
	add.s32 	%r4243, %r4242, %r4235;
	xor.b32  	%r4244, %r4235, %r4227;
	and.b32  	%r4245, %r4243, %r4244;
	xor.b32  	%r4246, %r4245, %r4227;
	add.s32 	%r4247, %r7733, %r4219;
	add.s32 	%r4248, %r4247, %r4246;
	add.s32 	%r4249, %r4248, 1200080426;
	shf.l.wrap.b32 	%r4250, %r4249, %r4249, 12;
	add.s32 	%r4251, %r4250, %r4243;
	xor.b32  	%r4252, %r4243, %r4235;
	and.b32  	%r4253, %r4251, %r4252;
	xor.b32  	%r4254, %r4253, %r4235;
	add.s32 	%r4255, %r7732, %r4227;
	add.s32 	%r4256, %r4255, %r4254;
	add.s32 	%r4257, %r4256, -1473231341;
	shf.l.wrap.b32 	%r4258, %r4257, %r4257, 17;
	add.s32 	%r4259, %r4258, %r4251;
	xor.b32  	%r4260, %r4251, %r4243;
	and.b32  	%r4261, %r4259, %r4260;
	xor.b32  	%r4262, %r4261, %r4243;
	add.s32 	%r4263, %r7731, %r4235;
	add.s32 	%r4264, %r4263, %r4262;
	add.s32 	%r4265, %r4264, -45705983;
	shf.l.wrap.b32 	%r4266, %r4265, %r4265, 22;
	add.s32 	%r4267, %r4266, %r4259;
	xor.b32  	%r4268, %r4259, %r4251;
	and.b32  	%r4269, %r4267, %r4268;
	xor.b32  	%r4270, %r4269, %r4251;
	add.s32 	%r4271, %r7730, %r4243;
	add.s32 	%r4272, %r4271, %r4270;
	add.s32 	%r4273, %r4272, 1770035416;
	shf.l.wrap.b32 	%r4274, %r4273, %r4273, 7;
	add.s32 	%r4275, %r4274, %r4267;
	xor.b32  	%r4276, %r4267, %r4259;
	and.b32  	%r4277, %r4275, %r4276;
	xor.b32  	%r4278, %r4277, %r4259;
	add.s32 	%r4279, %r7729, %r4251;
	add.s32 	%r4280, %r4279, %r4278;
	add.s32 	%r4281, %r4280, -1958414417;
	shf.l.wrap.b32 	%r4282, %r4281, %r4281, 12;
	add.s32 	%r4283, %r4282, %r4275;
	xor.b32  	%r4284, %r4275, %r4267;
	and.b32  	%r4285, %r4283, %r4284;
	xor.b32  	%r4286, %r4285, %r4267;
	add.s32 	%r4287, %r7728, %r4259;
	add.s32 	%r4288, %r4287, %r4286;
	add.s32 	%r4289, %r4288, -42063;
	shf.l.wrap.b32 	%r4290, %r4289, %r4289, 17;
	add.s32 	%r4291, %r4290, %r4283;
	xor.b32  	%r4292, %r4283, %r4275;
	and.b32  	%r4293, %r4291, %r4292;
	xor.b32  	%r4294, %r4293, %r4275;
	add.s32 	%r4295, %r7727, %r4267;
	add.s32 	%r4296, %r4295, %r4294;
	add.s32 	%r4297, %r4296, -1990404162;
	shf.l.wrap.b32 	%r4298, %r4297, %r4297, 22;
	add.s32 	%r4299, %r4298, %r4291;
	xor.b32  	%r4300, %r4291, %r4283;
	and.b32  	%r4301, %r4299, %r4300;
	xor.b32  	%r4302, %r4301, %r4283;
	add.s32 	%r4303, %r7726, %r4275;
	add.s32 	%r4304, %r4303, %r4302;
	add.s32 	%r4305, %r4304, 1804603682;
	shf.l.wrap.b32 	%r4306, %r4305, %r4305, 7;
	add.s32 	%r4307, %r4306, %r4299;
	xor.b32  	%r4308, %r4299, %r4291;
	and.b32  	%r4309, %r4307, %r4308;
	xor.b32  	%r4310, %r4309, %r4291;
	add.s32 	%r4311, %r7725, %r4283;
	add.s32 	%r4312, %r4311, %r4310;
	add.s32 	%r4313, %r4312, -40341101;
	shf.l.wrap.b32 	%r4314, %r4313, %r4313, 12;
	add.s32 	%r4315, %r4314, %r4307;
	xor.b32  	%r4316, %r4307, %r4299;
	and.b32  	%r4317, %r4315, %r4316;
	xor.b32  	%r4318, %r4317, %r4299;
	add.s32 	%r4319, %r626, %r4291;
	add.s32 	%r4320, %r4319, %r4318;
	add.s32 	%r4321, %r4320, -1502002290;
	shf.l.wrap.b32 	%r4322, %r4321, %r4321, 17;
	add.s32 	%r4323, %r4322, %r4315;
	xor.b32  	%r4324, %r4315, %r4307;
	and.b32  	%r4325, %r4323, %r4324;
	xor.b32  	%r4326, %r4325, %r4307;
	add.s32 	%r4327, %r627, %r4299;
	add.s32 	%r4328, %r4327, %r4326;
	add.s32 	%r4329, %r4328, 1236535329;
	shf.l.wrap.b32 	%r4330, %r4329, %r4329, 22;
	add.s32 	%r4331, %r4330, %r4323;
	xor.b32  	%r4332, %r4331, %r4323;
	and.b32  	%r4333, %r4332, %r4315;
	xor.b32  	%r4334, %r4333, %r4323;
	add.s32 	%r4335, %r7737, %r4307;
	add.s32 	%r4336, %r4335, %r4334;
	add.s32 	%r4337, %r4336, -165796510;
	shf.l.wrap.b32 	%r4338, %r4337, %r4337, 5;
	add.s32 	%r4339, %r4338, %r4331;
	xor.b32  	%r4340, %r4339, %r4331;
	and.b32  	%r4341, %r4340, %r4323;
	xor.b32  	%r4342, %r4341, %r4331;
	add.s32 	%r4343, %r7732, %r4315;
	add.s32 	%r4344, %r4343, %r4342;
	add.s32 	%r4345, %r4344, -1069501632;
	shf.l.wrap.b32 	%r4346, %r4345, %r4345, 9;
	add.s32 	%r4347, %r4346, %r4339;
	xor.b32  	%r4348, %r4347, %r4339;
	and.b32  	%r4349, %r4348, %r4331;
	xor.b32  	%r4350, %r4349, %r4339;
	add.s32 	%r4351, %r7727, %r4323;
	add.s32 	%r4352, %r4351, %r4350;
	add.s32 	%r4353, %r4352, 643717713;
	shf.l.wrap.b32 	%r4354, %r4353, %r4353, 14;
	add.s32 	%r4355, %r4354, %r4347;
	xor.b32  	%r4356, %r4355, %r4347;
	and.b32  	%r4357, %r4356, %r4339;
	xor.b32  	%r4358, %r4357, %r4347;
	add.s32 	%r4359, %r7738, %r4331;
	add.s32 	%r4360, %r4359, %r4358;
	add.s32 	%r4361, %r4360, -373897302;
	shf.l.wrap.b32 	%r4362, %r4361, %r4361, 20;
	add.s32 	%r4363, %r4362, %r4355;
	xor.b32  	%r4364, %r4363, %r4355;
	and.b32  	%r4365, %r4364, %r4347;
	xor.b32  	%r4366, %r4365, %r4355;
	add.s32 	%r4367, %r7733, %r4339;
	add.s32 	%r4368, %r4367, %r4366;
	add.s32 	%r4369, %r4368, -701558691;
	shf.l.wrap.b32 	%r4370, %r4369, %r4369, 5;
	add.s32 	%r4371, %r4370, %r4363;
	xor.b32  	%r4372, %r4371, %r4363;
	and.b32  	%r4373, %r4372, %r4355;
	xor.b32  	%r4374, %r4373, %r4363;
	add.s32 	%r4375, %r7728, %r4347;
	add.s32 	%r4376, %r4375, %r4374;
	add.s32 	%r4377, %r4376, 38016083;
	shf.l.wrap.b32 	%r4378, %r4377, %r4377, 9;
	add.s32 	%r4379, %r4378, %r4371;
	xor.b32  	%r4380, %r4379, %r4371;
	and.b32  	%r4381, %r4380, %r4363;
	xor.b32  	%r4382, %r4381, %r4371;
	add.s32 	%r4383, %r627, %r4355;
	add.s32 	%r4384, %r4383, %r4382;
	add.s32 	%r4385, %r4384, -660478335;
	shf.l.wrap.b32 	%r4386, %r4385, %r4385, 14;
	add.s32 	%r4387, %r4386, %r4379;
	xor.b32  	%r4388, %r4387, %r4379;
	and.b32  	%r4389, %r4388, %r4371;
	xor.b32  	%r4390, %r4389, %r4379;
	add.s32 	%r4391, %r7734, %r4363;
	add.s32 	%r4392, %r4391, %r4390;
	add.s32 	%r4393, %r4392, -405537848;
	shf.l.wrap.b32 	%r4394, %r4393, %r4393, 20;
	add.s32 	%r4395, %r4394, %r4387;
	xor.b32  	%r4396, %r4395, %r4387;
	and.b32  	%r4397, %r4396, %r4379;
	xor.b32  	%r4398, %r4397, %r4387;
	add.s32 	%r4399, %r7729, %r4371;
	add.s32 	%r4400, %r4399, %r4398;
	add.s32 	%r4401, %r4400, 568446438;
	shf.l.wrap.b32 	%r4402, %r4401, %r4401, 5;
	add.s32 	%r4403, %r4402, %r4395;
	xor.b32  	%r4404, %r4403, %r4395;
	and.b32  	%r4405, %r4404, %r4387;
	xor.b32  	%r4406, %r4405, %r4395;
	add.s32 	%r4407, %r626, %r4379;
	add.s32 	%r4408, %r4407, %r4406;
	add.s32 	%r4409, %r4408, -1019803690;
	shf.l.wrap.b32 	%r4410, %r4409, %r4409, 9;
	add.s32 	%r4411, %r4410, %r4403;
	xor.b32  	%r4412, %r4411, %r4403;
	and.b32  	%r4413, %r4412, %r4395;
	xor.b32  	%r4414, %r4413, %r4403;
	add.s32 	%r4415, %r7735, %r4387;
	add.s32 	%r4416, %r4415, %r4414;
	add.s32 	%r4417, %r4416, -187363961;
	shf.l.wrap.b32 	%r4418, %r4417, %r4417, 14;
	add.s32 	%r4419, %r4418, %r4411;
	xor.b32  	%r4420, %r4419, %r4411;
	and.b32  	%r4421, %r4420, %r4403;
	xor.b32  	%r4422, %r4421, %r4411;
	add.s32 	%r4423, %r7730, %r4395;
	add.s32 	%r4424, %r4423, %r4422;
	add.s32 	%r4425, %r4424, 1163531501;
	shf.l.wrap.b32 	%r4426, %r4425, %r4425, 20;
	add.s32 	%r4427, %r4426, %r4419;
	xor.b32  	%r4428, %r4427, %r4419;
	and.b32  	%r4429, %r4428, %r4411;
	xor.b32  	%r4430, %r4429, %r4419;
	add.s32 	%r4431, %r7725, %r4403;
	add.s32 	%r4432, %r4431, %r4430;
	add.s32 	%r4433, %r4432, -1444681467;
	shf.l.wrap.b32 	%r4434, %r4433, %r4433, 5;
	add.s32 	%r4435, %r4434, %r4427;
	xor.b32  	%r4436, %r4435, %r4427;
	and.b32  	%r4437, %r4436, %r4419;
	xor.b32  	%r4438, %r4437, %r4427;
	add.s32 	%r4439, %r7736, %r4411;
	add.s32 	%r4440, %r4439, %r4438;
	add.s32 	%r4441, %r4440, -51403784;
	shf.l.wrap.b32 	%r4442, %r4441, %r4441, 9;
	add.s32 	%r4443, %r4442, %r4435;
	xor.b32  	%r4444, %r4443, %r4435;
	and.b32  	%r4445, %r4444, %r4427;
	xor.b32  	%r4446, %r4445, %r4435;
	add.s32 	%r4447, %r7731, %r4419;
	add.s32 	%r4448, %r4447, %r4446;
	add.s32 	%r4449, %r4448, 1735328473;
	shf.l.wrap.b32 	%r4450, %r4449, %r4449, 14;
	add.s32 	%r4451, %r4450, %r4443;
	xor.b32  	%r4452, %r4451, %r4443;
	and.b32  	%r4453, %r4452, %r4435;
	xor.b32  	%r4454, %r4453, %r4443;
	add.s32 	%r4455, %r7726, %r4427;
	add.s32 	%r4456, %r4455, %r4454;
	add.s32 	%r4457, %r4456, -1926607734;
	shf.l.wrap.b32 	%r4458, %r4457, %r4457, 20;
	add.s32 	%r4459, %r4458, %r4451;
	xor.b32  	%r4460, %r4459, %r4451;
	xor.b32  	%r4461, %r4460, %r4443;
	add.s32 	%r4462, %r7733, %r4435;
	add.s32 	%r4463, %r4462, %r4461;
	add.s32 	%r4464, %r4463, -378558;
	shf.l.wrap.b32 	%r4465, %r4464, %r4464, 4;
	add.s32 	%r4466, %r4465, %r4459;
	xor.b32  	%r4467, %r4466, %r4460;
	add.s32 	%r4468, %r7730, %r4443;
	add.s32 	%r4469, %r4468, %r4467;
	add.s32 	%r4470, %r4469, -2022574463;
	shf.l.wrap.b32 	%r4471, %r4470, %r4470, 11;
	add.s32 	%r4472, %r4471, %r4466;
	xor.b32  	%r4473, %r4472, %r4466;
	xor.b32  	%r4474, %r4473, %r4459;
	add.s32 	%r4475, %r7727, %r4451;
	add.s32 	%r4476, %r4475, %r4474;
	add.s32 	%r4477, %r4476, 1839030562;
	shf.l.wrap.b32 	%r4478, %r4477, %r4477, 16;
	add.s32 	%r4479, %r4478, %r4472;
	xor.b32  	%r4480, %r4479, %r4473;
	add.s32 	%r4481, %r626, %r4459;
	add.s32 	%r4482, %r4481, %r4480;
	add.s32 	%r4483, %r4482, -35309556;
	shf.l.wrap.b32 	%r4484, %r4483, %r4483, 23;
	add.s32 	%r4485, %r4484, %r4479;
	xor.b32  	%r4486, %r4485, %r4479;
	xor.b32  	%r4487, %r4486, %r4472;
	add.s32 	%r4488, %r7737, %r4466;
	add.s32 	%r4489, %r4488, %r4487;
	add.s32 	%r4490, %r4489, -1530992060;
	shf.l.wrap.b32 	%r4491, %r4490, %r4490, 4;
	add.s32 	%r4492, %r4491, %r4485;
	xor.b32  	%r4493, %r4492, %r4486;
	add.s32 	%r4494, %r7734, %r4472;
	add.s32 	%r4495, %r4494, %r4493;
	add.s32 	%r4496, %r4495, 1272893353;
	shf.l.wrap.b32 	%r4497, %r4496, %r4496, 11;
	add.s32 	%r4498, %r4497, %r4492;
	xor.b32  	%r4499, %r4498, %r4492;
	xor.b32  	%r4500, %r4499, %r4485;
	add.s32 	%r4501, %r7731, %r4479;
	add.s32 	%r4502, %r4501, %r4500;
	add.s32 	%r4503, %r4502, -155497632;
	shf.l.wrap.b32 	%r4504, %r4503, %r4503, 16;
	add.s32 	%r4505, %r4504, %r4498;
	xor.b32  	%r4506, %r4505, %r4499;
	add.s32 	%r4507, %r7728, %r4485;
	add.s32 	%r4508, %r4507, %r4506;
	add.s32 	%r4509, %r4508, -1094730640;
	shf.l.wrap.b32 	%r4510, %r4509, %r4509, 23;
	add.s32 	%r4511, %r4510, %r4505;
	xor.b32  	%r4512, %r4511, %r4505;
	xor.b32  	%r4513, %r4512, %r4498;
	add.s32 	%r4514, %r7725, %r4492;
	add.s32 	%r4515, %r4514, %r4513;
	add.s32 	%r4516, %r4515, 681279174;
	shf.l.wrap.b32 	%r4517, %r4516, %r4516, 4;
	add.s32 	%r4518, %r4517, %r4511;
	xor.b32  	%r4519, %r4518, %r4512;
	add.s32 	%r4520, %r7738, %r4498;
	add.s32 	%r4521, %r4520, %r4519;
	add.s32 	%r4522, %r4521, -358537222;
	shf.l.wrap.b32 	%r4523, %r4522, %r4522, 11;
	add.s32 	%r4524, %r4523, %r4518;
	xor.b32  	%r4525, %r4524, %r4518;
	xor.b32  	%r4526, %r4525, %r4511;
	add.s32 	%r4527, %r7735, %r4505;
	add.s32 	%r4528, %r4527, %r4526;
	add.s32 	%r4529, %r4528, -722521979;
	shf.l.wrap.b32 	%r4530, %r4529, %r4529, 16;
	add.s32 	%r4531, %r4530, %r4524;
	xor.b32  	%r4532, %r4531, %r4525;
	add.s32 	%r4533, %r7732, %r4511;
	add.s32 	%r4534, %r4533, %r4532;
	add.s32 	%r4535, %r4534, 76029189;
	shf.l.wrap.b32 	%r4536, %r4535, %r4535, 23;
	add.s32 	%r4537, %r4536, %r4531;
	xor.b32  	%r4538, %r4537, %r4531;
	xor.b32  	%r4539, %r4538, %r4524;
	add.s32 	%r4540, %r7729, %r4518;
	add.s32 	%r4541, %r4540, %r4539;
	add.s32 	%r4542, %r4541, -640364487;
	shf.l.wrap.b32 	%r4543, %r4542, %r4542, 4;
	add.s32 	%r4544, %r4543, %r4537;
	xor.b32  	%r4545, %r4544, %r4538;
	add.s32 	%r4546, %r7726, %r4524;
	add.s32 	%r4547, %r4546, %r4545;
	add.s32 	%r4548, %r4547, -421815835;
	shf.l.wrap.b32 	%r4549, %r4548, %r4548, 11;
	add.s32 	%r4550, %r4549, %r4544;
	xor.b32  	%r4551, %r4550, %r4544;
	xor.b32  	%r4552, %r4551, %r4537;
	add.s32 	%r4553, %r627, %r4531;
	add.s32 	%r4554, %r4553, %r4552;
	add.s32 	%r4555, %r4554, 530742520;
	shf.l.wrap.b32 	%r4556, %r4555, %r4555, 16;
	add.s32 	%r4557, %r4556, %r4550;
	xor.b32  	%r4558, %r4557, %r4551;
	add.s32 	%r4559, %r7736, %r4537;
	add.s32 	%r4560, %r4559, %r4558;
	add.s32 	%r4561, %r4560, -995338651;
	shf.l.wrap.b32 	%r4562, %r4561, %r4561, 23;
	add.s32 	%r4563, %r4562, %r4557;
	not.b32 	%r4564, %r4550;
	or.b32  	%r4565, %r4563, %r4564;
	xor.b32  	%r4566, %r4565, %r4557;
	add.s32 	%r4567, %r7738, %r4544;
	add.s32 	%r4568, %r4567, %r4566;
	add.s32 	%r4569, %r4568, -198630844;
	shf.l.wrap.b32 	%r4570, %r4569, %r4569, 6;
	add.s32 	%r4571, %r4570, %r4563;
	not.b32 	%r4572, %r4557;
	or.b32  	%r4573, %r4571, %r4572;
	xor.b32  	%r4574, %r4573, %r4563;
	add.s32 	%r4575, %r7731, %r4550;
	add.s32 	%r4576, %r4575, %r4574;
	add.s32 	%r4577, %r4576, 1126891415;
	shf.l.wrap.b32 	%r4578, %r4577, %r4577, 10;
	add.s32 	%r4579, %r4578, %r4571;
	not.b32 	%r4580, %r4563;
	or.b32  	%r4581, %r4579, %r4580;
	xor.b32  	%r4582, %r4581, %r4571;
	add.s32 	%r4583, %r626, %r4557;
	add.s32 	%r4584, %r4583, %r4582;
	add.s32 	%r4585, %r4584, -1416354905;
	shf.l.wrap.b32 	%r4586, %r4585, %r4585, 15;
	add.s32 	%r4587, %r4586, %r4579;
	not.b32 	%r4588, %r4571;
	or.b32  	%r4589, %r4587, %r4588;
	xor.b32  	%r4590, %r4589, %r4579;
	add.s32 	%r4591, %r7733, %r4563;
	add.s32 	%r4592, %r4591, %r4590;
	add.s32 	%r4593, %r4592, -57434055;
	shf.l.wrap.b32 	%r4594, %r4593, %r4593, 21;
	add.s32 	%r4595, %r4594, %r4587;
	not.b32 	%r4596, %r4579;
	or.b32  	%r4597, %r4595, %r4596;
	xor.b32  	%r4598, %r4597, %r4587;
	add.s32 	%r4599, %r7726, %r4571;
	add.s32 	%r4600, %r4599, %r4598;
	add.s32 	%r4601, %r4600, 1700485571;
	shf.l.wrap.b32 	%r4602, %r4601, %r4601, 6;
	add.s32 	%r4603, %r4602, %r4595;
	not.b32 	%r4604, %r4587;
	or.b32  	%r4605, %r4603, %r4604;
	xor.b32  	%r4606, %r4605, %r4595;
	add.s32 	%r4607, %r7735, %r4579;
	add.s32 	%r4608, %r4607, %r4606;
	add.s32 	%r4609, %r4608, -1894986606;
	shf.l.wrap.b32 	%r4610, %r4609, %r4609, 10;
	add.s32 	%r4611, %r4610, %r4603;
	not.b32 	%r4612, %r4595;
	or.b32  	%r4613, %r4611, %r4612;
	xor.b32  	%r4614, %r4613, %r4603;
	add.s32 	%r4615, %r7728, %r4587;
	add.s32 	%r4616, %r4615, %r4614;
	add.s32 	%r4617, %r4616, -1051523;
	shf.l.wrap.b32 	%r4618, %r4617, %r4617, 15;
	add.s32 	%r4619, %r4618, %r4611;
	not.b32 	%r4620, %r4603;
	or.b32  	%r4621, %r4619, %r4620;
	xor.b32  	%r4622, %r4621, %r4611;
	add.s32 	%r4623, %r7737, %r4595;
	add.s32 	%r4624, %r4623, %r4622;
	add.s32 	%r4625, %r4624, -2054922799;
	shf.l.wrap.b32 	%r4626, %r4625, %r4625, 21;
	add.s32 	%r4627, %r4626, %r4619;
	not.b32 	%r4628, %r4611;
	or.b32  	%r4629, %r4627, %r4628;
	xor.b32  	%r4630, %r4629, %r4619;
	add.s32 	%r4631, %r7730, %r4603;
	add.s32 	%r4632, %r4631, %r4630;
	add.s32 	%r4633, %r4632, 1873313359;
	shf.l.wrap.b32 	%r4634, %r4633, %r4633, 6;
	add.s32 	%r4635, %r4634, %r4627;
	not.b32 	%r4636, %r4619;
	or.b32  	%r4637, %r4635, %r4636;
	xor.b32  	%r4638, %r4637, %r4627;
	add.s32 	%r4639, %r627, %r4611;
	add.s32 	%r4640, %r4639, %r4638;
	add.s32 	%r4641, %r4640, -30611744;
	shf.l.wrap.b32 	%r4642, %r4641, %r4641, 10;
	add.s32 	%r4643, %r4642, %r4635;
	not.b32 	%r4644, %r4627;
	or.b32  	%r4645, %r4643, %r4644;
	xor.b32  	%r4646, %r4645, %r4635;
	add.s32 	%r4647, %r7732, %r4619;
	add.s32 	%r4648, %r4647, %r4646;
	add.s32 	%r4649, %r4648, -1560198380;
	shf.l.wrap.b32 	%r4650, %r4649, %r4649, 15;
	add.s32 	%r4651, %r4650, %r4643;
	not.b32 	%r4652, %r4635;
	or.b32  	%r4653, %r4651, %r4652;
	xor.b32  	%r4654, %r4653, %r4643;
	add.s32 	%r4655, %r7725, %r4627;
	add.s32 	%r4656, %r4655, %r4654;
	add.s32 	%r4657, %r4656, 1309151649;
	shf.l.wrap.b32 	%r4658, %r4657, %r4657, 21;
	add.s32 	%r4659, %r4658, %r4651;
	not.b32 	%r4660, %r4643;
	or.b32  	%r4661, %r4659, %r4660;
	xor.b32  	%r4662, %r4661, %r4651;
	add.s32 	%r4663, %r7734, %r4635;
	add.s32 	%r4664, %r4663, %r4662;
	add.s32 	%r4665, %r4664, -145523070;
	shf.l.wrap.b32 	%r4666, %r4665, %r4665, 6;
	add.s32 	%r4667, %r4666, %r4659;
	not.b32 	%r4668, %r4651;
	or.b32  	%r4669, %r4667, %r4668;
	xor.b32  	%r4670, %r4669, %r4659;
	add.s32 	%r4671, %r7727, %r4643;
	add.s32 	%r4672, %r4671, %r4670;
	add.s32 	%r4673, %r4672, -1120210379;
	shf.l.wrap.b32 	%r4674, %r4673, %r4673, 10;
	add.s32 	%r4675, %r4674, %r4667;
	not.b32 	%r4676, %r4659;
	or.b32  	%r4677, %r4675, %r4676;
	xor.b32  	%r4678, %r4677, %r4667;
	add.s32 	%r4679, %r7736, %r4651;
	add.s32 	%r4680, %r4679, %r4678;
	add.s32 	%r4681, %r4680, 718787259;
	shf.l.wrap.b32 	%r4682, %r4681, %r4681, 15;
	add.s32 	%r4683, %r4682, %r4675;
	not.b32 	%r4684, %r4667;
	or.b32  	%r4685, %r4683, %r4684;
	xor.b32  	%r4686, %r4685, %r4675;
	add.s32 	%r4687, %r7729, %r4659;
	add.s32 	%r4688, %r4687, %r4686;
	add.s32 	%r4689, %r4688, -343485551;
	shf.l.wrap.b32 	%r4690, %r4689, %r4689, 21;
	add.s32 	%r92, %r4667, %r92;
	add.s32 	%r4691, %r4683, %r91;
	add.s32 	%r91, %r4691, %r4690;
	add.s32 	%r90, %r4683, %r90;
	add.s32 	%r89, %r4675, %r89;
	mov.u32 	%r7725, 0;
	mov.u32 	%r7726, %r7725;
	mov.u32 	%r7727, %r7725;
	mov.u32 	%r7728, %r7725;
	mov.u32 	%r7729, %r7725;
	mov.u32 	%r7730, %r7725;
	mov.u32 	%r7731, %r7725;
	mov.u32 	%r7732, %r7725;
	mov.u32 	%r7733, %r7725;
	mov.u32 	%r7734, %r7725;
	mov.u32 	%r7735, %r7725;
	mov.u32 	%r7736, %r7725;
	mov.u32 	%r7737, %r7725;
	mov.u32 	%r7738, %r7725;

BB4_113:
	xor.b32  	%r4692, %r90, %r89;
	and.b32  	%r4693, %r91, %r4692;
	xor.b32  	%r4694, %r4693, %r89;
	add.s32 	%r4695, %r7738, %r92;
	add.s32 	%r4696, %r4695, %r4694;
	add.s32 	%r4697, %r4696, -680876936;
	shf.l.wrap.b32 	%r4698, %r4697, %r4697, 7;
	add.s32 	%r4699, %r4698, %r91;
	xor.b32  	%r4700, %r91, %r90;
	and.b32  	%r4701, %r4699, %r4700;
	xor.b32  	%r4702, %r4701, %r90;
	add.s32 	%r4703, %r7737, %r89;
	add.s32 	%r4704, %r4703, %r4702;
	add.s32 	%r4705, %r4704, -389564586;
	shf.l.wrap.b32 	%r4706, %r4705, %r4705, 12;
	add.s32 	%r4707, %r4706, %r4699;
	xor.b32  	%r4708, %r4699, %r91;
	and.b32  	%r4709, %r4707, %r4708;
	xor.b32  	%r4710, %r4709, %r91;
	add.s32 	%r4711, %r7736, %r90;
	add.s32 	%r4712, %r4711, %r4710;
	add.s32 	%r4713, %r4712, 606105819;
	shf.l.wrap.b32 	%r4714, %r4713, %r4713, 17;
	add.s32 	%r4715, %r4714, %r4707;
	xor.b32  	%r4716, %r4707, %r4699;
	and.b32  	%r4717, %r4715, %r4716;
	xor.b32  	%r4718, %r4717, %r4699;
	add.s32 	%r4719, %r7735, %r91;
	add.s32 	%r4720, %r4719, %r4718;
	add.s32 	%r4721, %r4720, -1044525330;
	shf.l.wrap.b32 	%r4722, %r4721, %r4721, 22;
	add.s32 	%r4723, %r4722, %r4715;
	xor.b32  	%r4724, %r4715, %r4707;
	and.b32  	%r4725, %r4723, %r4724;
	xor.b32  	%r4726, %r4725, %r4707;
	add.s32 	%r4727, %r7734, %r4699;
	add.s32 	%r4728, %r4727, %r4726;
	add.s32 	%r4729, %r4728, -176418897;
	shf.l.wrap.b32 	%r4730, %r4729, %r4729, 7;
	add.s32 	%r4731, %r4730, %r4723;
	xor.b32  	%r4732, %r4723, %r4715;
	and.b32  	%r4733, %r4731, %r4732;
	xor.b32  	%r4734, %r4733, %r4715;
	add.s32 	%r4735, %r7733, %r4707;
	add.s32 	%r4736, %r4735, %r4734;
	add.s32 	%r4737, %r4736, 1200080426;
	shf.l.wrap.b32 	%r4738, %r4737, %r4737, 12;
	add.s32 	%r4739, %r4738, %r4731;
	xor.b32  	%r4740, %r4731, %r4723;
	and.b32  	%r4741, %r4739, %r4740;
	xor.b32  	%r4742, %r4741, %r4723;
	add.s32 	%r4743, %r7732, %r4715;
	add.s32 	%r4744, %r4743, %r4742;
	add.s32 	%r4745, %r4744, -1473231341;
	shf.l.wrap.b32 	%r4746, %r4745, %r4745, 17;
	add.s32 	%r4747, %r4746, %r4739;
	xor.b32  	%r4748, %r4739, %r4731;
	and.b32  	%r4749, %r4747, %r4748;
	xor.b32  	%r4750, %r4749, %r4731;
	add.s32 	%r4751, %r7731, %r4723;
	add.s32 	%r4752, %r4751, %r4750;
	add.s32 	%r4753, %r4752, -45705983;
	shf.l.wrap.b32 	%r4754, %r4753, %r4753, 22;
	add.s32 	%r4755, %r4754, %r4747;
	xor.b32  	%r4756, %r4747, %r4739;
	and.b32  	%r4757, %r4755, %r4756;
	xor.b32  	%r4758, %r4757, %r4739;
	add.s32 	%r4759, %r7730, %r4731;
	add.s32 	%r4760, %r4759, %r4758;
	add.s32 	%r4761, %r4760, 1770035416;
	shf.l.wrap.b32 	%r4762, %r4761, %r4761, 7;
	add.s32 	%r4763, %r4762, %r4755;
	xor.b32  	%r4764, %r4755, %r4747;
	and.b32  	%r4765, %r4763, %r4764;
	xor.b32  	%r4766, %r4765, %r4747;
	add.s32 	%r4767, %r7729, %r4739;
	add.s32 	%r4768, %r4767, %r4766;
	add.s32 	%r4769, %r4768, -1958414417;
	shf.l.wrap.b32 	%r4770, %r4769, %r4769, 12;
	add.s32 	%r4771, %r4770, %r4763;
	xor.b32  	%r4772, %r4763, %r4755;
	and.b32  	%r4773, %r4771, %r4772;
	xor.b32  	%r4774, %r4773, %r4755;
	add.s32 	%r4775, %r7728, %r4747;
	add.s32 	%r4776, %r4775, %r4774;
	add.s32 	%r4777, %r4776, -42063;
	shf.l.wrap.b32 	%r4778, %r4777, %r4777, 17;
	add.s32 	%r4779, %r4778, %r4771;
	xor.b32  	%r4780, %r4771, %r4763;
	and.b32  	%r4781, %r4779, %r4780;
	xor.b32  	%r4782, %r4781, %r4763;
	add.s32 	%r4783, %r7727, %r4755;
	add.s32 	%r4784, %r4783, %r4782;
	add.s32 	%r4785, %r4784, -1990404162;
	shf.l.wrap.b32 	%r4786, %r4785, %r4785, 22;
	add.s32 	%r4787, %r4786, %r4779;
	xor.b32  	%r4788, %r4779, %r4771;
	and.b32  	%r4789, %r4787, %r4788;
	xor.b32  	%r4790, %r4789, %r4771;
	add.s32 	%r4791, %r7726, %r4763;
	add.s32 	%r4792, %r4791, %r4790;
	add.s32 	%r4793, %r4792, 1804603682;
	shf.l.wrap.b32 	%r4794, %r4793, %r4793, 7;
	add.s32 	%r4795, %r4794, %r4787;
	xor.b32  	%r4796, %r4787, %r4779;
	and.b32  	%r4797, %r4795, %r4796;
	xor.b32  	%r4798, %r4797, %r4779;
	add.s32 	%r4799, %r7725, %r4771;
	add.s32 	%r4800, %r4799, %r4798;
	add.s32 	%r4801, %r4800, -40341101;
	shf.l.wrap.b32 	%r4802, %r4801, %r4801, 12;
	add.s32 	%r4803, %r4802, %r4795;
	xor.b32  	%r4804, %r4795, %r4787;
	and.b32  	%r4805, %r4803, %r4804;
	xor.b32  	%r4806, %r4805, %r4787;
	shl.b32 	%r4807, %r113, 3;
	add.s32 	%r4808, %r4807, %r4779;
	add.s32 	%r4809, %r4808, %r4806;
	add.s32 	%r4810, %r4809, -1502002290;
	shf.l.wrap.b32 	%r4811, %r4810, %r4810, 17;
	add.s32 	%r4812, %r4811, %r4803;
	xor.b32  	%r4813, %r4803, %r4795;
	and.b32  	%r4814, %r4812, %r4813;
	xor.b32  	%r4815, %r4814, %r4795;
	add.s32 	%r4816, %r4787, %r4815;
	add.s32 	%r4817, %r4816, 1236535329;
	shf.l.wrap.b32 	%r4818, %r4817, %r4817, 22;
	add.s32 	%r4819, %r4818, %r4812;
	xor.b32  	%r4820, %r4819, %r4812;
	and.b32  	%r4821, %r4820, %r4803;
	xor.b32  	%r4822, %r4821, %r4812;
	add.s32 	%r4823, %r7737, %r4795;
	add.s32 	%r4824, %r4823, %r4822;
	add.s32 	%r4825, %r4824, -165796510;
	shf.l.wrap.b32 	%r4826, %r4825, %r4825, 5;
	add.s32 	%r4827, %r4826, %r4819;
	xor.b32  	%r4828, %r4827, %r4819;
	and.b32  	%r4829, %r4828, %r4812;
	xor.b32  	%r4830, %r4829, %r4819;
	add.s32 	%r4831, %r7732, %r4803;
	add.s32 	%r4832, %r4831, %r4830;
	add.s32 	%r4833, %r4832, -1069501632;
	shf.l.wrap.b32 	%r4834, %r4833, %r4833, 9;
	add.s32 	%r4835, %r4834, %r4827;
	xor.b32  	%r4836, %r4835, %r4827;
	and.b32  	%r4837, %r4836, %r4819;
	xor.b32  	%r4838, %r4837, %r4827;
	add.s32 	%r4839, %r7727, %r4812;
	add.s32 	%r4840, %r4839, %r4838;
	add.s32 	%r4841, %r4840, 643717713;
	shf.l.wrap.b32 	%r4842, %r4841, %r4841, 14;
	add.s32 	%r4843, %r4842, %r4835;
	xor.b32  	%r4844, %r4843, %r4835;
	and.b32  	%r4845, %r4844, %r4827;
	xor.b32  	%r4846, %r4845, %r4835;
	add.s32 	%r4847, %r7738, %r4819;
	add.s32 	%r4848, %r4847, %r4846;
	add.s32 	%r4849, %r4848, -373897302;
	shf.l.wrap.b32 	%r4850, %r4849, %r4849, 20;
	add.s32 	%r4851, %r4850, %r4843;
	xor.b32  	%r4852, %r4851, %r4843;
	and.b32  	%r4853, %r4852, %r4835;
	xor.b32  	%r4854, %r4853, %r4843;
	add.s32 	%r4855, %r7733, %r4827;
	add.s32 	%r4856, %r4855, %r4854;
	add.s32 	%r4857, %r4856, -701558691;
	shf.l.wrap.b32 	%r4858, %r4857, %r4857, 5;
	add.s32 	%r4859, %r4858, %r4851;
	xor.b32  	%r4860, %r4859, %r4851;
	and.b32  	%r4861, %r4860, %r4843;
	xor.b32  	%r4862, %r4861, %r4851;
	add.s32 	%r4863, %r7728, %r4835;
	add.s32 	%r4864, %r4863, %r4862;
	add.s32 	%r4865, %r4864, 38016083;
	shf.l.wrap.b32 	%r4866, %r4865, %r4865, 9;
	add.s32 	%r4867, %r4866, %r4859;
	xor.b32  	%r4868, %r4867, %r4859;
	and.b32  	%r4869, %r4868, %r4851;
	xor.b32  	%r4870, %r4869, %r4859;
	add.s32 	%r4871, %r4843, %r4870;
	add.s32 	%r4872, %r4871, -660478335;
	shf.l.wrap.b32 	%r4873, %r4872, %r4872, 14;
	add.s32 	%r4874, %r4873, %r4867;
	xor.b32  	%r4875, %r4874, %r4867;
	and.b32  	%r4876, %r4875, %r4859;
	xor.b32  	%r4877, %r4876, %r4867;
	add.s32 	%r4878, %r7734, %r4851;
	add.s32 	%r4879, %r4878, %r4877;
	add.s32 	%r4880, %r4879, -405537848;
	shf.l.wrap.b32 	%r4881, %r4880, %r4880, 20;
	add.s32 	%r4882, %r4881, %r4874;
	xor.b32  	%r4883, %r4882, %r4874;
	and.b32  	%r4884, %r4883, %r4867;
	xor.b32  	%r4885, %r4884, %r4874;
	add.s32 	%r4886, %r7729, %r4859;
	add.s32 	%r4887, %r4886, %r4885;
	add.s32 	%r4888, %r4887, 568446438;
	shf.l.wrap.b32 	%r4889, %r4888, %r4888, 5;
	add.s32 	%r4890, %r4889, %r4882;
	xor.b32  	%r4891, %r4890, %r4882;
	and.b32  	%r4892, %r4891, %r4874;
	xor.b32  	%r4893, %r4892, %r4882;
	add.s32 	%r4894, %r4807, %r4867;
	add.s32 	%r4895, %r4894, %r4893;
	add.s32 	%r4896, %r4895, -1019803690;
	shf.l.wrap.b32 	%r4897, %r4896, %r4896, 9;
	add.s32 	%r4898, %r4897, %r4890;
	xor.b32  	%r4899, %r4898, %r4890;
	and.b32  	%r4900, %r4899, %r4882;
	xor.b32  	%r4901, %r4900, %r4890;
	add.s32 	%r4902, %r7735, %r4874;
	add.s32 	%r4903, %r4902, %r4901;
	add.s32 	%r4904, %r4903, -187363961;
	shf.l.wrap.b32 	%r4905, %r4904, %r4904, 14;
	add.s32 	%r4906, %r4905, %r4898;
	xor.b32  	%r4907, %r4906, %r4898;
	and.b32  	%r4908, %r4907, %r4890;
	xor.b32  	%r4909, %r4908, %r4898;
	add.s32 	%r4910, %r7730, %r4882;
	add.s32 	%r4911, %r4910, %r4909;
	add.s32 	%r4912, %r4911, 1163531501;
	shf.l.wrap.b32 	%r4913, %r4912, %r4912, 20;
	add.s32 	%r4914, %r4913, %r4906;
	xor.b32  	%r4915, %r4914, %r4906;
	and.b32  	%r4916, %r4915, %r4898;
	xor.b32  	%r4917, %r4916, %r4906;
	add.s32 	%r4918, %r7725, %r4890;
	add.s32 	%r4919, %r4918, %r4917;
	add.s32 	%r4920, %r4919, -1444681467;
	shf.l.wrap.b32 	%r4921, %r4920, %r4920, 5;
	add.s32 	%r4922, %r4921, %r4914;
	xor.b32  	%r4923, %r4922, %r4914;
	and.b32  	%r4924, %r4923, %r4906;
	xor.b32  	%r4925, %r4924, %r4914;
	add.s32 	%r4926, %r7736, %r4898;
	add.s32 	%r4927, %r4926, %r4925;
	add.s32 	%r4928, %r4927, -51403784;
	shf.l.wrap.b32 	%r4929, %r4928, %r4928, 9;
	add.s32 	%r4930, %r4929, %r4922;
	xor.b32  	%r4931, %r4930, %r4922;
	and.b32  	%r4932, %r4931, %r4914;
	xor.b32  	%r4933, %r4932, %r4922;
	add.s32 	%r4934, %r7731, %r4906;
	add.s32 	%r4935, %r4934, %r4933;
	add.s32 	%r4936, %r4935, 1735328473;
	shf.l.wrap.b32 	%r4937, %r4936, %r4936, 14;
	add.s32 	%r4938, %r4937, %r4930;
	xor.b32  	%r4939, %r4938, %r4930;
	and.b32  	%r4940, %r4939, %r4922;
	xor.b32  	%r4941, %r4940, %r4930;
	add.s32 	%r4942, %r7726, %r4914;
	add.s32 	%r4943, %r4942, %r4941;
	add.s32 	%r4944, %r4943, -1926607734;
	shf.l.wrap.b32 	%r4945, %r4944, %r4944, 20;
	add.s32 	%r4946, %r4945, %r4938;
	xor.b32  	%r4947, %r4946, %r4938;
	xor.b32  	%r4948, %r4947, %r4930;
	add.s32 	%r4949, %r7733, %r4922;
	add.s32 	%r4950, %r4949, %r4948;
	add.s32 	%r4951, %r4950, -378558;
	shf.l.wrap.b32 	%r4952, %r4951, %r4951, 4;
	add.s32 	%r4953, %r4952, %r4946;
	xor.b32  	%r4954, %r4953, %r4947;
	add.s32 	%r4955, %r7730, %r4930;
	add.s32 	%r4956, %r4955, %r4954;
	add.s32 	%r4957, %r4956, -2022574463;
	shf.l.wrap.b32 	%r4958, %r4957, %r4957, 11;
	add.s32 	%r4959, %r4958, %r4953;
	xor.b32  	%r4960, %r4959, %r4953;
	xor.b32  	%r4961, %r4960, %r4946;
	add.s32 	%r4962, %r7727, %r4938;
	add.s32 	%r4963, %r4962, %r4961;
	add.s32 	%r4964, %r4963, 1839030562;
	shf.l.wrap.b32 	%r4965, %r4964, %r4964, 16;
	add.s32 	%r4966, %r4965, %r4959;
	xor.b32  	%r4967, %r4966, %r4960;
	add.s32 	%r4968, %r4807, %r4946;
	add.s32 	%r4969, %r4968, %r4967;
	add.s32 	%r4970, %r4969, -35309556;
	shf.l.wrap.b32 	%r4971, %r4970, %r4970, 23;
	add.s32 	%r4972, %r4971, %r4966;
	xor.b32  	%r4973, %r4972, %r4966;
	xor.b32  	%r4974, %r4973, %r4959;
	add.s32 	%r4975, %r7737, %r4953;
	add.s32 	%r4976, %r4975, %r4974;
	add.s32 	%r4977, %r4976, -1530992060;
	shf.l.wrap.b32 	%r4978, %r4977, %r4977, 4;
	add.s32 	%r4979, %r4978, %r4972;
	xor.b32  	%r4980, %r4979, %r4973;
	add.s32 	%r4981, %r7734, %r4959;
	add.s32 	%r4982, %r4981, %r4980;
	add.s32 	%r4983, %r4982, 1272893353;
	shf.l.wrap.b32 	%r4984, %r4983, %r4983, 11;
	add.s32 	%r4985, %r4984, %r4979;
	xor.b32  	%r4986, %r4985, %r4979;
	xor.b32  	%r4987, %r4986, %r4972;
	add.s32 	%r4988, %r7731, %r4966;
	add.s32 	%r4989, %r4988, %r4987;
	add.s32 	%r4990, %r4989, -155497632;
	shf.l.wrap.b32 	%r4991, %r4990, %r4990, 16;
	add.s32 	%r4992, %r4991, %r4985;
	xor.b32  	%r4993, %r4992, %r4986;
	add.s32 	%r4994, %r7728, %r4972;
	add.s32 	%r4995, %r4994, %r4993;
	add.s32 	%r4996, %r4995, -1094730640;
	shf.l.wrap.b32 	%r4997, %r4996, %r4996, 23;
	add.s32 	%r4998, %r4997, %r4992;
	xor.b32  	%r4999, %r4998, %r4992;
	xor.b32  	%r5000, %r4999, %r4985;
	add.s32 	%r5001, %r7725, %r4979;
	add.s32 	%r5002, %r5001, %r5000;
	add.s32 	%r5003, %r5002, 681279174;
	shf.l.wrap.b32 	%r5004, %r5003, %r5003, 4;
	add.s32 	%r5005, %r5004, %r4998;
	xor.b32  	%r5006, %r5005, %r4999;
	add.s32 	%r5007, %r7738, %r4985;
	add.s32 	%r5008, %r5007, %r5006;
	add.s32 	%r5009, %r5008, -358537222;
	shf.l.wrap.b32 	%r5010, %r5009, %r5009, 11;
	add.s32 	%r5011, %r5010, %r5005;
	xor.b32  	%r5012, %r5011, %r5005;
	xor.b32  	%r5013, %r5012, %r4998;
	add.s32 	%r5014, %r7735, %r4992;
	add.s32 	%r5015, %r5014, %r5013;
	add.s32 	%r5016, %r5015, -722521979;
	shf.l.wrap.b32 	%r5017, %r5016, %r5016, 16;
	add.s32 	%r5018, %r5017, %r5011;
	xor.b32  	%r5019, %r5018, %r5012;
	add.s32 	%r5020, %r7732, %r4998;
	add.s32 	%r5021, %r5020, %r5019;
	add.s32 	%r5022, %r5021, 76029189;
	shf.l.wrap.b32 	%r5023, %r5022, %r5022, 23;
	add.s32 	%r5024, %r5023, %r5018;
	xor.b32  	%r5025, %r5024, %r5018;
	xor.b32  	%r5026, %r5025, %r5011;
	add.s32 	%r5027, %r7729, %r5005;
	add.s32 	%r5028, %r5027, %r5026;
	add.s32 	%r5029, %r5028, -640364487;
	shf.l.wrap.b32 	%r5030, %r5029, %r5029, 4;
	add.s32 	%r5031, %r5030, %r5024;
	xor.b32  	%r5032, %r5031, %r5025;
	add.s32 	%r5033, %r7726, %r5011;
	add.s32 	%r5034, %r5033, %r5032;
	add.s32 	%r5035, %r5034, -421815835;
	shf.l.wrap.b32 	%r5036, %r5035, %r5035, 11;
	add.s32 	%r5037, %r5036, %r5031;
	xor.b32  	%r5038, %r5037, %r5031;
	xor.b32  	%r5039, %r5038, %r5024;
	add.s32 	%r5040, %r5018, %r5039;
	add.s32 	%r5041, %r5040, 530742520;
	shf.l.wrap.b32 	%r5042, %r5041, %r5041, 16;
	add.s32 	%r5043, %r5042, %r5037;
	xor.b32  	%r5044, %r5043, %r5038;
	add.s32 	%r5045, %r7736, %r5024;
	add.s32 	%r5046, %r5045, %r5044;
	add.s32 	%r5047, %r5046, -995338651;
	shf.l.wrap.b32 	%r5048, %r5047, %r5047, 23;
	add.s32 	%r5049, %r5048, %r5043;
	not.b32 	%r5050, %r5037;
	or.b32  	%r5051, %r5049, %r5050;
	xor.b32  	%r5052, %r5051, %r5043;
	add.s32 	%r5053, %r7738, %r5031;
	add.s32 	%r5054, %r5053, %r5052;
	add.s32 	%r5055, %r5054, -198630844;
	shf.l.wrap.b32 	%r5056, %r5055, %r5055, 6;
	add.s32 	%r5057, %r5056, %r5049;
	not.b32 	%r5058, %r5043;
	or.b32  	%r5059, %r5057, %r5058;
	xor.b32  	%r5060, %r5059, %r5049;
	add.s32 	%r5061, %r7731, %r5037;
	add.s32 	%r5062, %r5061, %r5060;
	add.s32 	%r5063, %r5062, 1126891415;
	shf.l.wrap.b32 	%r5064, %r5063, %r5063, 10;
	add.s32 	%r5065, %r5064, %r5057;
	not.b32 	%r5066, %r5049;
	or.b32  	%r5067, %r5065, %r5066;
	xor.b32  	%r5068, %r5067, %r5057;
	add.s32 	%r5069, %r4807, %r5043;
	add.s32 	%r5070, %r5069, %r5068;
	add.s32 	%r5071, %r5070, -1416354905;
	shf.l.wrap.b32 	%r5072, %r5071, %r5071, 15;
	add.s32 	%r5073, %r5072, %r5065;
	not.b32 	%r5074, %r5057;
	or.b32  	%r5075, %r5073, %r5074;
	xor.b32  	%r5076, %r5075, %r5065;
	add.s32 	%r5077, %r7733, %r5049;
	add.s32 	%r5078, %r5077, %r5076;
	add.s32 	%r5079, %r5078, -57434055;
	shf.l.wrap.b32 	%r5080, %r5079, %r5079, 21;
	add.s32 	%r5081, %r5080, %r5073;
	not.b32 	%r5082, %r5065;
	or.b32  	%r5083, %r5081, %r5082;
	xor.b32  	%r5084, %r5083, %r5073;
	add.s32 	%r5085, %r7726, %r5057;
	add.s32 	%r5086, %r5085, %r5084;
	add.s32 	%r5087, %r5086, 1700485571;
	shf.l.wrap.b32 	%r5088, %r5087, %r5087, 6;
	add.s32 	%r5089, %r5088, %r5081;
	not.b32 	%r5090, %r5073;
	or.b32  	%r5091, %r5089, %r5090;
	xor.b32  	%r5092, %r5091, %r5081;
	add.s32 	%r5093, %r7735, %r5065;
	add.s32 	%r5094, %r5093, %r5092;
	add.s32 	%r5095, %r5094, -1894986606;
	shf.l.wrap.b32 	%r5096, %r5095, %r5095, 10;
	add.s32 	%r5097, %r5096, %r5089;
	not.b32 	%r5098, %r5081;
	or.b32  	%r5099, %r5097, %r5098;
	xor.b32  	%r5100, %r5099, %r5089;
	add.s32 	%r5101, %r7728, %r5073;
	add.s32 	%r5102, %r5101, %r5100;
	add.s32 	%r5103, %r5102, -1051523;
	shf.l.wrap.b32 	%r5104, %r5103, %r5103, 15;
	add.s32 	%r5105, %r5104, %r5097;
	not.b32 	%r5106, %r5089;
	or.b32  	%r5107, %r5105, %r5106;
	xor.b32  	%r5108, %r5107, %r5097;
	add.s32 	%r5109, %r7737, %r5081;
	add.s32 	%r5110, %r5109, %r5108;
	add.s32 	%r5111, %r5110, -2054922799;
	shf.l.wrap.b32 	%r5112, %r5111, %r5111, 21;
	add.s32 	%r5113, %r5112, %r5105;
	not.b32 	%r5114, %r5097;
	or.b32  	%r5115, %r5113, %r5114;
	xor.b32  	%r5116, %r5115, %r5105;
	add.s32 	%r5117, %r7730, %r5089;
	add.s32 	%r5118, %r5117, %r5116;
	add.s32 	%r5119, %r5118, 1873313359;
	shf.l.wrap.b32 	%r5120, %r5119, %r5119, 6;
	add.s32 	%r5121, %r5120, %r5113;
	not.b32 	%r5122, %r5105;
	or.b32  	%r5123, %r5121, %r5122;
	xor.b32  	%r5124, %r5123, %r5113;
	add.s32 	%r5125, %r5097, %r5124;
	add.s32 	%r5126, %r5125, -30611744;
	shf.l.wrap.b32 	%r5127, %r5126, %r5126, 10;
	add.s32 	%r5128, %r5127, %r5121;
	not.b32 	%r5129, %r5113;
	or.b32  	%r5130, %r5128, %r5129;
	xor.b32  	%r5131, %r5130, %r5121;
	add.s32 	%r5132, %r7732, %r5105;
	add.s32 	%r5133, %r5132, %r5131;
	add.s32 	%r5134, %r5133, -1560198380;
	shf.l.wrap.b32 	%r5135, %r5134, %r5134, 15;
	add.s32 	%r5136, %r5135, %r5128;
	not.b32 	%r5137, %r5121;
	or.b32  	%r5138, %r5136, %r5137;
	xor.b32  	%r5139, %r5138, %r5128;
	add.s32 	%r5140, %r7725, %r5113;
	add.s32 	%r5141, %r5140, %r5139;
	add.s32 	%r5142, %r5141, 1309151649;
	shf.l.wrap.b32 	%r5143, %r5142, %r5142, 21;
	add.s32 	%r5144, %r5143, %r5136;
	not.b32 	%r5145, %r5128;
	or.b32  	%r5146, %r5144, %r5145;
	xor.b32  	%r5147, %r5146, %r5136;
	add.s32 	%r5148, %r7734, %r5121;
	add.s32 	%r5149, %r5148, %r5147;
	add.s32 	%r5150, %r5149, -145523070;
	shf.l.wrap.b32 	%r5151, %r5150, %r5150, 6;
	add.s32 	%r5152, %r5151, %r5144;
	not.b32 	%r5153, %r5136;
	or.b32  	%r5154, %r5152, %r5153;
	xor.b32  	%r5155, %r5154, %r5144;
	add.s32 	%r5156, %r7727, %r5128;
	add.s32 	%r5157, %r5156, %r5155;
	add.s32 	%r5158, %r5157, -1120210379;
	shf.l.wrap.b32 	%r5159, %r5158, %r5158, 10;
	add.s32 	%r5160, %r5159, %r5152;
	not.b32 	%r5161, %r5144;
	or.b32  	%r5162, %r5160, %r5161;
	xor.b32  	%r5163, %r5162, %r5152;
	add.s32 	%r5164, %r7736, %r5136;
	add.s32 	%r5165, %r5164, %r5163;
	add.s32 	%r5166, %r5165, 718787259;
	shf.l.wrap.b32 	%r5167, %r5166, %r5166, 15;
	add.s32 	%r5168, %r5167, %r5160;
	not.b32 	%r5169, %r5152;
	or.b32  	%r5170, %r5168, %r5169;
	xor.b32  	%r5171, %r5170, %r5160;
	add.s32 	%r5172, %r7729, %r5144;
	add.s32 	%r5173, %r5172, %r5171;
	add.s32 	%r5174, %r5173, -343485551;
	shf.l.wrap.b32 	%r5175, %r5174, %r5174, 21;
	add.s32 	%r5176, %r5152, %r92;
	add.s32 	%r5177, %r5168, %r91;
	add.s32 	%r5178, %r5177, %r5175;
	add.s32 	%r5179, %r5168, %r90;
	add.s32 	%r5180, %r5160, %r89;
	setp.eq.s32	%p78, %r5176, %r2;
	setp.eq.s32	%p79, %r5180, %r3;
	and.pred  	%p80, %p78, %p79;
	setp.eq.s32	%p81, %r5179, %r4;
	and.pred  	%p82, %p80, %p81;
	setp.eq.s32	%p83, %r5178, %r5;
	and.pred  	%p84, %p82, %p83;
	@!%p84 bra 	BB4_118;
	bra.uni 	BB4_114;

BB4_114:
	atom.global.add.u32 	%r5181, [%rd3], 1;
	setp.ne.s32	%p85, %r5181, 0;
	@%p85 bra 	BB4_118;

	ld.param.u32 	%r7603, [m00000_sxx_param_31];
	atom.global.add.u32 	%r650, [%rd10], 1;
	setp.lt.u32	%p86, %r650, %r7603;
	@%p86 bra 	BB4_117;
	bra.uni 	BB4_116;

BB4_117:
	ld.param.u32 	%r7605, [m00000_sxx_param_27];
	ld.param.u64 	%rd30, [m00000_sxx_param_14];
	ld.param.u32 	%r7604, [m00000_sxx_param_32];
	mul.wide.u32 	%rd27, %r650, 24;
	mov.u32 	%r5183, 0;
	add.s64 	%rd28, %rd30, %rd27;
	st.global.v2.u32 	[%rd28+16], {%r5183, %r7604};
	st.global.v2.u32 	[%rd28+8], {%r7633, %r7605};
	st.global.u64 	[%rd28], %rd1;
	bra.uni 	BB4_118;

BB4_116:
	atom.global.add.u32 	%r5182, [%rd10], -1;

BB4_118:
	ld.param.u32 	%r7601, [m00000_sxx_param_30];
	add.s32 	%r7633, %r7633, 1;
	setp.lt.u32	%p87, %r7633, %r7601;
	@%p87 bra 	BB4_8;

BB4_119:
	ret;
}


  